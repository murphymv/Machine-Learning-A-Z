% Options for packages loaded elsewhere
\PassOptionsToPackage{unicode}{hyperref}
\PassOptionsToPackage{hyphens}{url}
%
\documentclass[
]{book}
\title{Machine Learning A-Z}
\author{}
\date{\vspace{-2.5em}}

\usepackage{amsmath,amssymb}
\usepackage{lmodern}
\usepackage{iftex}
\ifPDFTeX
  \usepackage[T1]{fontenc}
  \usepackage[utf8]{inputenc}
  \usepackage{textcomp} % provide euro and other symbols
\else % if luatex or xetex
  \usepackage{unicode-math}
  \defaultfontfeatures{Scale=MatchLowercase}
  \defaultfontfeatures[\rmfamily]{Ligatures=TeX,Scale=1}
\fi
% Use upquote if available, for straight quotes in verbatim environments
\IfFileExists{upquote.sty}{\usepackage{upquote}}{}
\IfFileExists{microtype.sty}{% use microtype if available
  \usepackage[]{microtype}
  \UseMicrotypeSet[protrusion]{basicmath} % disable protrusion for tt fonts
}{}
\makeatletter
\@ifundefined{KOMAClassName}{% if non-KOMA class
  \IfFileExists{parskip.sty}{%
    \usepackage{parskip}
  }{% else
    \setlength{\parindent}{0pt}
    \setlength{\parskip}{6pt plus 2pt minus 1pt}}
}{% if KOMA class
  \KOMAoptions{parskip=half}}
\makeatother
\usepackage{xcolor}
\IfFileExists{xurl.sty}{\usepackage{xurl}}{} % add URL line breaks if available
\IfFileExists{bookmark.sty}{\usepackage{bookmark}}{\usepackage{hyperref}}
\hypersetup{
  pdftitle={Machine Learning A-Z},
  hidelinks,
  pdfcreator={LaTeX via pandoc}}
\urlstyle{same} % disable monospaced font for URLs
\usepackage{color}
\usepackage{fancyvrb}
\newcommand{\VerbBar}{|}
\newcommand{\VERB}{\Verb[commandchars=\\\{\}]}
\DefineVerbatimEnvironment{Highlighting}{Verbatim}{commandchars=\\\{\}}
% Add ',fontsize=\small' for more characters per line
\usepackage{framed}
\definecolor{shadecolor}{RGB}{248,248,248}
\newenvironment{Shaded}{\begin{snugshade}}{\end{snugshade}}
\newcommand{\AlertTok}[1]{\textcolor[rgb]{0.94,0.16,0.16}{#1}}
\newcommand{\AnnotationTok}[1]{\textcolor[rgb]{0.56,0.35,0.01}{\textbf{\textit{#1}}}}
\newcommand{\AttributeTok}[1]{\textcolor[rgb]{0.77,0.63,0.00}{#1}}
\newcommand{\BaseNTok}[1]{\textcolor[rgb]{0.00,0.00,0.81}{#1}}
\newcommand{\BuiltInTok}[1]{#1}
\newcommand{\CharTok}[1]{\textcolor[rgb]{0.31,0.60,0.02}{#1}}
\newcommand{\CommentTok}[1]{\textcolor[rgb]{0.56,0.35,0.01}{\textit{#1}}}
\newcommand{\CommentVarTok}[1]{\textcolor[rgb]{0.56,0.35,0.01}{\textbf{\textit{#1}}}}
\newcommand{\ConstantTok}[1]{\textcolor[rgb]{0.00,0.00,0.00}{#1}}
\newcommand{\ControlFlowTok}[1]{\textcolor[rgb]{0.13,0.29,0.53}{\textbf{#1}}}
\newcommand{\DataTypeTok}[1]{\textcolor[rgb]{0.13,0.29,0.53}{#1}}
\newcommand{\DecValTok}[1]{\textcolor[rgb]{0.00,0.00,0.81}{#1}}
\newcommand{\DocumentationTok}[1]{\textcolor[rgb]{0.56,0.35,0.01}{\textbf{\textit{#1}}}}
\newcommand{\ErrorTok}[1]{\textcolor[rgb]{0.64,0.00,0.00}{\textbf{#1}}}
\newcommand{\ExtensionTok}[1]{#1}
\newcommand{\FloatTok}[1]{\textcolor[rgb]{0.00,0.00,0.81}{#1}}
\newcommand{\FunctionTok}[1]{\textcolor[rgb]{0.00,0.00,0.00}{#1}}
\newcommand{\ImportTok}[1]{#1}
\newcommand{\InformationTok}[1]{\textcolor[rgb]{0.56,0.35,0.01}{\textbf{\textit{#1}}}}
\newcommand{\KeywordTok}[1]{\textcolor[rgb]{0.13,0.29,0.53}{\textbf{#1}}}
\newcommand{\NormalTok}[1]{#1}
\newcommand{\OperatorTok}[1]{\textcolor[rgb]{0.81,0.36,0.00}{\textbf{#1}}}
\newcommand{\OtherTok}[1]{\textcolor[rgb]{0.56,0.35,0.01}{#1}}
\newcommand{\PreprocessorTok}[1]{\textcolor[rgb]{0.56,0.35,0.01}{\textit{#1}}}
\newcommand{\RegionMarkerTok}[1]{#1}
\newcommand{\SpecialCharTok}[1]{\textcolor[rgb]{0.00,0.00,0.00}{#1}}
\newcommand{\SpecialStringTok}[1]{\textcolor[rgb]{0.31,0.60,0.02}{#1}}
\newcommand{\StringTok}[1]{\textcolor[rgb]{0.31,0.60,0.02}{#1}}
\newcommand{\VariableTok}[1]{\textcolor[rgb]{0.00,0.00,0.00}{#1}}
\newcommand{\VerbatimStringTok}[1]{\textcolor[rgb]{0.31,0.60,0.02}{#1}}
\newcommand{\WarningTok}[1]{\textcolor[rgb]{0.56,0.35,0.01}{\textbf{\textit{#1}}}}
\usepackage{longtable,booktabs,array}
\usepackage{calc} % for calculating minipage widths
% Correct order of tables after \paragraph or \subparagraph
\usepackage{etoolbox}
\makeatletter
\patchcmd\longtable{\par}{\if@noskipsec\mbox{}\fi\par}{}{}
\makeatother
% Allow footnotes in longtable head/foot
\IfFileExists{footnotehyper.sty}{\usepackage{footnotehyper}}{\usepackage{footnote}}
\makesavenoteenv{longtable}
\usepackage{graphicx}
\makeatletter
\def\maxwidth{\ifdim\Gin@nat@width>\linewidth\linewidth\else\Gin@nat@width\fi}
\def\maxheight{\ifdim\Gin@nat@height>\textheight\textheight\else\Gin@nat@height\fi}
\makeatother
% Scale images if necessary, so that they will not overflow the page
% margins by default, and it is still possible to overwrite the defaults
% using explicit options in \includegraphics[width, height, ...]{}
\setkeys{Gin}{width=\maxwidth,height=\maxheight,keepaspectratio}
% Set default figure placement to htbp
\makeatletter
\def\fps@figure{htbp}
\makeatother
\setlength{\emergencystretch}{3em} % prevent overfull lines
\providecommand{\tightlist}{%
  \setlength{\itemsep}{0pt}\setlength{\parskip}{0pt}}
\setcounter{secnumdepth}{5}
\usepackage{booktabs}
\ifLuaTeX
  \usepackage{selnolig}  % disable illegal ligatures
\fi
\usepackage[]{natbib}
\bibliographystyle{plainnat}

\usepackage{amsthm}
\newtheorem{theorem}{Theorem}[chapter]
\newtheorem{lemma}{Lemma}[chapter]
\newtheorem{corollary}{Corollary}[chapter]
\newtheorem{proposition}{Proposition}[chapter]
\newtheorem{conjecture}{Conjecture}[chapter]
\theoremstyle{definition}
\newtheorem{definition}{Definition}[chapter]
\theoremstyle{definition}
\newtheorem{example}{Example}[chapter]
\theoremstyle{definition}
\newtheorem{exercise}{Exercise}[chapter]
\theoremstyle{definition}
\newtheorem{hypothesis}{Hypothesis}[chapter]
\theoremstyle{remark}
\newtheorem*{remark}{Remark}
\newtheorem*{solution}{Solution}
\begin{document}
\maketitle

{
\setcounter{tocdepth}{1}
\tableofcontents
}
\hypertarget{course-outline}{%
\chapter*{Course Outline}\label{course-outline}}
\addcontentsline{toc}{chapter}{Course Outline}

Interested in the field of Machine Learning? Then this course is for you!

This course has been designed by two professional Data Scientists so that we can share our knowledge and help you learn complex theory, algorithms, and coding libraries in a simple way.

We will walk you step-by-step into the World of Machine Learning. With every tutorial, you will develop new skills and improve your understanding of this challenging yet lucrative sub-field of Data Science.

This course is fun and exciting, but at the same time, we dive deep into Machine Learning. It is structured the following way:

\begin{itemize}
\item
  Part 1 - Data Preprocessing
\item
  Part 2 - Regression: Simple Linear Regression, Multiple Linear Regression, Polynomial Regression, SVR, Decision Tree Regression, Random Forest Regression
\item
  Part 3 - Classification: Logistic Regression, K-NN, SVM, Kernel SVM, Naive Bayes, Decision Tree Classification, Random Forest Classification
\item
  Part 4 - Clustering: K-Means, Hierarchical Clustering
\item
  Part 5 - Association Rule Learning: Apriori, Eclat
\item
  Part 6 - Reinforcement Learning: Upper Confidence Bound, Thompson Sampling
\item
  Part 7 - Natural Language Processing: Bag-of-words model and algorithms for NLP
\item
  Part 8 - Deep Learning: Artificial Neural Networks, Convolutional Neural Networks
\item
  Part 9 - Dimensionality Reduction: PCA, LDA, Kernel PCA
\item
  Part 10 - Model Selection \& Boosting: k-fold Cross Validation, Parameter Tuning, Grid Search, XGBoost
\end{itemize}

Moreover, the course is packed with practical exercises that are based on real-life examples. So not only will you learn the theory, but you will also get some hands-on practice building your own models.

And as a bonus, this course includes both Python and R code templates which you can download and use on your own projects.

\textbf{Important updates (June 2020):}

\begin{itemize}
\item
  CODES ALL UP TO DATE
\item
  DEEP LEARNING CODED IN TENSORFLOW 2.0
\item
  TOP GRADIENT BOOSTING MODELS INCLUDING XGBOOST AND EVEN CATBOOST!
\end{itemize}

\hypertarget{what-youll-learn}{%
\section*{What you'll learn:}\label{what-youll-learn}}
\addcontentsline{toc}{section}{What you'll learn:}

\begin{itemize}
\item
  Master Machine Learning on Python \& R
\item
  Have a great intuition of many Machine Learning models
\item
  Make accurate predictions
\item
  Make powerful analysis
\item
  Make robust Machine Learning models
\item
  Create strong added value to your business
\item
  Use Machine Learning for personal purpose
\item
  Handle specific topics like Reinforcement Learning, NLP and Deep Learning
\item
  Handle advanced techniques like Dimensionality Reduction
\item
  Know which Machine Learning model to choose for each type of problem
\item
  Build an army of powerful Machine Learning models and know how to combine them to solve any problem
\end{itemize}

\hypertarget{are-there-any-course-requirements-or-prerequisites}{%
\section*{Are there any course requirements or prerequisites?}\label{are-there-any-course-requirements-or-prerequisites}}
\addcontentsline{toc}{section}{Are there any course requirements or prerequisites?}

\begin{itemize}
\tightlist
\item
  Just some high school mathematics level.
\end{itemize}

\hypertarget{who-this-course-is-for}{%
\section*{Who this course is for:}\label{who-this-course-is-for}}
\addcontentsline{toc}{section}{Who this course is for:}

\begin{itemize}
\item
  Anyone interested in Machine Learning.
\item
  Students who have at least high school knowledge in math and who want to start learning Machine Learning.
\item
  Any intermediate level people who know the basics of machine learning, including the classical algorithms like linear regression or logistic regression, but who want to learn more about it and explore all the different fields of Machine Learning.
\item
  Any people who are not that comfortable with coding but who are interested in Machine Learning and want to apply it easily on datasets.
\item
  Any students in college who want to start a career in Data Science.
\item
  Any data analysts who want to level up in Machine Learning.
\item
  Any people who are not satisfied with their job and who want to become a Data Scientist.
\item
  Any people who want to create added value to their business by using powerful Machine Learning tools.
\end{itemize}

\hypertarget{data-preprocessing}{%
\chapter{Data Preprocessing}\label{data-preprocessing}}

\hypertarget{importing-the-libraries}{%
\section{Importing the libraries}\label{importing-the-libraries}}

Python

\begin{Shaded}
\begin{Highlighting}[]
\ImportTok{import}\NormalTok{ numpy }\ImportTok{as}\NormalTok{ np}
\ImportTok{import}\NormalTok{ matplotlib.pyplot }\ImportTok{as}\NormalTok{ plt}
\ImportTok{import}\NormalTok{ pandas }\ImportTok{as}\NormalTok{ pd}
\end{Highlighting}
\end{Shaded}

\hypertarget{importing-the-dataset}{%
\section{Importing the dataset}\label{importing-the-dataset}}

Python

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{dataset }\OperatorTok{=}\NormalTok{ pd.read\_csv(}\StringTok{\textquotesingle{}Data.csv\textquotesingle{}}\NormalTok{)}
\NormalTok{X }\OperatorTok{=}\NormalTok{ dataset.iloc[:, :}\OperatorTok{{-}}\DecValTok{1}\NormalTok{].values}
\NormalTok{y }\OperatorTok{=}\NormalTok{ dataset.iloc[:, }\OperatorTok{{-}}\DecValTok{1}\NormalTok{].values}
\BuiltInTok{print}\NormalTok{(X)}
\CommentTok{\#\# [[\textquotesingle{}France\textquotesingle{} 44.0 72000.0]}
\CommentTok{\#\#  [\textquotesingle{}Spain\textquotesingle{} 27.0 48000.0]}
\CommentTok{\#\#  [\textquotesingle{}Germany\textquotesingle{} 30.0 54000.0]}
\CommentTok{\#\#  [\textquotesingle{}Spain\textquotesingle{} 38.0 61000.0]}
\CommentTok{\#\#  [\textquotesingle{}Germany\textquotesingle{} 40.0 nan]}
\CommentTok{\#\#  [\textquotesingle{}France\textquotesingle{} 35.0 58000.0]}
\CommentTok{\#\#  [\textquotesingle{}Spain\textquotesingle{} nan 52000.0]}
\CommentTok{\#\#  [\textquotesingle{}France\textquotesingle{} 48.0 79000.0]}
\CommentTok{\#\#  [\textquotesingle{}Germany\textquotesingle{} 50.0 83000.0]}
\CommentTok{\#\#  [\textquotesingle{}France\textquotesingle{} 37.0 67000.0]]}
\BuiltInTok{print}\NormalTok{(y)}
\CommentTok{\#\# [\textquotesingle{}No\textquotesingle{} \textquotesingle{}Yes\textquotesingle{} \textquotesingle{}No\textquotesingle{} \textquotesingle{}No\textquotesingle{} \textquotesingle{}Yes\textquotesingle{} \textquotesingle{}Yes\textquotesingle{} \textquotesingle{}No\textquotesingle{} \textquotesingle{}Yes\textquotesingle{} \textquotesingle{}No\textquotesingle{} \textquotesingle{}Yes\textquotesingle{}]}
\end{Highlighting}
\end{Shaded}

R

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{dataset }\OtherTok{=} \FunctionTok{read.csv}\NormalTok{(}\StringTok{\textquotesingle{}Data.csv\textquotesingle{}}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\hypertarget{taking-care-of-missing-data}{%
\section{Taking care of missing data}\label{taking-care-of-missing-data}}

Python

\begin{Shaded}
\begin{Highlighting}[]
\ImportTok{from}\NormalTok{ sklearn.impute }\ImportTok{import}\NormalTok{ SimpleImputer}
\NormalTok{imputer }\OperatorTok{=}\NormalTok{ SimpleImputer(missing\_values}\OperatorTok{=}\NormalTok{np.nan, strategy}\OperatorTok{=}\StringTok{\textquotesingle{}mean\textquotesingle{}}\NormalTok{)}
\NormalTok{imputer.fit(X[:, }\DecValTok{1}\NormalTok{:}\DecValTok{3}\NormalTok{])}
\CommentTok{\#\# SimpleImputer()}
\NormalTok{X[:, }\DecValTok{1}\NormalTok{:}\DecValTok{3}\NormalTok{] }\OperatorTok{=}\NormalTok{ imputer.transform(X[:, }\DecValTok{1}\NormalTok{:}\DecValTok{3}\NormalTok{])}
\BuiltInTok{print}\NormalTok{(X)}
\CommentTok{\#\# [[\textquotesingle{}France\textquotesingle{} 44.0 72000.0]}
\CommentTok{\#\#  [\textquotesingle{}Spain\textquotesingle{} 27.0 48000.0]}
\CommentTok{\#\#  [\textquotesingle{}Germany\textquotesingle{} 30.0 54000.0]}
\CommentTok{\#\#  [\textquotesingle{}Spain\textquotesingle{} 38.0 61000.0]}
\CommentTok{\#\#  [\textquotesingle{}Germany\textquotesingle{} 40.0 63777.77777777778]}
\CommentTok{\#\#  [\textquotesingle{}France\textquotesingle{} 35.0 58000.0]}
\CommentTok{\#\#  [\textquotesingle{}Spain\textquotesingle{} 38.77777777777778 52000.0]}
\CommentTok{\#\#  [\textquotesingle{}France\textquotesingle{} 48.0 79000.0]}
\CommentTok{\#\#  [\textquotesingle{}Germany\textquotesingle{} 50.0 83000.0]}
\CommentTok{\#\#  [\textquotesingle{}France\textquotesingle{} 37.0 67000.0]]}
\end{Highlighting}
\end{Shaded}

R

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{dataset}\SpecialCharTok{$}\NormalTok{Age }\OtherTok{=} \FunctionTok{ifelse}\NormalTok{(}\FunctionTok{is.na}\NormalTok{(dataset}\SpecialCharTok{$}\NormalTok{Age),}
                     \FunctionTok{ave}\NormalTok{(dataset}\SpecialCharTok{$}\NormalTok{Age, }\AttributeTok{FUN =} \ControlFlowTok{function}\NormalTok{(x) }\FunctionTok{mean}\NormalTok{(x, }\AttributeTok{na.rm =} \ConstantTok{TRUE}\NormalTok{)),}
\NormalTok{                     dataset}\SpecialCharTok{$}\NormalTok{Age)}
\NormalTok{dataset}\SpecialCharTok{$}\NormalTok{Salary }\OtherTok{=} \FunctionTok{ifelse}\NormalTok{(}\FunctionTok{is.na}\NormalTok{(dataset}\SpecialCharTok{$}\NormalTok{Salary),}
                        \FunctionTok{ave}\NormalTok{(dataset}\SpecialCharTok{$}\NormalTok{Salary, }\AttributeTok{FUN =} \ControlFlowTok{function}\NormalTok{(x) }\FunctionTok{mean}\NormalTok{(x, }\AttributeTok{na.rm =} \ConstantTok{TRUE}\NormalTok{)),}
\NormalTok{                        dataset}\SpecialCharTok{$}\NormalTok{Salary)}
\end{Highlighting}
\end{Shaded}

\hypertarget{encoding-categorical-data}{%
\section{Encoding categorical data}\label{encoding-categorical-data}}

Python

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\# Independent Variable}
\ImportTok{from}\NormalTok{ sklearn.compose }\ImportTok{import}\NormalTok{ ColumnTransformer}
\ImportTok{from}\NormalTok{ sklearn.preprocessing }\ImportTok{import}\NormalTok{ OneHotEncoder}
\NormalTok{ct }\OperatorTok{=}\NormalTok{ ColumnTransformer(transformers}\OperatorTok{=}\NormalTok{[(}\StringTok{\textquotesingle{}encoder\textquotesingle{}}\NormalTok{, OneHotEncoder(), [}\DecValTok{0}\NormalTok{])], remainder}\OperatorTok{=}\StringTok{\textquotesingle{}passthrough\textquotesingle{}}\NormalTok{)}
\NormalTok{X }\OperatorTok{=}\NormalTok{ np.array(ct.fit\_transform(X))}
\BuiltInTok{print}\NormalTok{(X)}

\CommentTok{\# Dependent Variable}
\CommentTok{\#\# [[1.0 0.0 0.0 44.0 72000.0]}
\CommentTok{\#\#  [0.0 0.0 1.0 27.0 48000.0]}
\CommentTok{\#\#  [0.0 1.0 0.0 30.0 54000.0]}
\CommentTok{\#\#  [0.0 0.0 1.0 38.0 61000.0]}
\CommentTok{\#\#  [0.0 1.0 0.0 40.0 63777.77777777778]}
\CommentTok{\#\#  [1.0 0.0 0.0 35.0 58000.0]}
\CommentTok{\#\#  [0.0 0.0 1.0 38.77777777777778 52000.0]}
\CommentTok{\#\#  [1.0 0.0 0.0 48.0 79000.0]}
\CommentTok{\#\#  [0.0 1.0 0.0 50.0 83000.0]}
\CommentTok{\#\#  [1.0 0.0 0.0 37.0 67000.0]]}
\ImportTok{from}\NormalTok{ sklearn.preprocessing }\ImportTok{import}\NormalTok{ LabelEncoder}
\NormalTok{le }\OperatorTok{=}\NormalTok{ LabelEncoder()}
\NormalTok{y }\OperatorTok{=}\NormalTok{ le.fit\_transform(y)}
\BuiltInTok{print}\NormalTok{(y)}
\CommentTok{\#\# [0 1 0 0 1 1 0 1 0 1]}
\end{Highlighting}
\end{Shaded}

R

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\# Independent Variable}
\NormalTok{dataset}\SpecialCharTok{$}\NormalTok{Country }\OtherTok{=} \FunctionTok{factor}\NormalTok{(dataset}\SpecialCharTok{$}\NormalTok{Country,}
                         \AttributeTok{levels =} \FunctionTok{c}\NormalTok{(}\StringTok{\textquotesingle{}France\textquotesingle{}}\NormalTok{, }\StringTok{\textquotesingle{}Spain\textquotesingle{}}\NormalTok{, }\StringTok{\textquotesingle{}Germany\textquotesingle{}}\NormalTok{),}
                         \AttributeTok{labels =} \FunctionTok{c}\NormalTok{(}\DecValTok{1}\NormalTok{, }\DecValTok{2}\NormalTok{, }\DecValTok{3}\NormalTok{))}

\CommentTok{\# Dependent Variable}
\NormalTok{dataset}\SpecialCharTok{$}\NormalTok{Purchased }\OtherTok{=} \FunctionTok{factor}\NormalTok{(dataset}\SpecialCharTok{$}\NormalTok{Purchased,}
                           \AttributeTok{levels =} \FunctionTok{c}\NormalTok{(}\StringTok{\textquotesingle{}No\textquotesingle{}}\NormalTok{, }\StringTok{\textquotesingle{}Yes\textquotesingle{}}\NormalTok{),}
                           \AttributeTok{labels =} \FunctionTok{c}\NormalTok{(}\DecValTok{0}\NormalTok{, }\DecValTok{1}\NormalTok{))}
\end{Highlighting}
\end{Shaded}

\hypertarget{splitting-the-dataset-into-the-training-set-and-test-set}{%
\section{Splitting the dataset into the Training set and Test set}\label{splitting-the-dataset-into-the-training-set-and-test-set}}

Python

\begin{Shaded}
\begin{Highlighting}[]
\ImportTok{from}\NormalTok{ sklearn.model\_selection }\ImportTok{import}\NormalTok{ train\_test\_split}
\NormalTok{X\_train, X\_test, y\_train, y\_test }\OperatorTok{=}\NormalTok{ train\_test\_split(X, y, test\_size }\OperatorTok{=} \FloatTok{0.2}\NormalTok{, random\_state }\OperatorTok{=} \DecValTok{1}\NormalTok{)}
\BuiltInTok{print}\NormalTok{(X\_train)}
\CommentTok{\#\# [[0.0 0.0 1.0 38.77777777777778 52000.0]}
\CommentTok{\#\#  [0.0 1.0 0.0 40.0 63777.77777777778]}
\CommentTok{\#\#  [1.0 0.0 0.0 44.0 72000.0]}
\CommentTok{\#\#  [0.0 0.0 1.0 38.0 61000.0]}
\CommentTok{\#\#  [0.0 0.0 1.0 27.0 48000.0]}
\CommentTok{\#\#  [1.0 0.0 0.0 48.0 79000.0]}
\CommentTok{\#\#  [0.0 1.0 0.0 50.0 83000.0]}
\CommentTok{\#\#  [1.0 0.0 0.0 35.0 58000.0]]}
\BuiltInTok{print}\NormalTok{(X\_test)}
\CommentTok{\#\# [[0.0 1.0 0.0 30.0 54000.0]}
\CommentTok{\#\#  [1.0 0.0 0.0 37.0 67000.0]]}
\BuiltInTok{print}\NormalTok{(y\_train)}
\CommentTok{\#\# [0 1 0 0 1 1 0 1]}
\BuiltInTok{print}\NormalTok{(y\_test)}
\CommentTok{\#\# [0 1]}
\end{Highlighting}
\end{Shaded}

R

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\# install.packages(\textquotesingle{}caTools\textquotesingle{})}
\FunctionTok{library}\NormalTok{(caTools)}
\FunctionTok{set.seed}\NormalTok{(}\DecValTok{123}\NormalTok{)}
\NormalTok{split }\OtherTok{=} \FunctionTok{sample.split}\NormalTok{(dataset}\SpecialCharTok{$}\NormalTok{Purchased, }\AttributeTok{SplitRatio =} \FloatTok{0.8}\NormalTok{)}
\NormalTok{training\_set }\OtherTok{=} \FunctionTok{subset}\NormalTok{(dataset, split }\SpecialCharTok{==} \ConstantTok{TRUE}\NormalTok{)}
\NormalTok{test\_set }\OtherTok{=} \FunctionTok{subset}\NormalTok{(dataset, split }\SpecialCharTok{==} \ConstantTok{FALSE}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\hypertarget{feature-scaling}{%
\section{Feature Scaling}\label{feature-scaling}}

Python

\begin{Shaded}
\begin{Highlighting}[]
\ImportTok{from}\NormalTok{ sklearn.preprocessing }\ImportTok{import}\NormalTok{ StandardScaler}
\NormalTok{sc }\OperatorTok{=}\NormalTok{ StandardScaler()}
\NormalTok{X\_train[:, }\DecValTok{3}\NormalTok{:] }\OperatorTok{=}\NormalTok{ sc.fit\_transform(X\_train[:, }\DecValTok{3}\NormalTok{:])}
\NormalTok{X\_test[:, }\DecValTok{3}\NormalTok{:] }\OperatorTok{=}\NormalTok{ sc.transform(X\_test[:, }\DecValTok{3}\NormalTok{:])}
\BuiltInTok{print}\NormalTok{(X\_train)}
\CommentTok{\#\# [[0.0 0.0 1.0 {-}0.19159184384578545 {-}1.0781259408412425]}
\CommentTok{\#\#  [0.0 1.0 0.0 {-}0.014117293757057777 {-}0.07013167641635372]}
\CommentTok{\#\#  [1.0 0.0 0.0 0.566708506533324 0.633562432710455]}
\CommentTok{\#\#  [0.0 0.0 1.0 {-}0.30453019390224867 {-}0.30786617274297867]}
\CommentTok{\#\#  [0.0 0.0 1.0 {-}1.9018011447007988 {-}1.420463615551582]}
\CommentTok{\#\#  [1.0 0.0 0.0 1.1475343068237058 1.232653363453549]}
\CommentTok{\#\#  [0.0 1.0 0.0 1.4379472069688968 1.5749910381638885]}
\CommentTok{\#\#  [1.0 0.0 0.0 {-}0.7401495441200351 {-}0.5646194287757332]]}
\BuiltInTok{print}\NormalTok{(X\_test)}
\CommentTok{\#\# [[0.0 1.0 0.0 {-}1.4661817944830124 {-}0.9069571034860727]}
\CommentTok{\#\#  [1.0 0.0 0.0 {-}0.44973664397484414 0.2056403393225306]]}
\end{Highlighting}
\end{Shaded}

R

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\# training\_set = scale(training\_set)}
\CommentTok{\# test\_set = scale(test\_set)}
\end{Highlighting}
\end{Shaded}

\hypertarget{regression}{%
\chapter{Regression}\label{regression}}

\hypertarget{simple-linear-regression}{%
\section{Simple Linear Regression}\label{simple-linear-regression}}

\hypertarget{importing-the-libraries-1}{%
\subsection{Importing the libraries}\label{importing-the-libraries-1}}

Python

\begin{Shaded}
\begin{Highlighting}[]
\ImportTok{import}\NormalTok{ numpy }\ImportTok{as}\NormalTok{ np}
\ImportTok{import}\NormalTok{ matplotlib.pyplot }\ImportTok{as}\NormalTok{ plt}
\ImportTok{import}\NormalTok{ pandas }\ImportTok{as}\NormalTok{ pd}
\end{Highlighting}
\end{Shaded}

\hypertarget{importing-the-dataset-1}{%
\subsection{Importing the dataset}\label{importing-the-dataset-1}}

Python

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{dataset }\OperatorTok{=}\NormalTok{ pd.read\_csv(}\StringTok{\textquotesingle{}Salary\_Data.csv\textquotesingle{}}\NormalTok{)}
\NormalTok{X }\OperatorTok{=}\NormalTok{ dataset.iloc[:, :}\OperatorTok{{-}}\DecValTok{1}\NormalTok{].values}
\NormalTok{y }\OperatorTok{=}\NormalTok{ dataset.iloc[:, }\OperatorTok{{-}}\DecValTok{1}\NormalTok{].values}
\end{Highlighting}
\end{Shaded}

R

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{dataset }\OtherTok{=} \FunctionTok{read.csv}\NormalTok{(}\StringTok{\textquotesingle{}Salary\_Data.csv\textquotesingle{}}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\hypertarget{splitting-the-dataset-into-the-training-set-and-test-set-1}{%
\subsection{Splitting the dataset into the Training set and Test set}\label{splitting-the-dataset-into-the-training-set-and-test-set-1}}

Python

\begin{Shaded}
\begin{Highlighting}[]
\ImportTok{from}\NormalTok{ sklearn.model\_selection }\ImportTok{import}\NormalTok{ train\_test\_split}
\NormalTok{X\_train, X\_test, y\_train, y\_test }\OperatorTok{=}\NormalTok{ train\_test\_split(X, y, test\_size }\OperatorTok{=} \DecValTok{1}\OperatorTok{/}\DecValTok{3}\NormalTok{, random\_state }\OperatorTok{=} \DecValTok{0}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

R

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\# install.packages(\textquotesingle{}caTools\textquotesingle{})}
\FunctionTok{library}\NormalTok{(caTools)}
\FunctionTok{set.seed}\NormalTok{(}\DecValTok{123}\NormalTok{)}
\NormalTok{split }\OtherTok{=} \FunctionTok{sample.split}\NormalTok{(dataset}\SpecialCharTok{$}\NormalTok{Salary, }\AttributeTok{SplitRatio =} \DecValTok{2}\SpecialCharTok{/}\DecValTok{3}\NormalTok{)}
\NormalTok{training\_set }\OtherTok{=} \FunctionTok{subset}\NormalTok{(dataset, split }\SpecialCharTok{==} \ConstantTok{TRUE}\NormalTok{)}
\NormalTok{test\_set }\OtherTok{=} \FunctionTok{subset}\NormalTok{(dataset, split }\SpecialCharTok{==} \ConstantTok{FALSE}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\hypertarget{training-the-simple-linear-regression-model-on-the-training-set}{%
\subsection{Training the Simple Linear Regression model on the Training set}\label{training-the-simple-linear-regression-model-on-the-training-set}}

Python

\begin{Shaded}
\begin{Highlighting}[]
\ImportTok{from}\NormalTok{ sklearn.linear\_model }\ImportTok{import}\NormalTok{ LinearRegression}
\NormalTok{regressor }\OperatorTok{=}\NormalTok{ LinearRegression()}
\NormalTok{regressor.fit(X\_train, y\_train)}
\CommentTok{\#\# LinearRegression()}
\end{Highlighting}
\end{Shaded}

R

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{regressor }\OtherTok{=} \FunctionTok{lm}\NormalTok{(}\AttributeTok{formula =}\NormalTok{ Salary }\SpecialCharTok{\textasciitilde{}}\NormalTok{ YearsExperience,}
               \AttributeTok{data =}\NormalTok{ training\_set)}
\end{Highlighting}
\end{Shaded}

\hypertarget{predicting-the-test-set-results}{%
\subsection{Predicting the Test set results}\label{predicting-the-test-set-results}}

Python

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{y\_pred }\OperatorTok{=}\NormalTok{ regressor.predict(X\_test)}
\end{Highlighting}
\end{Shaded}

R

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{y\_pred }\OtherTok{=} \FunctionTok{predict}\NormalTok{(regressor, }\AttributeTok{newdata =}\NormalTok{ test\_set)}
\end{Highlighting}
\end{Shaded}

\hypertarget{visualising-the-training-set-results}{%
\subsection{Visualising the Training set results}\label{visualising-the-training-set-results}}

Python

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{plt.scatter(X\_train, y\_train, color }\OperatorTok{=} \StringTok{\textquotesingle{}red\textquotesingle{}}\NormalTok{)}
\NormalTok{plt.plot(X\_train, regressor.predict(X\_train), color }\OperatorTok{=} \StringTok{\textquotesingle{}blue\textquotesingle{}}\NormalTok{)}
\NormalTok{plt.title(}\StringTok{\textquotesingle{}Salary vs Experience (Training set)\textquotesingle{}}\NormalTok{)}
\NormalTok{plt.xlabel(}\StringTok{\textquotesingle{}Years of Experience\textquotesingle{}}\NormalTok{)}
\NormalTok{plt.ylabel(}\StringTok{\textquotesingle{}Salary\textquotesingle{}}\NormalTok{)}
\NormalTok{plt.show()}
\end{Highlighting}
\end{Shaded}

\includegraphics{_main_files/figure-latex/unnamed-chunk-21-1.pdf}

R

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\# install.packages(\textquotesingle{}ggplot2\textquotesingle{})}
\FunctionTok{library}\NormalTok{(ggplot2)}
\FunctionTok{ggplot}\NormalTok{() }\SpecialCharTok{+}
  \FunctionTok{geom\_point}\NormalTok{(}\FunctionTok{aes}\NormalTok{(}\AttributeTok{x =}\NormalTok{ training\_set}\SpecialCharTok{$}\NormalTok{YearsExperience, }\AttributeTok{y =}\NormalTok{ training\_set}\SpecialCharTok{$}\NormalTok{Salary),}
             \AttributeTok{colour =} \StringTok{\textquotesingle{}red\textquotesingle{}}\NormalTok{) }\SpecialCharTok{+}
  \FunctionTok{geom\_line}\NormalTok{(}\FunctionTok{aes}\NormalTok{(}\AttributeTok{x =}\NormalTok{ training\_set}\SpecialCharTok{$}\NormalTok{YearsExperience, }\AttributeTok{y =} \FunctionTok{predict}\NormalTok{(regressor, }\AttributeTok{newdata =}\NormalTok{ training\_set)),}
            \AttributeTok{colour =} \StringTok{\textquotesingle{}blue\textquotesingle{}}\NormalTok{) }\SpecialCharTok{+}
  \FunctionTok{ggtitle}\NormalTok{(}\StringTok{\textquotesingle{}Salary vs Experience (Training set)\textquotesingle{}}\NormalTok{) }\SpecialCharTok{+}
  \FunctionTok{xlab}\NormalTok{(}\StringTok{\textquotesingle{}Years of experience\textquotesingle{}}\NormalTok{) }\SpecialCharTok{+}
  \FunctionTok{ylab}\NormalTok{(}\StringTok{\textquotesingle{}Salary\textquotesingle{}}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\includegraphics{_main_files/figure-latex/unnamed-chunk-22-3.pdf}

\hypertarget{visualising-the-test-set-results}{%
\subsection{Visualising the Test set results}\label{visualising-the-test-set-results}}

Python

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{plt.scatter(X\_test, y\_test, color }\OperatorTok{=} \StringTok{\textquotesingle{}red\textquotesingle{}}\NormalTok{)}
\NormalTok{plt.plot(X\_train, regressor.predict(X\_train), color }\OperatorTok{=} \StringTok{\textquotesingle{}blue\textquotesingle{}}\NormalTok{)}
\NormalTok{plt.title(}\StringTok{\textquotesingle{}Salary vs Experience (Test set)\textquotesingle{}}\NormalTok{)}
\NormalTok{plt.xlabel(}\StringTok{\textquotesingle{}Years of Experience\textquotesingle{}}\NormalTok{)}
\NormalTok{plt.ylabel(}\StringTok{\textquotesingle{}Salary\textquotesingle{}}\NormalTok{)}
\NormalTok{plt.show()}
\end{Highlighting}
\end{Shaded}

\includegraphics{_main_files/figure-latex/unnamed-chunk-23-1.pdf}

R

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\# install.packages(\textquotesingle{}ggplot2\textquotesingle{})}
\FunctionTok{library}\NormalTok{(ggplot2)}
\FunctionTok{ggplot}\NormalTok{() }\SpecialCharTok{+}
  \FunctionTok{geom\_point}\NormalTok{(}\FunctionTok{aes}\NormalTok{(}\AttributeTok{x =}\NormalTok{ test\_set}\SpecialCharTok{$}\NormalTok{YearsExperience, }\AttributeTok{y =}\NormalTok{ test\_set}\SpecialCharTok{$}\NormalTok{Salary),}
             \AttributeTok{colour =} \StringTok{\textquotesingle{}red\textquotesingle{}}\NormalTok{) }\SpecialCharTok{+}
  \FunctionTok{geom\_line}\NormalTok{(}\FunctionTok{aes}\NormalTok{(}\AttributeTok{x =}\NormalTok{ training\_set}\SpecialCharTok{$}\NormalTok{YearsExperience, }\AttributeTok{y =} \FunctionTok{predict}\NormalTok{(regressor, }\AttributeTok{newdata =}\NormalTok{ training\_set)),}
            \AttributeTok{colour =} \StringTok{\textquotesingle{}blue\textquotesingle{}}\NormalTok{) }\SpecialCharTok{+}
  \FunctionTok{ggtitle}\NormalTok{(}\StringTok{\textquotesingle{}Salary vs Experience (Test set)\textquotesingle{}}\NormalTok{) }\SpecialCharTok{+}
  \FunctionTok{xlab}\NormalTok{(}\StringTok{\textquotesingle{}Years of experience\textquotesingle{}}\NormalTok{) }\SpecialCharTok{+}
  \FunctionTok{ylab}\NormalTok{(}\StringTok{\textquotesingle{}Salary\textquotesingle{}}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\includegraphics{_main_files/figure-latex/unnamed-chunk-24-3.pdf}

\hypertarget{multiple-linear-regression}{%
\section{Multiple Linear Regression}\label{multiple-linear-regression}}

\hypertarget{importing-the-libraries-2}{%
\subsection{Importing the libraries}\label{importing-the-libraries-2}}

Python

\begin{Shaded}
\begin{Highlighting}[]
\ImportTok{import}\NormalTok{ numpy }\ImportTok{as}\NormalTok{ np}
\ImportTok{import}\NormalTok{ matplotlib.pyplot }\ImportTok{as}\NormalTok{ plt}
\ImportTok{import}\NormalTok{ pandas }\ImportTok{as}\NormalTok{ pd}
\end{Highlighting}
\end{Shaded}

\hypertarget{importing-the-dataset-2}{%
\subsection{Importing the dataset}\label{importing-the-dataset-2}}

Python

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{dataset }\OperatorTok{=}\NormalTok{ pd.read\_csv(}\StringTok{\textquotesingle{}50\_Startups.csv\textquotesingle{}}\NormalTok{)}
\NormalTok{X }\OperatorTok{=}\NormalTok{ dataset.iloc[:, :}\OperatorTok{{-}}\DecValTok{1}\NormalTok{].values}
\NormalTok{y }\OperatorTok{=}\NormalTok{ dataset.iloc[:, }\OperatorTok{{-}}\DecValTok{1}\NormalTok{].values}
\BuiltInTok{print}\NormalTok{(X)}
\CommentTok{\#\# [[165349.2 136897.8 471784.1 \textquotesingle{}New York\textquotesingle{}]}
\CommentTok{\#\#  [162597.7 151377.59 443898.53 \textquotesingle{}California\textquotesingle{}]}
\CommentTok{\#\#  [153441.51 101145.55 407934.54 \textquotesingle{}Florida\textquotesingle{}]}
\CommentTok{\#\#  [144372.41 118671.85 383199.62 \textquotesingle{}New York\textquotesingle{}]}
\CommentTok{\#\#  [142107.34 91391.77 366168.42 \textquotesingle{}Florida\textquotesingle{}]}
\CommentTok{\#\#  [131876.9 99814.71 362861.36 \textquotesingle{}New York\textquotesingle{}]}
\CommentTok{\#\#  [134615.46 147198.87 127716.82 \textquotesingle{}California\textquotesingle{}]}
\CommentTok{\#\#  [130298.13 145530.06 323876.68 \textquotesingle{}Florida\textquotesingle{}]}
\CommentTok{\#\#  [120542.52 148718.95 311613.29 \textquotesingle{}New York\textquotesingle{}]}
\CommentTok{\#\#  [123334.88 108679.17 304981.62 \textquotesingle{}California\textquotesingle{}]}
\CommentTok{\#\#  [101913.08 110594.11 229160.95 \textquotesingle{}Florida\textquotesingle{}]}
\CommentTok{\#\#  [100671.96 91790.61 249744.55 \textquotesingle{}California\textquotesingle{}]}
\CommentTok{\#\#  [93863.75 127320.38 249839.44 \textquotesingle{}Florida\textquotesingle{}]}
\CommentTok{\#\#  [91992.39 135495.07 252664.93 \textquotesingle{}California\textquotesingle{}]}
\CommentTok{\#\#  [119943.24 156547.42 256512.92 \textquotesingle{}Florida\textquotesingle{}]}
\CommentTok{\#\#  [114523.61 122616.84 261776.23 \textquotesingle{}New York\textquotesingle{}]}
\CommentTok{\#\#  [78013.11 121597.55 264346.06 \textquotesingle{}California\textquotesingle{}]}
\CommentTok{\#\#  [94657.16 145077.58 282574.31 \textquotesingle{}New York\textquotesingle{}]}
\CommentTok{\#\#  [91749.16 114175.79 294919.57 \textquotesingle{}Florida\textquotesingle{}]}
\CommentTok{\#\#  [86419.7 153514.11 0.0 \textquotesingle{}New York\textquotesingle{}]}
\CommentTok{\#\#  [76253.86 113867.3 298664.47 \textquotesingle{}California\textquotesingle{}]}
\CommentTok{\#\#  [78389.47 153773.43 299737.29 \textquotesingle{}New York\textquotesingle{}]}
\CommentTok{\#\#  [73994.56 122782.75 303319.26 \textquotesingle{}Florida\textquotesingle{}]}
\CommentTok{\#\#  [67532.53 105751.03 304768.73 \textquotesingle{}Florida\textquotesingle{}]}
\CommentTok{\#\#  [77044.01 99281.34 140574.81 \textquotesingle{}New York\textquotesingle{}]}
\CommentTok{\#\#  [64664.71 139553.16 137962.62 \textquotesingle{}California\textquotesingle{}]}
\CommentTok{\#\#  [75328.87 144135.98 134050.07 \textquotesingle{}Florida\textquotesingle{}]}
\CommentTok{\#\#  [72107.6 127864.55 353183.81 \textquotesingle{}New York\textquotesingle{}]}
\CommentTok{\#\#  [66051.52 182645.56 118148.2 \textquotesingle{}Florida\textquotesingle{}]}
\CommentTok{\#\#  [65605.48 153032.06 107138.38 \textquotesingle{}New York\textquotesingle{}]}
\CommentTok{\#\#  [61994.48 115641.28 91131.24 \textquotesingle{}Florida\textquotesingle{}]}
\CommentTok{\#\#  [61136.38 152701.92 88218.23 \textquotesingle{}New York\textquotesingle{}]}
\CommentTok{\#\#  [63408.86 129219.61 46085.25 \textquotesingle{}California\textquotesingle{}]}
\CommentTok{\#\#  [55493.95 103057.49 214634.81 \textquotesingle{}Florida\textquotesingle{}]}
\CommentTok{\#\#  [46426.07 157693.92 210797.67 \textquotesingle{}California\textquotesingle{}]}
\CommentTok{\#\#  [46014.02 85047.44 205517.64 \textquotesingle{}New York\textquotesingle{}]}
\CommentTok{\#\#  [28663.76 127056.21 201126.82 \textquotesingle{}Florida\textquotesingle{}]}
\CommentTok{\#\#  [44069.95 51283.14 197029.42 \textquotesingle{}California\textquotesingle{}]}
\CommentTok{\#\#  [20229.59 65947.93 185265.1 \textquotesingle{}New York\textquotesingle{}]}
\CommentTok{\#\#  [38558.51 82982.09 174999.3 \textquotesingle{}California\textquotesingle{}]}
\CommentTok{\#\#  [28754.33 118546.05 172795.67 \textquotesingle{}California\textquotesingle{}]}
\CommentTok{\#\#  [27892.92 84710.77 164470.71 \textquotesingle{}Florida\textquotesingle{}]}
\CommentTok{\#\#  [23640.93 96189.63 148001.11 \textquotesingle{}California\textquotesingle{}]}
\CommentTok{\#\#  [15505.73 127382.3 35534.17 \textquotesingle{}New York\textquotesingle{}]}
\CommentTok{\#\#  [22177.74 154806.14 28334.72 \textquotesingle{}California\textquotesingle{}]}
\CommentTok{\#\#  [1000.23 124153.04 1903.93 \textquotesingle{}New York\textquotesingle{}]}
\CommentTok{\#\#  [1315.46 115816.21 297114.46 \textquotesingle{}Florida\textquotesingle{}]}
\CommentTok{\#\#  [0.0 135426.92 0.0 \textquotesingle{}California\textquotesingle{}]}
\CommentTok{\#\#  [542.05 51743.15 0.0 \textquotesingle{}New York\textquotesingle{}]}
\CommentTok{\#\#  [0.0 116983.8 45173.06 \textquotesingle{}California\textquotesingle{}]]}
\end{Highlighting}
\end{Shaded}

R

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{dataset }\OtherTok{=} \FunctionTok{read.csv}\NormalTok{(}\StringTok{\textquotesingle{}50\_Startups.csv\textquotesingle{}}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\hypertarget{encoding-categorical-data-1}{%
\subsection{Encoding categorical data}\label{encoding-categorical-data-1}}

Python

\begin{Shaded}
\begin{Highlighting}[]
\ImportTok{from}\NormalTok{ sklearn.compose }\ImportTok{import}\NormalTok{ ColumnTransformer}
\ImportTok{from}\NormalTok{ sklearn.preprocessing }\ImportTok{import}\NormalTok{ OneHotEncoder}
\NormalTok{ct }\OperatorTok{=}\NormalTok{ ColumnTransformer(transformers}\OperatorTok{=}\NormalTok{[(}\StringTok{\textquotesingle{}encoder\textquotesingle{}}\NormalTok{, OneHotEncoder(), [}\DecValTok{3}\NormalTok{])], remainder}\OperatorTok{=}\StringTok{\textquotesingle{}passthrough\textquotesingle{}}\NormalTok{)}
\NormalTok{X }\OperatorTok{=}\NormalTok{ np.array(ct.fit\_transform(X))}
\BuiltInTok{print}\NormalTok{(X)}
\CommentTok{\#\# [[0.0 0.0 1.0 165349.2 136897.8 471784.1]}
\CommentTok{\#\#  [1.0 0.0 0.0 162597.7 151377.59 443898.53]}
\CommentTok{\#\#  [0.0 1.0 0.0 153441.51 101145.55 407934.54]}
\CommentTok{\#\#  [0.0 0.0 1.0 144372.41 118671.85 383199.62]}
\CommentTok{\#\#  [0.0 1.0 0.0 142107.34 91391.77 366168.42]}
\CommentTok{\#\#  [0.0 0.0 1.0 131876.9 99814.71 362861.36]}
\CommentTok{\#\#  [1.0 0.0 0.0 134615.46 147198.87 127716.82]}
\CommentTok{\#\#  [0.0 1.0 0.0 130298.13 145530.06 323876.68]}
\CommentTok{\#\#  [0.0 0.0 1.0 120542.52 148718.95 311613.29]}
\CommentTok{\#\#  [1.0 0.0 0.0 123334.88 108679.17 304981.62]}
\CommentTok{\#\#  [0.0 1.0 0.0 101913.08 110594.11 229160.95]}
\CommentTok{\#\#  [1.0 0.0 0.0 100671.96 91790.61 249744.55]}
\CommentTok{\#\#  [0.0 1.0 0.0 93863.75 127320.38 249839.44]}
\CommentTok{\#\#  [1.0 0.0 0.0 91992.39 135495.07 252664.93]}
\CommentTok{\#\#  [0.0 1.0 0.0 119943.24 156547.42 256512.92]}
\CommentTok{\#\#  [0.0 0.0 1.0 114523.61 122616.84 261776.23]}
\CommentTok{\#\#  [1.0 0.0 0.0 78013.11 121597.55 264346.06]}
\CommentTok{\#\#  [0.0 0.0 1.0 94657.16 145077.58 282574.31]}
\CommentTok{\#\#  [0.0 1.0 0.0 91749.16 114175.79 294919.57]}
\CommentTok{\#\#  [0.0 0.0 1.0 86419.7 153514.11 0.0]}
\CommentTok{\#\#  [1.0 0.0 0.0 76253.86 113867.3 298664.47]}
\CommentTok{\#\#  [0.0 0.0 1.0 78389.47 153773.43 299737.29]}
\CommentTok{\#\#  [0.0 1.0 0.0 73994.56 122782.75 303319.26]}
\CommentTok{\#\#  [0.0 1.0 0.0 67532.53 105751.03 304768.73]}
\CommentTok{\#\#  [0.0 0.0 1.0 77044.01 99281.34 140574.81]}
\CommentTok{\#\#  [1.0 0.0 0.0 64664.71 139553.16 137962.62]}
\CommentTok{\#\#  [0.0 1.0 0.0 75328.87 144135.98 134050.07]}
\CommentTok{\#\#  [0.0 0.0 1.0 72107.6 127864.55 353183.81]}
\CommentTok{\#\#  [0.0 1.0 0.0 66051.52 182645.56 118148.2]}
\CommentTok{\#\#  [0.0 0.0 1.0 65605.48 153032.06 107138.38]}
\CommentTok{\#\#  [0.0 1.0 0.0 61994.48 115641.28 91131.24]}
\CommentTok{\#\#  [0.0 0.0 1.0 61136.38 152701.92 88218.23]}
\CommentTok{\#\#  [1.0 0.0 0.0 63408.86 129219.61 46085.25]}
\CommentTok{\#\#  [0.0 1.0 0.0 55493.95 103057.49 214634.81]}
\CommentTok{\#\#  [1.0 0.0 0.0 46426.07 157693.92 210797.67]}
\CommentTok{\#\#  [0.0 0.0 1.0 46014.02 85047.44 205517.64]}
\CommentTok{\#\#  [0.0 1.0 0.0 28663.76 127056.21 201126.82]}
\CommentTok{\#\#  [1.0 0.0 0.0 44069.95 51283.14 197029.42]}
\CommentTok{\#\#  [0.0 0.0 1.0 20229.59 65947.93 185265.1]}
\CommentTok{\#\#  [1.0 0.0 0.0 38558.51 82982.09 174999.3]}
\CommentTok{\#\#  [1.0 0.0 0.0 28754.33 118546.05 172795.67]}
\CommentTok{\#\#  [0.0 1.0 0.0 27892.92 84710.77 164470.71]}
\CommentTok{\#\#  [1.0 0.0 0.0 23640.93 96189.63 148001.11]}
\CommentTok{\#\#  [0.0 0.0 1.0 15505.73 127382.3 35534.17]}
\CommentTok{\#\#  [1.0 0.0 0.0 22177.74 154806.14 28334.72]}
\CommentTok{\#\#  [0.0 0.0 1.0 1000.23 124153.04 1903.93]}
\CommentTok{\#\#  [0.0 1.0 0.0 1315.46 115816.21 297114.46]}
\CommentTok{\#\#  [1.0 0.0 0.0 0.0 135426.92 0.0]}
\CommentTok{\#\#  [0.0 0.0 1.0 542.05 51743.15 0.0]}
\CommentTok{\#\#  [1.0 0.0 0.0 0.0 116983.8 45173.06]]}
\end{Highlighting}
\end{Shaded}

R

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{dataset}\SpecialCharTok{$}\NormalTok{State }\OtherTok{=} \FunctionTok{factor}\NormalTok{(dataset}\SpecialCharTok{$}\NormalTok{State,}
                       \AttributeTok{levels =} \FunctionTok{c}\NormalTok{(}\StringTok{\textquotesingle{}New York\textquotesingle{}}\NormalTok{, }\StringTok{\textquotesingle{}California\textquotesingle{}}\NormalTok{, }\StringTok{\textquotesingle{}Florida\textquotesingle{}}\NormalTok{),}
                       \AttributeTok{labels =} \FunctionTok{c}\NormalTok{(}\DecValTok{1}\NormalTok{, }\DecValTok{2}\NormalTok{, }\DecValTok{3}\NormalTok{))}
\end{Highlighting}
\end{Shaded}

\hypertarget{splitting-the-dataset-into-the-training-set-and-test-set-2}{%
\subsection{Splitting the dataset into the Training set and Test set}\label{splitting-the-dataset-into-the-training-set-and-test-set-2}}

Python

\begin{Shaded}
\begin{Highlighting}[]
\ImportTok{from}\NormalTok{ sklearn.model\_selection }\ImportTok{import}\NormalTok{ train\_test\_split}
\NormalTok{X\_train, X\_test, y\_train, y\_test }\OperatorTok{=}\NormalTok{ train\_test\_split(X, y, test\_size }\OperatorTok{=} \FloatTok{0.2}\NormalTok{, random\_state }\OperatorTok{=} \DecValTok{0}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

R

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\# install.packages(\textquotesingle{}caTools\textquotesingle{})}
\FunctionTok{library}\NormalTok{(caTools)}
\FunctionTok{set.seed}\NormalTok{(}\DecValTok{123}\NormalTok{)}
\NormalTok{split }\OtherTok{=} \FunctionTok{sample.split}\NormalTok{(dataset}\SpecialCharTok{$}\NormalTok{Profit, }\AttributeTok{SplitRatio =} \FloatTok{0.8}\NormalTok{)}
\NormalTok{training\_set }\OtherTok{=} \FunctionTok{subset}\NormalTok{(dataset, split }\SpecialCharTok{==} \ConstantTok{TRUE}\NormalTok{)}
\NormalTok{test\_set }\OtherTok{=} \FunctionTok{subset}\NormalTok{(dataset, split }\SpecialCharTok{==} \ConstantTok{FALSE}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\hypertarget{training-the-multiple-linear-regression-model-on-the-training-set}{%
\subsection{Training the Multiple Linear Regression model on the Training set}\label{training-the-multiple-linear-regression-model-on-the-training-set}}

Python

\begin{Shaded}
\begin{Highlighting}[]
\ImportTok{from}\NormalTok{ sklearn.linear\_model }\ImportTok{import}\NormalTok{ LinearRegression}
\NormalTok{regressor }\OperatorTok{=}\NormalTok{ LinearRegression()}
\NormalTok{regressor.fit(X\_train, y\_train)}
\CommentTok{\#\# LinearRegression()}
\end{Highlighting}
\end{Shaded}

R

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{regressor }\OtherTok{=} \FunctionTok{lm}\NormalTok{(}\AttributeTok{formula =}\NormalTok{ Profit }\SpecialCharTok{\textasciitilde{}}\NormalTok{ .,}
               \AttributeTok{data =}\NormalTok{ training\_set)}
\end{Highlighting}
\end{Shaded}

\hypertarget{predicting-the-test-set-results-1}{%
\subsection{Predicting the Test set results}\label{predicting-the-test-set-results-1}}

Python

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{y\_pred }\OperatorTok{=}\NormalTok{ regressor.predict(X\_test)}
\NormalTok{np.set\_printoptions(precision}\OperatorTok{=}\DecValTok{2}\NormalTok{)}
\BuiltInTok{print}\NormalTok{(np.concatenate((y\_pred.reshape(}\BuiltInTok{len}\NormalTok{(y\_pred),}\DecValTok{1}\NormalTok{), y\_test.reshape(}\BuiltInTok{len}\NormalTok{(y\_test),}\DecValTok{1}\NormalTok{)),}\DecValTok{1}\NormalTok{))}
\CommentTok{\#\# [[103015.2  103282.38]}
\CommentTok{\#\#  [132582.28 144259.4 ]}
\CommentTok{\#\#  [132447.74 146121.95]}
\CommentTok{\#\#  [ 71976.1   77798.83]}
\CommentTok{\#\#  [178537.48 191050.39]}
\CommentTok{\#\#  [116161.24 105008.31]}
\CommentTok{\#\#  [ 67851.69  81229.06]}
\CommentTok{\#\#  [ 98791.73  97483.56]}
\CommentTok{\#\#  [113969.44 110352.25]}
\CommentTok{\#\#  [167921.07 166187.94]]}
\end{Highlighting}
\end{Shaded}

R

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{y\_pred }\OtherTok{=} \FunctionTok{predict}\NormalTok{(regressor, }\AttributeTok{newdata =}\NormalTok{ test\_set)}
\end{Highlighting}
\end{Shaded}

\hypertarget{polynomial-regression}{%
\section{Polynomial Regression}\label{polynomial-regression}}

\hypertarget{importing-the-libraries-3}{%
\subsection{Importing the libraries}\label{importing-the-libraries-3}}

Python

\begin{Shaded}
\begin{Highlighting}[]
\ImportTok{import}\NormalTok{ numpy }\ImportTok{as}\NormalTok{ np}
\ImportTok{import}\NormalTok{ matplotlib.pyplot }\ImportTok{as}\NormalTok{ plt}
\ImportTok{import}\NormalTok{ pandas }\ImportTok{as}\NormalTok{ pd}
\end{Highlighting}
\end{Shaded}

\hypertarget{importing-the-dataset-3}{%
\subsection{Importing the dataset}\label{importing-the-dataset-3}}

Python

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{dataset }\OperatorTok{=}\NormalTok{ pd.read\_csv(}\StringTok{\textquotesingle{}Position\_Salaries.csv\textquotesingle{}}\NormalTok{)}
\NormalTok{X }\OperatorTok{=}\NormalTok{ dataset.iloc[:, }\DecValTok{1}\NormalTok{:}\OperatorTok{{-}}\DecValTok{1}\NormalTok{].values}
\NormalTok{y }\OperatorTok{=}\NormalTok{ dataset.iloc[:, }\OperatorTok{{-}}\DecValTok{1}\NormalTok{].values}
\end{Highlighting}
\end{Shaded}

R

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{dataset }\OtherTok{=} \FunctionTok{read.csv}\NormalTok{(}\StringTok{\textquotesingle{}Position\_Salaries.csv\textquotesingle{}}\NormalTok{)}
\NormalTok{dataset }\OtherTok{=}\NormalTok{ dataset[}\DecValTok{2}\SpecialCharTok{:}\DecValTok{3}\NormalTok{]}
\end{Highlighting}
\end{Shaded}

\hypertarget{training-the-linear-regression-model-on-the-whole-dataset}{%
\subsection{Training the Linear Regression model on the whole dataset}\label{training-the-linear-regression-model-on-the-whole-dataset}}

Python

\begin{Shaded}
\begin{Highlighting}[]
\ImportTok{from}\NormalTok{ sklearn.linear\_model }\ImportTok{import}\NormalTok{ LinearRegression}
\NormalTok{lin\_reg }\OperatorTok{=}\NormalTok{ LinearRegression()}
\NormalTok{lin\_reg.fit(X, y)}
\CommentTok{\#\# LinearRegression()}
\end{Highlighting}
\end{Shaded}

R

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{lin\_reg }\OtherTok{=} \FunctionTok{lm}\NormalTok{(}\AttributeTok{formula =}\NormalTok{ Salary }\SpecialCharTok{\textasciitilde{}}\NormalTok{ .,}
             \AttributeTok{data =}\NormalTok{ dataset)}
\end{Highlighting}
\end{Shaded}

\hypertarget{training-the-polynomial-regression-model-on-the-whole-dataset}{%
\subsection{Training the Polynomial Regression model on the whole dataset}\label{training-the-polynomial-regression-model-on-the-whole-dataset}}

Python

\begin{Shaded}
\begin{Highlighting}[]
\ImportTok{from}\NormalTok{ sklearn.preprocessing }\ImportTok{import}\NormalTok{ PolynomialFeatures}
\NormalTok{poly\_reg }\OperatorTok{=}\NormalTok{ PolynomialFeatures(degree }\OperatorTok{=} \DecValTok{4}\NormalTok{)}
\NormalTok{X\_poly }\OperatorTok{=}\NormalTok{ poly\_reg.fit\_transform(X)}
\NormalTok{lin\_reg\_2 }\OperatorTok{=}\NormalTok{ LinearRegression()}
\NormalTok{lin\_reg\_2.fit(X\_poly, y)}
\CommentTok{\#\# LinearRegression()}
\end{Highlighting}
\end{Shaded}

R

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{dataset}\SpecialCharTok{$}\NormalTok{Level2 }\OtherTok{=}\NormalTok{ dataset}\SpecialCharTok{$}\NormalTok{Level}\SpecialCharTok{\^{}}\DecValTok{2}
\NormalTok{dataset}\SpecialCharTok{$}\NormalTok{Level3 }\OtherTok{=}\NormalTok{ dataset}\SpecialCharTok{$}\NormalTok{Level}\SpecialCharTok{\^{}}\DecValTok{3}
\NormalTok{dataset}\SpecialCharTok{$}\NormalTok{Level4 }\OtherTok{=}\NormalTok{ dataset}\SpecialCharTok{$}\NormalTok{Level}\SpecialCharTok{\^{}}\DecValTok{4}
\NormalTok{poly\_reg }\OtherTok{=} \FunctionTok{lm}\NormalTok{(}\AttributeTok{formula =}\NormalTok{ Salary }\SpecialCharTok{\textasciitilde{}}\NormalTok{ .,}
              \AttributeTok{data =}\NormalTok{ dataset)}
\end{Highlighting}
\end{Shaded}

\hypertarget{visualising-the-linear-regression-results}{%
\subsection{Visualising the Linear Regression results}\label{visualising-the-linear-regression-results}}

Python

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{plt.scatter(X, y, color }\OperatorTok{=} \StringTok{\textquotesingle{}red\textquotesingle{}}\NormalTok{)}
\NormalTok{plt.plot(X, lin\_reg.predict(X), color }\OperatorTok{=} \StringTok{\textquotesingle{}blue\textquotesingle{}}\NormalTok{)}
\NormalTok{plt.title(}\StringTok{\textquotesingle{}Truth or Bluff (Linear Regression)\textquotesingle{}}\NormalTok{)}
\NormalTok{plt.xlabel(}\StringTok{\textquotesingle{}Position Level\textquotesingle{}}\NormalTok{)}
\NormalTok{plt.ylabel(}\StringTok{\textquotesingle{}Salary\textquotesingle{}}\NormalTok{)}
\NormalTok{plt.show()}
\end{Highlighting}
\end{Shaded}

\includegraphics{_main_files/figure-latex/unnamed-chunk-43-1.pdf}

R

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\# install.packages(\textquotesingle{}ggplot2\textquotesingle{})}
\FunctionTok{library}\NormalTok{(ggplot2)}
\FunctionTok{ggplot}\NormalTok{() }\SpecialCharTok{+}
  \FunctionTok{geom\_point}\NormalTok{(}\FunctionTok{aes}\NormalTok{(}\AttributeTok{x =}\NormalTok{ dataset}\SpecialCharTok{$}\NormalTok{Level, }\AttributeTok{y =}\NormalTok{ dataset}\SpecialCharTok{$}\NormalTok{Salary),}
             \AttributeTok{colour =} \StringTok{\textquotesingle{}red\textquotesingle{}}\NormalTok{) }\SpecialCharTok{+}
  \FunctionTok{geom\_line}\NormalTok{(}\FunctionTok{aes}\NormalTok{(}\AttributeTok{x =}\NormalTok{ dataset}\SpecialCharTok{$}\NormalTok{Level, }\AttributeTok{y =} \FunctionTok{predict}\NormalTok{(lin\_reg, }\AttributeTok{newdata =}\NormalTok{ dataset)),}
            \AttributeTok{colour =} \StringTok{\textquotesingle{}blue\textquotesingle{}}\NormalTok{) }\SpecialCharTok{+}
  \FunctionTok{ggtitle}\NormalTok{(}\StringTok{\textquotesingle{}Truth or Bluff (Linear Regression)\textquotesingle{}}\NormalTok{) }\SpecialCharTok{+}
  \FunctionTok{xlab}\NormalTok{(}\StringTok{\textquotesingle{}Level\textquotesingle{}}\NormalTok{) }\SpecialCharTok{+}
  \FunctionTok{ylab}\NormalTok{(}\StringTok{\textquotesingle{}Salary\textquotesingle{}}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\includegraphics{_main_files/figure-latex/unnamed-chunk-44-3.pdf}

\hypertarget{visualising-the-polynomial-regression-results}{%
\subsection{Visualising the Polynomial Regression results}\label{visualising-the-polynomial-regression-results}}

Python

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{plt.scatter(X, y, color }\OperatorTok{=} \StringTok{\textquotesingle{}red\textquotesingle{}}\NormalTok{)}
\NormalTok{plt.plot(X, lin\_reg\_2.predict(poly\_reg.fit\_transform(X)), color }\OperatorTok{=} \StringTok{\textquotesingle{}blue\textquotesingle{}}\NormalTok{)}
\NormalTok{plt.title(}\StringTok{\textquotesingle{}Truth or Bluff (Polynomial Regression)\textquotesingle{}}\NormalTok{)}
\NormalTok{plt.xlabel(}\StringTok{\textquotesingle{}Position level\textquotesingle{}}\NormalTok{)}
\NormalTok{plt.ylabel(}\StringTok{\textquotesingle{}Salary\textquotesingle{}}\NormalTok{)}
\NormalTok{plt.show()}
\end{Highlighting}
\end{Shaded}

\includegraphics{_main_files/figure-latex/unnamed-chunk-45-1.pdf}

R

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\# install.packages(\textquotesingle{}ggplot2\textquotesingle{})}
\FunctionTok{library}\NormalTok{(ggplot2)}
\FunctionTok{ggplot}\NormalTok{() }\SpecialCharTok{+}
  \FunctionTok{geom\_point}\NormalTok{(}\FunctionTok{aes}\NormalTok{(}\AttributeTok{x =}\NormalTok{ dataset}\SpecialCharTok{$}\NormalTok{Level, }\AttributeTok{y =}\NormalTok{ dataset}\SpecialCharTok{$}\NormalTok{Salary),}
             \AttributeTok{colour =} \StringTok{\textquotesingle{}red\textquotesingle{}}\NormalTok{) }\SpecialCharTok{+}
  \FunctionTok{geom\_line}\NormalTok{(}\FunctionTok{aes}\NormalTok{(}\AttributeTok{x =}\NormalTok{ dataset}\SpecialCharTok{$}\NormalTok{Level, }\AttributeTok{y =} \FunctionTok{predict}\NormalTok{(poly\_reg, }\AttributeTok{newdata =}\NormalTok{ dataset)),}
            \AttributeTok{colour =} \StringTok{\textquotesingle{}blue\textquotesingle{}}\NormalTok{) }\SpecialCharTok{+}
  \FunctionTok{ggtitle}\NormalTok{(}\StringTok{\textquotesingle{}Truth or Bluff (Polynomial Regression)\textquotesingle{}}\NormalTok{) }\SpecialCharTok{+}
  \FunctionTok{xlab}\NormalTok{(}\StringTok{\textquotesingle{}Level\textquotesingle{}}\NormalTok{) }\SpecialCharTok{+}
  \FunctionTok{ylab}\NormalTok{(}\StringTok{\textquotesingle{}Salary\textquotesingle{}}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\includegraphics{_main_files/figure-latex/unnamed-chunk-46-3.pdf}

\hypertarget{visualising-the-polynomial-regression-results-for-higher-resolution-and-smoother-curve}{%
\subsection{Visualising the Polynomial Regression results (for higher resolution and smoother curve)}\label{visualising-the-polynomial-regression-results-for-higher-resolution-and-smoother-curve}}

Python

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{X\_grid }\OperatorTok{=}\NormalTok{ np.arange(}\BuiltInTok{min}\NormalTok{(X), }\BuiltInTok{max}\NormalTok{(X), }\FloatTok{0.1}\NormalTok{)}
\NormalTok{X\_grid }\OperatorTok{=}\NormalTok{ X\_grid.reshape((}\BuiltInTok{len}\NormalTok{(X\_grid), }\DecValTok{1}\NormalTok{))}
\NormalTok{plt.scatter(X, y, color }\OperatorTok{=} \StringTok{\textquotesingle{}red\textquotesingle{}}\NormalTok{)}
\NormalTok{plt.plot(X\_grid, lin\_reg\_2.predict(poly\_reg.fit\_transform(X\_grid)), color }\OperatorTok{=} \StringTok{\textquotesingle{}blue\textquotesingle{}}\NormalTok{)}
\NormalTok{plt.title(}\StringTok{\textquotesingle{}Truth or Bluff (Polynomial Regression)\textquotesingle{}}\NormalTok{)}
\NormalTok{plt.xlabel(}\StringTok{\textquotesingle{}Position level\textquotesingle{}}\NormalTok{)}
\NormalTok{plt.ylabel(}\StringTok{\textquotesingle{}Salary\textquotesingle{}}\NormalTok{)}
\NormalTok{plt.show()}
\end{Highlighting}
\end{Shaded}

\includegraphics{_main_files/figure-latex/unnamed-chunk-47-1.pdf}

R

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\# install.packages(\textquotesingle{}ggplot2\textquotesingle{})}
\FunctionTok{library}\NormalTok{(ggplot2)}
\NormalTok{x\_grid }\OtherTok{=} \FunctionTok{seq}\NormalTok{(}\FunctionTok{min}\NormalTok{(dataset}\SpecialCharTok{$}\NormalTok{Level), }\FunctionTok{max}\NormalTok{(dataset}\SpecialCharTok{$}\NormalTok{Level), }\FloatTok{0.1}\NormalTok{)}
\FunctionTok{ggplot}\NormalTok{() }\SpecialCharTok{+}
  \FunctionTok{geom\_point}\NormalTok{(}\FunctionTok{aes}\NormalTok{(}\AttributeTok{x =}\NormalTok{ dataset}\SpecialCharTok{$}\NormalTok{Level, }\AttributeTok{y =}\NormalTok{ dataset}\SpecialCharTok{$}\NormalTok{Salary),}
             \AttributeTok{colour =} \StringTok{\textquotesingle{}red\textquotesingle{}}\NormalTok{) }\SpecialCharTok{+}
  \FunctionTok{geom\_line}\NormalTok{(}\FunctionTok{aes}\NormalTok{(}\AttributeTok{x =}\NormalTok{ x\_grid, }\AttributeTok{y =} \FunctionTok{predict}\NormalTok{(poly\_reg,}
                                        \AttributeTok{newdata =} \FunctionTok{data.frame}\NormalTok{(}\AttributeTok{Level =}\NormalTok{ x\_grid,}
                                                             \AttributeTok{Level2 =}\NormalTok{ x\_grid}\SpecialCharTok{\^{}}\DecValTok{2}\NormalTok{,}
                                                             \AttributeTok{Level3 =}\NormalTok{ x\_grid}\SpecialCharTok{\^{}}\DecValTok{3}\NormalTok{,}
                                                             \AttributeTok{Level4 =}\NormalTok{ x\_grid}\SpecialCharTok{\^{}}\DecValTok{4}\NormalTok{))),}
            \AttributeTok{colour =} \StringTok{\textquotesingle{}blue\textquotesingle{}}\NormalTok{) }\SpecialCharTok{+}
  \FunctionTok{ggtitle}\NormalTok{(}\StringTok{\textquotesingle{}Truth or Bluff (Polynomial Regression)\textquotesingle{}}\NormalTok{) }\SpecialCharTok{+}
  \FunctionTok{xlab}\NormalTok{(}\StringTok{\textquotesingle{}Level\textquotesingle{}}\NormalTok{) }\SpecialCharTok{+}
  \FunctionTok{ylab}\NormalTok{(}\StringTok{\textquotesingle{}Salary\textquotesingle{}}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\includegraphics{_main_files/figure-latex/unnamed-chunk-48-3.pdf}

\hypertarget{predicting-a-new-result-with-linear-regression}{%
\subsection{Predicting a new result with Linear Regression}\label{predicting-a-new-result-with-linear-regression}}

Python

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{lin\_reg.predict([[}\FloatTok{6.5}\NormalTok{]])}
\CommentTok{\#\# array([330378.79])}
\end{Highlighting}
\end{Shaded}

R

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{predict}\NormalTok{(lin\_reg, }\FunctionTok{data.frame}\NormalTok{(}\AttributeTok{Level =} \FloatTok{6.5}\NormalTok{))}
\DocumentationTok{\#\#        1 }
\DocumentationTok{\#\# 330378.8}
\end{Highlighting}
\end{Shaded}

\hypertarget{predicting-a-new-result-with-polynomial-regression}{%
\subsection{Predicting a new result with Polynomial Regression}\label{predicting-a-new-result-with-polynomial-regression}}

Python

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{lin\_reg\_2.predict(poly\_reg.fit\_transform([[}\FloatTok{6.5}\NormalTok{]]))}
\CommentTok{\#\# array([158862.45])}
\end{Highlighting}
\end{Shaded}

R

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{predict}\NormalTok{(poly\_reg, }\FunctionTok{data.frame}\NormalTok{(}\AttributeTok{Level =} \FloatTok{6.5}\NormalTok{,}
                             \AttributeTok{Level2 =} \FloatTok{6.5}\SpecialCharTok{\^{}}\DecValTok{2}\NormalTok{,}
                             \AttributeTok{Level3 =} \FloatTok{6.5}\SpecialCharTok{\^{}}\DecValTok{3}\NormalTok{,}
                             \AttributeTok{Level4 =} \FloatTok{6.5}\SpecialCharTok{\^{}}\DecValTok{4}\NormalTok{))}
\DocumentationTok{\#\#        1 }
\DocumentationTok{\#\# 158862.5}
\end{Highlighting}
\end{Shaded}

\hypertarget{support-vector-regression}{%
\section{Support Vector Regression}\label{support-vector-regression}}

\hypertarget{importing-the-libraries-4}{%
\subsection{Importing the libraries}\label{importing-the-libraries-4}}

Python

\begin{Shaded}
\begin{Highlighting}[]
\ImportTok{import}\NormalTok{ numpy }\ImportTok{as}\NormalTok{ np}
\ImportTok{import}\NormalTok{ matplotlib.pyplot }\ImportTok{as}\NormalTok{ plt}
\ImportTok{import}\NormalTok{ pandas }\ImportTok{as}\NormalTok{ pd}
\end{Highlighting}
\end{Shaded}

\hypertarget{importing-the-dataset-4}{%
\subsection{Importing the dataset}\label{importing-the-dataset-4}}

Python

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{dataset }\OperatorTok{=}\NormalTok{ pd.read\_csv(}\StringTok{\textquotesingle{}Position\_Salaries.csv\textquotesingle{}}\NormalTok{)}
\NormalTok{X }\OperatorTok{=}\NormalTok{ dataset.iloc[:, }\DecValTok{1}\NormalTok{:}\OperatorTok{{-}}\DecValTok{1}\NormalTok{].values}
\NormalTok{y }\OperatorTok{=}\NormalTok{ dataset.iloc[:, }\OperatorTok{{-}}\DecValTok{1}\NormalTok{].values}
\BuiltInTok{print}\NormalTok{(X)}
\CommentTok{\#\# [[ 1]}
\CommentTok{\#\#  [ 2]}
\CommentTok{\#\#  [ 3]}
\CommentTok{\#\#  [ 4]}
\CommentTok{\#\#  [ 5]}
\CommentTok{\#\#  [ 6]}
\CommentTok{\#\#  [ 7]}
\CommentTok{\#\#  [ 8]}
\CommentTok{\#\#  [ 9]}
\CommentTok{\#\#  [10]]}
\BuiltInTok{print}\NormalTok{(y)}
\CommentTok{\#\# [  45000   50000   60000   80000  110000  150000  200000  300000  500000}
\CommentTok{\#\#  1000000]}
\NormalTok{y }\OperatorTok{=}\NormalTok{ y.reshape(}\BuiltInTok{len}\NormalTok{(y),}\DecValTok{1}\NormalTok{)}
\BuiltInTok{print}\NormalTok{(y)}
\CommentTok{\#\# [[  45000]}
\CommentTok{\#\#  [  50000]}
\CommentTok{\#\#  [  60000]}
\CommentTok{\#\#  [  80000]}
\CommentTok{\#\#  [ 110000]}
\CommentTok{\#\#  [ 150000]}
\CommentTok{\#\#  [ 200000]}
\CommentTok{\#\#  [ 300000]}
\CommentTok{\#\#  [ 500000]}
\CommentTok{\#\#  [1000000]]}
\end{Highlighting}
\end{Shaded}

R

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{dataset }\OtherTok{=} \FunctionTok{read.csv}\NormalTok{(}\StringTok{\textquotesingle{}Position\_Salaries.csv\textquotesingle{}}\NormalTok{)}
\NormalTok{dataset }\OtherTok{=}\NormalTok{ dataset[}\DecValTok{2}\SpecialCharTok{:}\DecValTok{3}\NormalTok{]}
\end{Highlighting}
\end{Shaded}

\hypertarget{feature-scaling-1}{%
\subsection{Feature Scaling}\label{feature-scaling-1}}

Python

\begin{Shaded}
\begin{Highlighting}[]
\ImportTok{from}\NormalTok{ sklearn.preprocessing }\ImportTok{import}\NormalTok{ StandardScaler}
\NormalTok{sc\_X }\OperatorTok{=}\NormalTok{ StandardScaler()}
\NormalTok{sc\_y }\OperatorTok{=}\NormalTok{ StandardScaler()}
\NormalTok{X }\OperatorTok{=}\NormalTok{ sc\_X.fit\_transform(X)}
\NormalTok{y }\OperatorTok{=}\NormalTok{ sc\_y.fit\_transform(y)}
\BuiltInTok{print}\NormalTok{(X)}
\CommentTok{\#\# [[{-}1.57]}
\CommentTok{\#\#  [{-}1.22]}
\CommentTok{\#\#  [{-}0.87]}
\CommentTok{\#\#  [{-}0.52]}
\CommentTok{\#\#  [{-}0.17]}
\CommentTok{\#\#  [ 0.17]}
\CommentTok{\#\#  [ 0.52]}
\CommentTok{\#\#  [ 0.87]}
\CommentTok{\#\#  [ 1.22]}
\CommentTok{\#\#  [ 1.57]]}
\BuiltInTok{print}\NormalTok{(y)}
\CommentTok{\#\# [[{-}0.72]}
\CommentTok{\#\#  [{-}0.7 ]}
\CommentTok{\#\#  [{-}0.67]}
\CommentTok{\#\#  [{-}0.6 ]}
\CommentTok{\#\#  [{-}0.49]}
\CommentTok{\#\#  [{-}0.35]}
\CommentTok{\#\#  [{-}0.17]}
\CommentTok{\#\#  [ 0.18]}
\CommentTok{\#\#  [ 0.88]}
\CommentTok{\#\#  [ 2.64]]}
\end{Highlighting}
\end{Shaded}

R

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\# training\_set = scale(training\_set)}
\CommentTok{\# test\_set = scale(test\_set)}
\end{Highlighting}
\end{Shaded}

\hypertarget{training-the-svr-model-on-the-whole-dataset}{%
\subsection{Training the SVR model on the whole dataset}\label{training-the-svr-model-on-the-whole-dataset}}

Python

\begin{Shaded}
\begin{Highlighting}[]
\ImportTok{from}\NormalTok{ sklearn.svm }\ImportTok{import}\NormalTok{ SVR}
\NormalTok{regressor }\OperatorTok{=}\NormalTok{ SVR(kernel }\OperatorTok{=} \StringTok{\textquotesingle{}rbf\textquotesingle{}}\NormalTok{)}
\NormalTok{regressor.fit(X, y)}
\CommentTok{\#\# SVR()}
\CommentTok{\#\# }
\CommentTok{\#\# C:\textbackslash{}Users\textbackslash{}murph\textbackslash{}mambaforge\textbackslash{}lib\textbackslash{}site{-}packages\textbackslash{}sklearn\textbackslash{}utils\textbackslash{}validation.py:63: DataConversionWarning: A column{-}vector y was passed when a 1d array was expected. Please change the shape of y to (n\_samples, ), for example using ravel().}
\CommentTok{\#\#   return f(*args, **kwargs)}
\end{Highlighting}
\end{Shaded}

R

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\# install.packages(\textquotesingle{}e1071\textquotesingle{})}
\FunctionTok{library}\NormalTok{(e1071)}
\NormalTok{regressor }\OtherTok{=} \FunctionTok{svm}\NormalTok{(}\AttributeTok{formula =}\NormalTok{ Salary }\SpecialCharTok{\textasciitilde{}}\NormalTok{ .,}
                \AttributeTok{data =}\NormalTok{ dataset,}
                \AttributeTok{type =} \StringTok{\textquotesingle{}eps{-}regression\textquotesingle{}}\NormalTok{,}
                \AttributeTok{kernel =} \StringTok{\textquotesingle{}radial\textquotesingle{}}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\hypertarget{predicting-a-new-result}{%
\subsection{Predicting a new result}\label{predicting-a-new-result}}

Python

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{sc\_y.inverse\_transform(regressor.predict(sc\_X.transform([[}\FloatTok{6.5}\NormalTok{]])))}
\CommentTok{\#\# array([170370.02])}
\end{Highlighting}
\end{Shaded}

R

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{y\_pred }\OtherTok{=} \FunctionTok{predict}\NormalTok{(regressor, }\FunctionTok{data.frame}\NormalTok{(}\AttributeTok{Level =} \FloatTok{6.5}\NormalTok{))}
\end{Highlighting}
\end{Shaded}

\hypertarget{visualising-the-svr-results}{%
\subsection{Visualising the SVR results}\label{visualising-the-svr-results}}

Python

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{plt.scatter(sc\_X.inverse\_transform(X), sc\_y.inverse\_transform(y), color }\OperatorTok{=} \StringTok{\textquotesingle{}red\textquotesingle{}}\NormalTok{)}
\NormalTok{plt.plot(sc\_X.inverse\_transform(X), sc\_y.inverse\_transform(regressor.predict(X)), color }\OperatorTok{=} \StringTok{\textquotesingle{}blue\textquotesingle{}}\NormalTok{)}
\NormalTok{plt.title(}\StringTok{\textquotesingle{}Truth or Bluff (SVR)\textquotesingle{}}\NormalTok{)}
\NormalTok{plt.xlabel(}\StringTok{\textquotesingle{}Position level\textquotesingle{}}\NormalTok{)}
\NormalTok{plt.ylabel(}\StringTok{\textquotesingle{}Salary\textquotesingle{}}\NormalTok{)}
\NormalTok{plt.show()}
\end{Highlighting}
\end{Shaded}

\includegraphics{_main_files/figure-latex/unnamed-chunk-62-1.pdf}

R

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\# install.packages(\textquotesingle{}ggplot2\textquotesingle{})}
\FunctionTok{library}\NormalTok{(ggplot2)}
\FunctionTok{ggplot}\NormalTok{() }\SpecialCharTok{+}
  \FunctionTok{geom\_point}\NormalTok{(}\FunctionTok{aes}\NormalTok{(}\AttributeTok{x =}\NormalTok{ dataset}\SpecialCharTok{$}\NormalTok{Level, }\AttributeTok{y =}\NormalTok{ dataset}\SpecialCharTok{$}\NormalTok{Salary),}
             \AttributeTok{colour =} \StringTok{\textquotesingle{}red\textquotesingle{}}\NormalTok{) }\SpecialCharTok{+}
  \FunctionTok{geom\_line}\NormalTok{(}\FunctionTok{aes}\NormalTok{(}\AttributeTok{x =}\NormalTok{ dataset}\SpecialCharTok{$}\NormalTok{Level, }\AttributeTok{y =} \FunctionTok{predict}\NormalTok{(regressor, }\AttributeTok{newdata =}\NormalTok{ dataset)),}
            \AttributeTok{colour =} \StringTok{\textquotesingle{}blue\textquotesingle{}}\NormalTok{) }\SpecialCharTok{+}
  \FunctionTok{ggtitle}\NormalTok{(}\StringTok{\textquotesingle{}Truth or Bluff (SVR)\textquotesingle{}}\NormalTok{) }\SpecialCharTok{+}
  \FunctionTok{xlab}\NormalTok{(}\StringTok{\textquotesingle{}Level\textquotesingle{}}\NormalTok{) }\SpecialCharTok{+}
  \FunctionTok{ylab}\NormalTok{(}\StringTok{\textquotesingle{}Salary\textquotesingle{}}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\includegraphics{_main_files/figure-latex/unnamed-chunk-63-3.pdf}

\hypertarget{visualising-the-svr-results-for-higher-resolution-and-smoother-curve}{%
\subsection{Visualising the SVR results (for higher resolution and smoother curve)}\label{visualising-the-svr-results-for-higher-resolution-and-smoother-curve}}

Python

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{X\_grid }\OperatorTok{=}\NormalTok{ np.arange(}\BuiltInTok{min}\NormalTok{(sc\_X.inverse\_transform(X)), }\BuiltInTok{max}\NormalTok{(sc\_X.inverse\_transform(X)), }\FloatTok{0.1}\NormalTok{)}
\NormalTok{X\_grid }\OperatorTok{=}\NormalTok{ X\_grid.reshape((}\BuiltInTok{len}\NormalTok{(X\_grid), }\DecValTok{1}\NormalTok{))}
\NormalTok{plt.scatter(sc\_X.inverse\_transform(X), sc\_y.inverse\_transform(y), color }\OperatorTok{=} \StringTok{\textquotesingle{}red\textquotesingle{}}\NormalTok{)}
\NormalTok{plt.plot(X\_grid, sc\_y.inverse\_transform(regressor.predict(sc\_X.transform(X\_grid))), color }\OperatorTok{=} \StringTok{\textquotesingle{}blue\textquotesingle{}}\NormalTok{)}
\NormalTok{plt.title(}\StringTok{\textquotesingle{}Truth or Bluff (SVR)\textquotesingle{}}\NormalTok{)}
\NormalTok{plt.xlabel(}\StringTok{\textquotesingle{}Position level\textquotesingle{}}\NormalTok{)}
\NormalTok{plt.ylabel(}\StringTok{\textquotesingle{}Salary\textquotesingle{}}\NormalTok{)}
\NormalTok{plt.show()}
\end{Highlighting}
\end{Shaded}

\includegraphics{_main_files/figure-latex/unnamed-chunk-64-1.pdf}

R

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\# install.packages(\textquotesingle{}ggplot2\textquotesingle{})}
\FunctionTok{library}\NormalTok{(ggplot2)}
\NormalTok{x\_grid }\OtherTok{=} \FunctionTok{seq}\NormalTok{(}\FunctionTok{min}\NormalTok{(dataset}\SpecialCharTok{$}\NormalTok{Level), }\FunctionTok{max}\NormalTok{(dataset}\SpecialCharTok{$}\NormalTok{Level), }\FloatTok{0.1}\NormalTok{)}
\FunctionTok{ggplot}\NormalTok{() }\SpecialCharTok{+}
  \FunctionTok{geom\_point}\NormalTok{(}\FunctionTok{aes}\NormalTok{(}\AttributeTok{x =}\NormalTok{ dataset}\SpecialCharTok{$}\NormalTok{Level, }\AttributeTok{y =}\NormalTok{ dataset}\SpecialCharTok{$}\NormalTok{Salary),}
             \AttributeTok{colour =} \StringTok{\textquotesingle{}red\textquotesingle{}}\NormalTok{) }\SpecialCharTok{+}
  \FunctionTok{geom\_line}\NormalTok{(}\FunctionTok{aes}\NormalTok{(}\AttributeTok{x =}\NormalTok{ x\_grid, }\AttributeTok{y =} \FunctionTok{predict}\NormalTok{(regressor, }\AttributeTok{newdata =} \FunctionTok{data.frame}\NormalTok{(}\AttributeTok{Level =}\NormalTok{ x\_grid))),}
            \AttributeTok{colour =} \StringTok{\textquotesingle{}blue\textquotesingle{}}\NormalTok{) }\SpecialCharTok{+}
  \FunctionTok{ggtitle}\NormalTok{(}\StringTok{\textquotesingle{}Truth or Bluff (SVR)\textquotesingle{}}\NormalTok{) }\SpecialCharTok{+}
  \FunctionTok{xlab}\NormalTok{(}\StringTok{\textquotesingle{}Level\textquotesingle{}}\NormalTok{) }\SpecialCharTok{+}
  \FunctionTok{ylab}\NormalTok{(}\StringTok{\textquotesingle{}Salary\textquotesingle{}}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\includegraphics{_main_files/figure-latex/unnamed-chunk-65-3.pdf}

\hypertarget{decision-tree-regression}{%
\section{Decision Tree Regression}\label{decision-tree-regression}}

\hypertarget{importing-the-libraries-5}{%
\subsection{Importing the libraries}\label{importing-the-libraries-5}}

Python

\begin{Shaded}
\begin{Highlighting}[]
\ImportTok{import}\NormalTok{ numpy }\ImportTok{as}\NormalTok{ np}
\ImportTok{import}\NormalTok{ matplotlib.pyplot }\ImportTok{as}\NormalTok{ plt}
\ImportTok{import}\NormalTok{ pandas }\ImportTok{as}\NormalTok{ pd}
\end{Highlighting}
\end{Shaded}

\hypertarget{importing-the-dataset-5}{%
\subsection{Importing the dataset}\label{importing-the-dataset-5}}

Python

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{dataset }\OperatorTok{=}\NormalTok{ pd.read\_csv(}\StringTok{\textquotesingle{}Position\_Salaries.csv\textquotesingle{}}\NormalTok{)}
\NormalTok{X }\OperatorTok{=}\NormalTok{ dataset.iloc[:, }\DecValTok{1}\NormalTok{:}\OperatorTok{{-}}\DecValTok{1}\NormalTok{].values}
\NormalTok{y }\OperatorTok{=}\NormalTok{ dataset.iloc[:, }\OperatorTok{{-}}\DecValTok{1}\NormalTok{].values}
\end{Highlighting}
\end{Shaded}

R

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{dataset }\OtherTok{=} \FunctionTok{read.csv}\NormalTok{(}\StringTok{\textquotesingle{}Position\_Salaries.csv\textquotesingle{}}\NormalTok{)}
\NormalTok{dataset }\OtherTok{=}\NormalTok{ dataset[}\DecValTok{2}\SpecialCharTok{:}\DecValTok{3}\NormalTok{]}
\end{Highlighting}
\end{Shaded}

\hypertarget{training-the-decision-tree-regression-model-on-the-whole-dataset}{%
\subsection{Training the Decision Tree Regression model on the whole dataset}\label{training-the-decision-tree-regression-model-on-the-whole-dataset}}

Python

\begin{Shaded}
\begin{Highlighting}[]
\ImportTok{from}\NormalTok{ sklearn.tree }\ImportTok{import}\NormalTok{ DecisionTreeRegressor}
\NormalTok{regressor }\OperatorTok{=}\NormalTok{ DecisionTreeRegressor(random\_state }\OperatorTok{=} \DecValTok{0}\NormalTok{)}
\NormalTok{regressor.fit(X, y)}
\CommentTok{\#\# DecisionTreeRegressor(random\_state=0)}
\end{Highlighting}
\end{Shaded}

R

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\# install.packages(\textquotesingle{}rpart\textquotesingle{})}
\FunctionTok{library}\NormalTok{(rpart)}
\NormalTok{regressor }\OtherTok{=} \FunctionTok{rpart}\NormalTok{(}\AttributeTok{formula =}\NormalTok{ Salary }\SpecialCharTok{\textasciitilde{}}\NormalTok{ .,}
                  \AttributeTok{data =}\NormalTok{ dataset,}
                  \AttributeTok{control =} \FunctionTok{rpart.control}\NormalTok{(}\AttributeTok{minsplit =} \DecValTok{1}\NormalTok{))}
\end{Highlighting}
\end{Shaded}

\hypertarget{predicting-a-new-result-1}{%
\subsection{Predicting a new result}\label{predicting-a-new-result-1}}

Python

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{regressor.predict([[}\FloatTok{6.5}\NormalTok{]])}
\CommentTok{\#\# array([150000.])}
\end{Highlighting}
\end{Shaded}

R

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{y\_pred }\OtherTok{=} \FunctionTok{predict}\NormalTok{(regressor, }\FunctionTok{data.frame}\NormalTok{(}\AttributeTok{Level =} \FloatTok{6.5}\NormalTok{))}
\end{Highlighting}
\end{Shaded}

\hypertarget{visualising-the-decision-tree-regression-results-higher-resolution}{%
\subsection{Visualising the Decision Tree Regression results (higher resolution)}\label{visualising-the-decision-tree-regression-results-higher-resolution}}

Python

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{X\_grid }\OperatorTok{=}\NormalTok{ np.arange(}\BuiltInTok{min}\NormalTok{(X), }\BuiltInTok{max}\NormalTok{(X), }\FloatTok{0.01}\NormalTok{)}
\NormalTok{X\_grid }\OperatorTok{=}\NormalTok{ X\_grid.reshape((}\BuiltInTok{len}\NormalTok{(X\_grid), }\DecValTok{1}\NormalTok{))}
\NormalTok{plt.scatter(X, y, color }\OperatorTok{=} \StringTok{\textquotesingle{}red\textquotesingle{}}\NormalTok{)}
\NormalTok{plt.plot(X\_grid, regressor.predict(X\_grid), color }\OperatorTok{=} \StringTok{\textquotesingle{}blue\textquotesingle{}}\NormalTok{)}
\NormalTok{plt.title(}\StringTok{\textquotesingle{}Truth or Bluff (Decision Tree Regression)\textquotesingle{}}\NormalTok{)}
\NormalTok{plt.xlabel(}\StringTok{\textquotesingle{}Position level\textquotesingle{}}\NormalTok{)}
\NormalTok{plt.ylabel(}\StringTok{\textquotesingle{}Salary\textquotesingle{}}\NormalTok{)}
\NormalTok{plt.show()}
\end{Highlighting}
\end{Shaded}

\includegraphics{_main_files/figure-latex/unnamed-chunk-73-1.pdf}

R

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\# install.packages(\textquotesingle{}ggplot2\textquotesingle{})}
\FunctionTok{library}\NormalTok{(ggplot2)}
\NormalTok{x\_grid }\OtherTok{=} \FunctionTok{seq}\NormalTok{(}\FunctionTok{min}\NormalTok{(dataset}\SpecialCharTok{$}\NormalTok{Level), }\FunctionTok{max}\NormalTok{(dataset}\SpecialCharTok{$}\NormalTok{Level), }\FloatTok{0.01}\NormalTok{)}
\FunctionTok{ggplot}\NormalTok{() }\SpecialCharTok{+}
  \FunctionTok{geom\_point}\NormalTok{(}\FunctionTok{aes}\NormalTok{(}\AttributeTok{x =}\NormalTok{ dataset}\SpecialCharTok{$}\NormalTok{Level, }\AttributeTok{y =}\NormalTok{ dataset}\SpecialCharTok{$}\NormalTok{Salary),}
             \AttributeTok{colour =} \StringTok{\textquotesingle{}red\textquotesingle{}}\NormalTok{) }\SpecialCharTok{+}
  \FunctionTok{geom\_line}\NormalTok{(}\FunctionTok{aes}\NormalTok{(}\AttributeTok{x =}\NormalTok{ x\_grid, }\AttributeTok{y =} \FunctionTok{predict}\NormalTok{(regressor, }\AttributeTok{newdata =} \FunctionTok{data.frame}\NormalTok{(}\AttributeTok{Level =}\NormalTok{ x\_grid))),}
            \AttributeTok{colour =} \StringTok{\textquotesingle{}blue\textquotesingle{}}\NormalTok{) }\SpecialCharTok{+}
  \FunctionTok{ggtitle}\NormalTok{(}\StringTok{\textquotesingle{}Truth or Bluff (Decision Tree Regression)\textquotesingle{}}\NormalTok{) }\SpecialCharTok{+}
  \FunctionTok{xlab}\NormalTok{(}\StringTok{\textquotesingle{}Level\textquotesingle{}}\NormalTok{) }\SpecialCharTok{+}
  \FunctionTok{ylab}\NormalTok{(}\StringTok{\textquotesingle{}Salary\textquotesingle{}}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\includegraphics{_main_files/figure-latex/unnamed-chunk-74-3.pdf}

\hypertarget{plotting-the-tree}{%
\subsection{Plotting the tree}\label{plotting-the-tree}}

R

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{plot}\NormalTok{(regressor)}
\FunctionTok{text}\NormalTok{(regressor)}
\end{Highlighting}
\end{Shaded}

\includegraphics{_main_files/figure-latex/unnamed-chunk-75-1.pdf}

\hypertarget{random-forest-regression}{%
\section{Random Forest Regression}\label{random-forest-regression}}

\hypertarget{importing-the-libraries-6}{%
\subsection{Importing the libraries}\label{importing-the-libraries-6}}

Python

\begin{Shaded}
\begin{Highlighting}[]
\ImportTok{import}\NormalTok{ numpy }\ImportTok{as}\NormalTok{ np}
\ImportTok{import}\NormalTok{ matplotlib.pyplot }\ImportTok{as}\NormalTok{ plt}
\ImportTok{import}\NormalTok{ pandas }\ImportTok{as}\NormalTok{ pd}
\end{Highlighting}
\end{Shaded}

\hypertarget{importing-the-dataset-6}{%
\subsection{Importing the dataset}\label{importing-the-dataset-6}}

Python

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{dataset }\OperatorTok{=}\NormalTok{ pd.read\_csv(}\StringTok{\textquotesingle{}Position\_Salaries.csv\textquotesingle{}}\NormalTok{)}
\NormalTok{X }\OperatorTok{=}\NormalTok{ dataset.iloc[:, }\DecValTok{1}\NormalTok{:}\OperatorTok{{-}}\DecValTok{1}\NormalTok{].values}
\NormalTok{y }\OperatorTok{=}\NormalTok{ dataset.iloc[:, }\OperatorTok{{-}}\DecValTok{1}\NormalTok{].values}
\end{Highlighting}
\end{Shaded}

R

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{dataset }\OtherTok{=} \FunctionTok{read.csv}\NormalTok{(}\StringTok{\textquotesingle{}Position\_Salaries.csv\textquotesingle{}}\NormalTok{)}
\NormalTok{dataset }\OtherTok{=}\NormalTok{ dataset[}\DecValTok{2}\SpecialCharTok{:}\DecValTok{3}\NormalTok{]}
\end{Highlighting}
\end{Shaded}

\hypertarget{training-the-random-forest-regression-model-on-the-whole-dataset}{%
\subsection{Training the Random Forest Regression model on the whole dataset}\label{training-the-random-forest-regression-model-on-the-whole-dataset}}

Python

\begin{Shaded}
\begin{Highlighting}[]
\ImportTok{from}\NormalTok{ sklearn.ensemble }\ImportTok{import}\NormalTok{ RandomForestRegressor}
\NormalTok{regressor }\OperatorTok{=}\NormalTok{ RandomForestRegressor(n\_estimators }\OperatorTok{=} \DecValTok{10}\NormalTok{, random\_state }\OperatorTok{=} \DecValTok{0}\NormalTok{)}
\NormalTok{regressor.fit(X, y)}
\CommentTok{\#\# RandomForestRegressor(n\_estimators=10, random\_state=0)}
\end{Highlighting}
\end{Shaded}

R

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\# install.packages(\textquotesingle{}randomForest\textquotesingle{})}
\FunctionTok{library}\NormalTok{(randomForest)}
\DocumentationTok{\#\# randomForest 4.6{-}14}
\DocumentationTok{\#\# Type rfNews() to see new features/changes/bug fixes.}
\DocumentationTok{\#\# }
\DocumentationTok{\#\# Attaching package: \textquotesingle{}randomForest\textquotesingle{}}
\DocumentationTok{\#\# The following object is masked from \textquotesingle{}package:ggplot2\textquotesingle{}:}
\DocumentationTok{\#\# }
\DocumentationTok{\#\#     margin}
\FunctionTok{set.seed}\NormalTok{(}\DecValTok{1234}\NormalTok{)}
\NormalTok{regressor }\OtherTok{=} \FunctionTok{randomForest}\NormalTok{(}\AttributeTok{x =}\NormalTok{ dataset[}\SpecialCharTok{{-}}\DecValTok{2}\NormalTok{],}
                         \AttributeTok{y =}\NormalTok{ dataset}\SpecialCharTok{$}\NormalTok{Salary,}
                         \AttributeTok{ntree =} \DecValTok{500}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\hypertarget{predicting-a-new-result-2}{%
\subsection{Predicting a new result}\label{predicting-a-new-result-2}}

Python

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{regressor.predict([[}\FloatTok{6.5}\NormalTok{]])}
\CommentTok{\#\# array([167000.])}
\end{Highlighting}
\end{Shaded}

R

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{y\_pred }\OtherTok{=} \FunctionTok{predict}\NormalTok{(regressor, }\FunctionTok{data.frame}\NormalTok{(}\AttributeTok{Level =} \FloatTok{6.5}\NormalTok{))}
\end{Highlighting}
\end{Shaded}

\hypertarget{visualising-the-random-forest-regression-results-higher-resolution}{%
\subsection{Visualising the Random Forest Regression results (higher resolution)}\label{visualising-the-random-forest-regression-results-higher-resolution}}

Python

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{X\_grid }\OperatorTok{=}\NormalTok{ np.arange(}\BuiltInTok{min}\NormalTok{(X), }\BuiltInTok{max}\NormalTok{(X), }\FloatTok{0.01}\NormalTok{)}
\NormalTok{X\_grid }\OperatorTok{=}\NormalTok{ X\_grid.reshape((}\BuiltInTok{len}\NormalTok{(X\_grid), }\DecValTok{1}\NormalTok{))}
\NormalTok{plt.scatter(X, y, color }\OperatorTok{=} \StringTok{\textquotesingle{}red\textquotesingle{}}\NormalTok{)}
\NormalTok{plt.plot(X\_grid, regressor.predict(X\_grid), color }\OperatorTok{=} \StringTok{\textquotesingle{}blue\textquotesingle{}}\NormalTok{)}
\NormalTok{plt.title(}\StringTok{\textquotesingle{}Truth or Bluff (Random Forest Regression)\textquotesingle{}}\NormalTok{)}
\NormalTok{plt.xlabel(}\StringTok{\textquotesingle{}Position level\textquotesingle{}}\NormalTok{)}
\NormalTok{plt.ylabel(}\StringTok{\textquotesingle{}Salary\textquotesingle{}}\NormalTok{)}
\NormalTok{plt.show()}
\end{Highlighting}
\end{Shaded}

\includegraphics{_main_files/figure-latex/unnamed-chunk-83-1.pdf}

R

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\# install.packages(\textquotesingle{}ggplot2\textquotesingle{})}
\FunctionTok{library}\NormalTok{(ggplot2)}
\NormalTok{x\_grid }\OtherTok{=} \FunctionTok{seq}\NormalTok{(}\FunctionTok{min}\NormalTok{(dataset}\SpecialCharTok{$}\NormalTok{Level), }\FunctionTok{max}\NormalTok{(dataset}\SpecialCharTok{$}\NormalTok{Level), }\FloatTok{0.01}\NormalTok{)}
\FunctionTok{ggplot}\NormalTok{() }\SpecialCharTok{+}
  \FunctionTok{geom\_point}\NormalTok{(}\FunctionTok{aes}\NormalTok{(}\AttributeTok{x =}\NormalTok{ dataset}\SpecialCharTok{$}\NormalTok{Level, }\AttributeTok{y =}\NormalTok{ dataset}\SpecialCharTok{$}\NormalTok{Salary),}
             \AttributeTok{colour =} \StringTok{\textquotesingle{}red\textquotesingle{}}\NormalTok{) }\SpecialCharTok{+}
  \FunctionTok{geom\_line}\NormalTok{(}\FunctionTok{aes}\NormalTok{(}\AttributeTok{x =}\NormalTok{ x\_grid, }\AttributeTok{y =} \FunctionTok{predict}\NormalTok{(regressor, }\AttributeTok{newdata =} \FunctionTok{data.frame}\NormalTok{(}\AttributeTok{Level =}\NormalTok{ x\_grid))),}
            \AttributeTok{colour =} \StringTok{\textquotesingle{}blue\textquotesingle{}}\NormalTok{) }\SpecialCharTok{+}
  \FunctionTok{ggtitle}\NormalTok{(}\StringTok{\textquotesingle{}Truth or Bluff (Random Forest Regression)\textquotesingle{}}\NormalTok{) }\SpecialCharTok{+}
  \FunctionTok{xlab}\NormalTok{(}\StringTok{\textquotesingle{}Level\textquotesingle{}}\NormalTok{) }\SpecialCharTok{+}
  \FunctionTok{ylab}\NormalTok{(}\StringTok{\textquotesingle{}Salary\textquotesingle{}}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\includegraphics{_main_files/figure-latex/unnamed-chunk-84-3.pdf}

\hypertarget{classification}{%
\chapter{Classification}\label{classification}}

\hypertarget{logistic-regression}{%
\section{Logistic Regression}\label{logistic-regression}}

\hypertarget{importing-the-libraries-7}{%
\subsection{Importing the libraries}\label{importing-the-libraries-7}}

Python

\begin{Shaded}
\begin{Highlighting}[]
\ImportTok{import}\NormalTok{ numpy }\ImportTok{as}\NormalTok{ np}
\ImportTok{import}\NormalTok{ matplotlib.pyplot }\ImportTok{as}\NormalTok{ plt}
\ImportTok{import}\NormalTok{ pandas }\ImportTok{as}\NormalTok{ pd}
\end{Highlighting}
\end{Shaded}

\hypertarget{importing-the-dataset-7}{%
\subsection{Importing the dataset}\label{importing-the-dataset-7}}

Python

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{dataset }\OperatorTok{=}\NormalTok{ pd.read\_csv(}\StringTok{\textquotesingle{}Social\_Network\_Ads.csv\textquotesingle{}}\NormalTok{)}
\NormalTok{X }\OperatorTok{=}\NormalTok{ dataset.iloc[:, :}\OperatorTok{{-}}\DecValTok{1}\NormalTok{].values}
\NormalTok{y }\OperatorTok{=}\NormalTok{ dataset.iloc[:, }\OperatorTok{{-}}\DecValTok{1}\NormalTok{].values}
\end{Highlighting}
\end{Shaded}

R

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{dataset }\OtherTok{=} \FunctionTok{read.csv}\NormalTok{(}\StringTok{\textquotesingle{}Social\_Network\_Ads.csv\textquotesingle{}}\NormalTok{)}
\CommentTok{\# dataset = dataset[3:5]}
\end{Highlighting}
\end{Shaded}

\hypertarget{encoding-the-target-feature-as-factor}{%
\subsection{Encoding the target feature as factor}\label{encoding-the-target-feature-as-factor}}

R

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{dataset}\SpecialCharTok{$}\NormalTok{Purchased }\OtherTok{=} \FunctionTok{factor}\NormalTok{(dataset}\SpecialCharTok{$}\NormalTok{Purchased, }\AttributeTok{levels =} \FunctionTok{c}\NormalTok{(}\DecValTok{0}\NormalTok{, }\DecValTok{1}\NormalTok{))}
\end{Highlighting}
\end{Shaded}

\hypertarget{splitting-the-dataset-into-the-training-set-and-test-set-3}{%
\subsection{Splitting the dataset into the Training set and Test set}\label{splitting-the-dataset-into-the-training-set-and-test-set-3}}

Python

\begin{Shaded}
\begin{Highlighting}[]
\ImportTok{from}\NormalTok{ sklearn.model\_selection }\ImportTok{import}\NormalTok{ train\_test\_split}
\NormalTok{X\_train, X\_test, y\_train, y\_test }\OperatorTok{=}\NormalTok{ train\_test\_split(X, y, test\_size }\OperatorTok{=} \FloatTok{0.25}\NormalTok{, random\_state }\OperatorTok{=} \DecValTok{0}\NormalTok{)}
\BuiltInTok{print}\NormalTok{(X\_train)}
\CommentTok{\#\# [[    44  39000]}
\CommentTok{\#\#  [    32 120000]}
\CommentTok{\#\#  [    38  50000]}
\CommentTok{\#\#  [    32 135000]}
\CommentTok{\#\#  [    52  21000]}
\CommentTok{\#\#  [    53 104000]}
\CommentTok{\#\#  [    39  42000]}
\CommentTok{\#\#  [    38  61000]}
\CommentTok{\#\#  [    36  50000]}
\CommentTok{\#\#  [    36  63000]}
\CommentTok{\#\#  [    35  25000]}
\CommentTok{\#\#  [    35  50000]}
\CommentTok{\#\#  [    42  73000]}
\CommentTok{\#\#  [    47  49000]}
\CommentTok{\#\#  [    59  29000]}
\CommentTok{\#\#  [    49  65000]}
\CommentTok{\#\#  [    45 131000]}
\CommentTok{\#\#  [    31  89000]}
\CommentTok{\#\#  [    46  82000]}
\CommentTok{\#\#  [    47  51000]}
\CommentTok{\#\#  [    26  15000]}
\CommentTok{\#\#  [    60 102000]}
\CommentTok{\#\#  [    38 112000]}
\CommentTok{\#\#  [    40 107000]}
\CommentTok{\#\#  [    42  53000]}
\CommentTok{\#\#  [    35  59000]}
\CommentTok{\#\#  [    48  41000]}
\CommentTok{\#\#  [    48 134000]}
\CommentTok{\#\#  [    38 113000]}
\CommentTok{\#\#  [    29 148000]}
\CommentTok{\#\#  [    26  15000]}
\CommentTok{\#\#  [    60  42000]}
\CommentTok{\#\#  [    24  19000]}
\CommentTok{\#\#  [    42 149000]}
\CommentTok{\#\#  [    46  96000]}
\CommentTok{\#\#  [    28  59000]}
\CommentTok{\#\#  [    39  96000]}
\CommentTok{\#\#  [    28  89000]}
\CommentTok{\#\#  [    41  72000]}
\CommentTok{\#\#  [    45  26000]}
\CommentTok{\#\#  [    33  69000]}
\CommentTok{\#\#  [    20  82000]}
\CommentTok{\#\#  [    31  74000]}
\CommentTok{\#\#  [    42  80000]}
\CommentTok{\#\#  [    35  72000]}
\CommentTok{\#\#  [    33 149000]}
\CommentTok{\#\#  [    40  71000]}
\CommentTok{\#\#  [    51 146000]}
\CommentTok{\#\#  [    46  79000]}
\CommentTok{\#\#  [    35  75000]}
\CommentTok{\#\#  [    38  51000]}
\CommentTok{\#\#  [    36  75000]}
\CommentTok{\#\#  [    37  78000]}
\CommentTok{\#\#  [    38  61000]}
\CommentTok{\#\#  [    60 108000]}
\CommentTok{\#\#  [    20  82000]}
\CommentTok{\#\#  [    57  74000]}
\CommentTok{\#\#  [    42  65000]}
\CommentTok{\#\#  [    26  80000]}
\CommentTok{\#\#  [    46 117000]}
\CommentTok{\#\#  [    35  61000]}
\CommentTok{\#\#  [    21  68000]}
\CommentTok{\#\#  [    28  44000]}
\CommentTok{\#\#  [    41  87000]}
\CommentTok{\#\#  [    37  33000]}
\CommentTok{\#\#  [    27  90000]}
\CommentTok{\#\#  [    39  42000]}
\CommentTok{\#\#  [    28 123000]}
\CommentTok{\#\#  [    31 118000]}
\CommentTok{\#\#  [    25  87000]}
\CommentTok{\#\#  [    35  71000]}
\CommentTok{\#\#  [    37  70000]}
\CommentTok{\#\#  [    35  39000]}
\CommentTok{\#\#  [    47  23000]}
\CommentTok{\#\#  [    35 147000]}
\CommentTok{\#\#  [    48 138000]}
\CommentTok{\#\#  [    26  86000]}
\CommentTok{\#\#  [    25  79000]}
\CommentTok{\#\#  [    52 138000]}
\CommentTok{\#\#  [    51  23000]}
\CommentTok{\#\#  [    35  60000]}
\CommentTok{\#\#  [    33 113000]}
\CommentTok{\#\#  [    30 107000]}
\CommentTok{\#\#  [    48  33000]}
\CommentTok{\#\#  [    41  80000]}
\CommentTok{\#\#  [    48  96000]}
\CommentTok{\#\#  [    31  18000]}
\CommentTok{\#\#  [    31  71000]}
\CommentTok{\#\#  [    43 129000]}
\CommentTok{\#\#  [    59  76000]}
\CommentTok{\#\#  [    18  44000]}
\CommentTok{\#\#  [    36 118000]}
\CommentTok{\#\#  [    42  90000]}
\CommentTok{\#\#  [    47  30000]}
\CommentTok{\#\#  [    26  43000]}
\CommentTok{\#\#  [    40  78000]}
\CommentTok{\#\#  [    46  59000]}
\CommentTok{\#\#  [    59  42000]}
\CommentTok{\#\#  [    46  74000]}
\CommentTok{\#\#  [    35  91000]}
\CommentTok{\#\#  [    28  59000]}
\CommentTok{\#\#  [    40  57000]}
\CommentTok{\#\#  [    59 143000]}
\CommentTok{\#\#  [    57  26000]}
\CommentTok{\#\#  [    52  38000]}
\CommentTok{\#\#  [    47 113000]}
\CommentTok{\#\#  [    53 143000]}
\CommentTok{\#\#  [    35  27000]}
\CommentTok{\#\#  [    58 101000]}
\CommentTok{\#\#  [    45  45000]}
\CommentTok{\#\#  [    23  82000]}
\CommentTok{\#\#  [    46  23000]}
\CommentTok{\#\#  [    42  65000]}
\CommentTok{\#\#  [    28  84000]}
\CommentTok{\#\#  [    38  59000]}
\CommentTok{\#\#  [    26  84000]}
\CommentTok{\#\#  [    29  28000]}
\CommentTok{\#\#  [    37  71000]}
\CommentTok{\#\#  [    22  55000]}
\CommentTok{\#\#  [    48  35000]}
\CommentTok{\#\#  [    49  28000]}
\CommentTok{\#\#  [    38  65000]}
\CommentTok{\#\#  [    27  17000]}
\CommentTok{\#\#  [    46  28000]}
\CommentTok{\#\#  [    48 141000]}
\CommentTok{\#\#  [    26  17000]}
\CommentTok{\#\#  [    35  97000]}
\CommentTok{\#\#  [    39  59000]}
\CommentTok{\#\#  [    24  27000]}
\CommentTok{\#\#  [    32  18000]}
\CommentTok{\#\#  [    46  88000]}
\CommentTok{\#\#  [    35  58000]}
\CommentTok{\#\#  [    56  60000]}
\CommentTok{\#\#  [    47  34000]}
\CommentTok{\#\#  [    40  72000]}
\CommentTok{\#\#  [    32 100000]}
\CommentTok{\#\#  [    19  21000]}
\CommentTok{\#\#  [    25  90000]}
\CommentTok{\#\#  [    35  88000]}
\CommentTok{\#\#  [    28  32000]}
\CommentTok{\#\#  [    50  20000]}
\CommentTok{\#\#  [    40  59000]}
\CommentTok{\#\#  [    50  44000]}
\CommentTok{\#\#  [    35  72000]}
\CommentTok{\#\#  [    40 142000]}
\CommentTok{\#\#  [    46  32000]}
\CommentTok{\#\#  [    39  71000]}
\CommentTok{\#\#  [    20  74000]}
\CommentTok{\#\#  [    29  75000]}
\CommentTok{\#\#  [    31  76000]}
\CommentTok{\#\#  [    47  25000]}
\CommentTok{\#\#  [    40  61000]}
\CommentTok{\#\#  [    34 112000]}
\CommentTok{\#\#  [    38  80000]}
\CommentTok{\#\#  [    42  75000]}
\CommentTok{\#\#  [    47  47000]}
\CommentTok{\#\#  [    39  75000]}
\CommentTok{\#\#  [    19  25000]}
\CommentTok{\#\#  [    37  80000]}
\CommentTok{\#\#  [    36  60000]}
\CommentTok{\#\#  [    41  52000]}
\CommentTok{\#\#  [    36 125000]}
\CommentTok{\#\#  [    48  29000]}
\CommentTok{\#\#  [    36 126000]}
\CommentTok{\#\#  [    51 134000]}
\CommentTok{\#\#  [    27  57000]}
\CommentTok{\#\#  [    38  71000]}
\CommentTok{\#\#  [    39  61000]}
\CommentTok{\#\#  [    22  27000]}
\CommentTok{\#\#  [    33  60000]}
\CommentTok{\#\#  [    48  74000]}
\CommentTok{\#\#  [    58  23000]}
\CommentTok{\#\#  [    53  72000]}
\CommentTok{\#\#  [    32 117000]}
\CommentTok{\#\#  [    54  70000]}
\CommentTok{\#\#  [    30  80000]}
\CommentTok{\#\#  [    58  95000]}
\CommentTok{\#\#  [    26  52000]}
\CommentTok{\#\#  [    45  79000]}
\CommentTok{\#\#  [    24  55000]}
\CommentTok{\#\#  [    40  75000]}
\CommentTok{\#\#  [    33  28000]}
\CommentTok{\#\#  [    44 139000]}
\CommentTok{\#\#  [    22  18000]}
\CommentTok{\#\#  [    33  51000]}
\CommentTok{\#\#  [    43 133000]}
\CommentTok{\#\#  [    24  32000]}
\CommentTok{\#\#  [    46  22000]}
\CommentTok{\#\#  [    35  55000]}
\CommentTok{\#\#  [    54 104000]}
\CommentTok{\#\#  [    48 119000]}
\CommentTok{\#\#  [    35  53000]}
\CommentTok{\#\#  [    37 144000]}
\CommentTok{\#\#  [    23  66000]}
\CommentTok{\#\#  [    37 137000]}
\CommentTok{\#\#  [    31  58000]}
\CommentTok{\#\#  [    33  41000]}
\CommentTok{\#\#  [    45  22000]}
\CommentTok{\#\#  [    30  15000]}
\CommentTok{\#\#  [    19  19000]}
\CommentTok{\#\#  [    49  74000]}
\CommentTok{\#\#  [    39 122000]}
\CommentTok{\#\#  [    35  73000]}
\CommentTok{\#\#  [    39  71000]}
\CommentTok{\#\#  [    24  23000]}
\CommentTok{\#\#  [    41  72000]}
\CommentTok{\#\#  [    29  83000]}
\CommentTok{\#\#  [    54  26000]}
\CommentTok{\#\#  [    35  44000]}
\CommentTok{\#\#  [    37  75000]}
\CommentTok{\#\#  [    29  47000]}
\CommentTok{\#\#  [    31  68000]}
\CommentTok{\#\#  [    42  54000]}
\CommentTok{\#\#  [    30 135000]}
\CommentTok{\#\#  [    52 114000]}
\CommentTok{\#\#  [    50  36000]}
\CommentTok{\#\#  [    56 133000]}
\CommentTok{\#\#  [    29  61000]}
\CommentTok{\#\#  [    30  89000]}
\CommentTok{\#\#  [    26  16000]}
\CommentTok{\#\#  [    33  31000]}
\CommentTok{\#\#  [    41  72000]}
\CommentTok{\#\#  [    36  33000]}
\CommentTok{\#\#  [    55 125000]}
\CommentTok{\#\#  [    48 131000]}
\CommentTok{\#\#  [    41  71000]}
\CommentTok{\#\#  [    30  62000]}
\CommentTok{\#\#  [    37  72000]}
\CommentTok{\#\#  [    41  63000]}
\CommentTok{\#\#  [    58  47000]}
\CommentTok{\#\#  [    30 116000]}
\CommentTok{\#\#  [    20  49000]}
\CommentTok{\#\#  [    37  74000]}
\CommentTok{\#\#  [    41  59000]}
\CommentTok{\#\#  [    49  89000]}
\CommentTok{\#\#  [    28  79000]}
\CommentTok{\#\#  [    53  82000]}
\CommentTok{\#\#  [    40  57000]}
\CommentTok{\#\#  [    60  34000]}
\CommentTok{\#\#  [    35 108000]}
\CommentTok{\#\#  [    21  72000]}
\CommentTok{\#\#  [    38  71000]}
\CommentTok{\#\#  [    39 106000]}
\CommentTok{\#\#  [    37  57000]}
\CommentTok{\#\#  [    26  72000]}
\CommentTok{\#\#  [    35  23000]}
\CommentTok{\#\#  [    54 108000]}
\CommentTok{\#\#  [    30  17000]}
\CommentTok{\#\#  [    39 134000]}
\CommentTok{\#\#  [    29  43000]}
\CommentTok{\#\#  [    33  43000]}
\CommentTok{\#\#  [    35  38000]}
\CommentTok{\#\#  [    41  45000]}
\CommentTok{\#\#  [    41  72000]}
\CommentTok{\#\#  [    39 134000]}
\CommentTok{\#\#  [    27 137000]}
\CommentTok{\#\#  [    21  16000]}
\CommentTok{\#\#  [    26  32000]}
\CommentTok{\#\#  [    31  66000]}
\CommentTok{\#\#  [    39  73000]}
\CommentTok{\#\#  [    41  79000]}
\CommentTok{\#\#  [    47  50000]}
\CommentTok{\#\#  [    41  30000]}
\CommentTok{\#\#  [    37  93000]}
\CommentTok{\#\#  [    60  46000]}
\CommentTok{\#\#  [    25  22000]}
\CommentTok{\#\#  [    28  37000]}
\CommentTok{\#\#  [    38  55000]}
\CommentTok{\#\#  [    36  54000]}
\CommentTok{\#\#  [    20  36000]}
\CommentTok{\#\#  [    56 104000]}
\CommentTok{\#\#  [    40  57000]}
\CommentTok{\#\#  [    42 108000]}
\CommentTok{\#\#  [    20  23000]}
\CommentTok{\#\#  [    40  65000]}
\CommentTok{\#\#  [    47  20000]}
\CommentTok{\#\#  [    18  86000]}
\CommentTok{\#\#  [    35  79000]}
\CommentTok{\#\#  [    57  33000]}
\CommentTok{\#\#  [    34  72000]}
\CommentTok{\#\#  [    49  39000]}
\CommentTok{\#\#  [    27  31000]}
\CommentTok{\#\#  [    19  70000]}
\CommentTok{\#\#  [    39  79000]}
\CommentTok{\#\#  [    26  81000]}
\CommentTok{\#\#  [    25  80000]}
\CommentTok{\#\#  [    28  85000]}
\CommentTok{\#\#  [    55  39000]}
\CommentTok{\#\#  [    50  88000]}
\CommentTok{\#\#  [    49  88000]}
\CommentTok{\#\#  [    52 150000]}
\CommentTok{\#\#  [    35  65000]}
\CommentTok{\#\#  [    42  54000]}
\CommentTok{\#\#  [    34  43000]}
\CommentTok{\#\#  [    37  52000]}
\CommentTok{\#\#  [    48  30000]}
\CommentTok{\#\#  [    29  43000]}
\CommentTok{\#\#  [    36  52000]}
\CommentTok{\#\#  [    27  54000]}
\CommentTok{\#\#  [    26 118000]]}
\BuiltInTok{print}\NormalTok{(y\_train)}
\CommentTok{\#\# [0 1 0 1 1 1 0 0 0 0 0 0 1 1 1 0 1 0 0 1 0 1 0 1 0 0 1 1 1 1 0 1 0 1 0 0 1}
\CommentTok{\#\#  0 0 1 0 0 0 0 0 1 1 1 1 0 0 0 1 0 1 0 1 0 0 1 0 0 0 1 0 0 0 1 1 0 0 1 0 1}
\CommentTok{\#\#  1 1 0 0 1 1 0 0 1 1 0 1 0 0 1 1 0 1 1 1 0 0 0 0 0 1 0 0 1 1 1 1 1 0 1 1 0}
\CommentTok{\#\#  1 0 0 0 0 0 0 0 1 1 0 0 1 0 0 1 0 0 0 1 0 1 1 0 1 0 0 0 0 1 0 0 0 1 1 0 0}
\CommentTok{\#\#  0 0 1 0 1 0 0 0 1 0 0 0 0 1 1 1 0 0 0 0 0 0 1 1 1 1 1 0 1 0 0 0 0 0 1 0 0}
\CommentTok{\#\#  0 0 0 0 1 1 0 1 0 1 0 0 1 0 0 0 1 0 0 0 0 0 1 0 0 0 0 0 1 0 1 1 0 0 0 0 0}
\CommentTok{\#\#  0 1 1 0 0 0 0 1 0 0 0 0 1 0 1 0 1 0 0 0 1 0 0 0 1 0 1 0 0 0 0 0 1 1 0 0 0}
\CommentTok{\#\#  0 0 1 0 1 1 0 0 0 0 0 1 0 1 0 0 1 0 0 1 0 1 0 0 0 0 0 0 1 1 1 1 0 0 0 0 1}
\CommentTok{\#\#  0 0 0 0]}
\BuiltInTok{print}\NormalTok{(X\_test)}
\CommentTok{\#\# [[    30  87000]}
\CommentTok{\#\#  [    38  50000]}
\CommentTok{\#\#  [    35  75000]}
\CommentTok{\#\#  [    30  79000]}
\CommentTok{\#\#  [    35  50000]}
\CommentTok{\#\#  [    27  20000]}
\CommentTok{\#\#  [    31  15000]}
\CommentTok{\#\#  [    36 144000]}
\CommentTok{\#\#  [    18  68000]}
\CommentTok{\#\#  [    47  43000]}
\CommentTok{\#\#  [    30  49000]}
\CommentTok{\#\#  [    28  55000]}
\CommentTok{\#\#  [    37  55000]}
\CommentTok{\#\#  [    39  77000]}
\CommentTok{\#\#  [    20  86000]}
\CommentTok{\#\#  [    32 117000]}
\CommentTok{\#\#  [    37  77000]}
\CommentTok{\#\#  [    19  85000]}
\CommentTok{\#\#  [    55 130000]}
\CommentTok{\#\#  [    35  22000]}
\CommentTok{\#\#  [    35  47000]}
\CommentTok{\#\#  [    47 144000]}
\CommentTok{\#\#  [    41  51000]}
\CommentTok{\#\#  [    47 105000]}
\CommentTok{\#\#  [    23  28000]}
\CommentTok{\#\#  [    49 141000]}
\CommentTok{\#\#  [    28  87000]}
\CommentTok{\#\#  [    29  80000]}
\CommentTok{\#\#  [    37  62000]}
\CommentTok{\#\#  [    32  86000]}
\CommentTok{\#\#  [    21  88000]}
\CommentTok{\#\#  [    37  79000]}
\CommentTok{\#\#  [    57  60000]}
\CommentTok{\#\#  [    37  53000]}
\CommentTok{\#\#  [    24  58000]}
\CommentTok{\#\#  [    18  52000]}
\CommentTok{\#\#  [    22  81000]}
\CommentTok{\#\#  [    34  43000]}
\CommentTok{\#\#  [    31  34000]}
\CommentTok{\#\#  [    49  36000]}
\CommentTok{\#\#  [    27  88000]}
\CommentTok{\#\#  [    41  52000]}
\CommentTok{\#\#  [    27  84000]}
\CommentTok{\#\#  [    35  20000]}
\CommentTok{\#\#  [    43 112000]}
\CommentTok{\#\#  [    27  58000]}
\CommentTok{\#\#  [    37  80000]}
\CommentTok{\#\#  [    52  90000]}
\CommentTok{\#\#  [    26  30000]}
\CommentTok{\#\#  [    49  86000]}
\CommentTok{\#\#  [    57 122000]}
\CommentTok{\#\#  [    34  25000]}
\CommentTok{\#\#  [    35  57000]}
\CommentTok{\#\#  [    34 115000]}
\CommentTok{\#\#  [    59  88000]}
\CommentTok{\#\#  [    45  32000]}
\CommentTok{\#\#  [    29  83000]}
\CommentTok{\#\#  [    26  80000]}
\CommentTok{\#\#  [    49  28000]}
\CommentTok{\#\#  [    23  20000]}
\CommentTok{\#\#  [    32  18000]}
\CommentTok{\#\#  [    60  42000]}
\CommentTok{\#\#  [    19  76000]}
\CommentTok{\#\#  [    36  99000]}
\CommentTok{\#\#  [    19  26000]}
\CommentTok{\#\#  [    60  83000]}
\CommentTok{\#\#  [    24  89000]}
\CommentTok{\#\#  [    27  58000]}
\CommentTok{\#\#  [    40  47000]}
\CommentTok{\#\#  [    42  70000]}
\CommentTok{\#\#  [    32 150000]}
\CommentTok{\#\#  [    35  77000]}
\CommentTok{\#\#  [    22  63000]}
\CommentTok{\#\#  [    45  22000]}
\CommentTok{\#\#  [    27  89000]}
\CommentTok{\#\#  [    18  82000]}
\CommentTok{\#\#  [    42  79000]}
\CommentTok{\#\#  [    40  60000]}
\CommentTok{\#\#  [    53  34000]}
\CommentTok{\#\#  [    47 107000]}
\CommentTok{\#\#  [    58 144000]}
\CommentTok{\#\#  [    59  83000]}
\CommentTok{\#\#  [    24  55000]}
\CommentTok{\#\#  [    26  35000]}
\CommentTok{\#\#  [    58  38000]}
\CommentTok{\#\#  [    42  80000]}
\CommentTok{\#\#  [    40  75000]}
\CommentTok{\#\#  [    59 130000]}
\CommentTok{\#\#  [    46  41000]}
\CommentTok{\#\#  [    41  60000]}
\CommentTok{\#\#  [    42  64000]}
\CommentTok{\#\#  [    37 146000]}
\CommentTok{\#\#  [    23  48000]}
\CommentTok{\#\#  [    25  33000]}
\CommentTok{\#\#  [    24  84000]}
\CommentTok{\#\#  [    27  96000]}
\CommentTok{\#\#  [    23  63000]}
\CommentTok{\#\#  [    48  33000]}
\CommentTok{\#\#  [    48  90000]}
\CommentTok{\#\#  [    42 104000]]}
\BuiltInTok{print}\NormalTok{(y\_test)}
\CommentTok{\#\# [0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 1 0 0 1 0 1 0 1 0 0 0 0 0 1 1 0 0 0 0}
\CommentTok{\#\#  0 0 1 0 0 0 0 1 0 0 1 0 1 1 0 0 0 1 1 0 0 1 0 0 1 0 1 0 1 0 0 0 0 1 0 0 1}
\CommentTok{\#\#  0 0 0 0 1 1 1 0 0 0 1 1 0 1 1 0 0 1 0 0 0 1 0 1 1 1]}
\end{Highlighting}
\end{Shaded}

R

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\# install.packages(\textquotesingle{}caTools\textquotesingle{})}
\FunctionTok{library}\NormalTok{(caTools)}
\FunctionTok{set.seed}\NormalTok{(}\DecValTok{123}\NormalTok{)}
\NormalTok{split }\OtherTok{=} \FunctionTok{sample.split}\NormalTok{(dataset}\SpecialCharTok{$}\NormalTok{Purchased, }\AttributeTok{SplitRatio =} \FloatTok{0.75}\NormalTok{)}
\NormalTok{training\_set }\OtherTok{=} \FunctionTok{subset}\NormalTok{(dataset, split }\SpecialCharTok{==} \ConstantTok{TRUE}\NormalTok{)}
\NormalTok{test\_set }\OtherTok{=} \FunctionTok{subset}\NormalTok{(dataset, split }\SpecialCharTok{==} \ConstantTok{FALSE}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\hypertarget{feature-scaling-2}{%
\subsection{Feature Scaling}\label{feature-scaling-2}}

Python

\begin{Shaded}
\begin{Highlighting}[]
\ImportTok{from}\NormalTok{ sklearn.preprocessing }\ImportTok{import}\NormalTok{ StandardScaler}
\NormalTok{sc }\OperatorTok{=}\NormalTok{ StandardScaler()}
\NormalTok{X\_train }\OperatorTok{=}\NormalTok{ sc.fit\_transform(X\_train)}
\NormalTok{X\_test }\OperatorTok{=}\NormalTok{ sc.transform(X\_test)}
\BuiltInTok{print}\NormalTok{(X\_train)}
\CommentTok{\#\# [[ 0.58 {-}0.89]}
\CommentTok{\#\#  [{-}0.61  1.46]}
\CommentTok{\#\#  [{-}0.01 {-}0.57]}
\CommentTok{\#\#  [{-}0.61  1.9 ]}
\CommentTok{\#\#  [ 1.37 {-}1.41]}
\CommentTok{\#\#  [ 1.47  1.  ]}
\CommentTok{\#\#  [ 0.09 {-}0.8 ]}
\CommentTok{\#\#  [{-}0.01 {-}0.25]}
\CommentTok{\#\#  [{-}0.21 {-}0.57]}
\CommentTok{\#\#  [{-}0.21 {-}0.19]}
\CommentTok{\#\#  [{-}0.31 {-}1.29]}
\CommentTok{\#\#  [{-}0.31 {-}0.57]}
\CommentTok{\#\#  [ 0.38  0.1 ]}
\CommentTok{\#\#  [ 0.88 {-}0.6 ]}
\CommentTok{\#\#  [ 2.07 {-}1.18]}
\CommentTok{\#\#  [ 1.08 {-}0.13]}
\CommentTok{\#\#  [ 0.68  1.78]}
\CommentTok{\#\#  [{-}0.71  0.56]}
\CommentTok{\#\#  [ 0.78  0.36]}
\CommentTok{\#\#  [ 0.88 {-}0.54]}
\CommentTok{\#\#  [{-}1.2  {-}1.58]}
\CommentTok{\#\#  [ 2.17  0.94]}
\CommentTok{\#\#  [{-}0.01  1.23]}
\CommentTok{\#\#  [ 0.19  1.08]}
\CommentTok{\#\#  [ 0.38 {-}0.48]}
\CommentTok{\#\#  [{-}0.31 {-}0.31]}
\CommentTok{\#\#  [ 0.98 {-}0.83]}
\CommentTok{\#\#  [ 0.98  1.87]}
\CommentTok{\#\#  [{-}0.01  1.26]}
\CommentTok{\#\#  [{-}0.9   2.27]}
\CommentTok{\#\#  [{-}1.2  {-}1.58]}
\CommentTok{\#\#  [ 2.17 {-}0.8 ]}
\CommentTok{\#\#  [{-}1.4  {-}1.47]}
\CommentTok{\#\#  [ 0.38  2.3 ]}
\CommentTok{\#\#  [ 0.78  0.77]}
\CommentTok{\#\#  [{-}1.   {-}0.31]}
\CommentTok{\#\#  [ 0.09  0.77]}
\CommentTok{\#\#  [{-}1.    0.56]}
\CommentTok{\#\#  [ 0.28  0.07]}
\CommentTok{\#\#  [ 0.68 {-}1.26]}
\CommentTok{\#\#  [{-}0.51 {-}0.02]}
\CommentTok{\#\#  [{-}1.8   0.36]}
\CommentTok{\#\#  [{-}0.71  0.13]}
\CommentTok{\#\#  [ 0.38  0.3 ]}
\CommentTok{\#\#  [{-}0.31  0.07]}
\CommentTok{\#\#  [{-}0.51  2.3 ]}
\CommentTok{\#\#  [ 0.19  0.04]}
\CommentTok{\#\#  [ 1.27  2.22]}
\CommentTok{\#\#  [ 0.78  0.27]}
\CommentTok{\#\#  [{-}0.31  0.16]}
\CommentTok{\#\#  [{-}0.01 {-}0.54]}
\CommentTok{\#\#  [{-}0.21  0.16]}
\CommentTok{\#\#  [{-}0.11  0.24]}
\CommentTok{\#\#  [{-}0.01 {-}0.25]}
\CommentTok{\#\#  [ 2.17  1.11]}
\CommentTok{\#\#  [{-}1.8   0.36]}
\CommentTok{\#\#  [ 1.87  0.13]}
\CommentTok{\#\#  [ 0.38 {-}0.13]}
\CommentTok{\#\#  [{-}1.2   0.3 ]}
\CommentTok{\#\#  [ 0.78  1.37]}
\CommentTok{\#\#  [{-}0.31 {-}0.25]}
\CommentTok{\#\#  [{-}1.7  {-}0.05]}
\CommentTok{\#\#  [{-}1.   {-}0.74]}
\CommentTok{\#\#  [ 0.28  0.5 ]}
\CommentTok{\#\#  [{-}0.11 {-}1.06]}
\CommentTok{\#\#  [{-}1.1   0.59]}
\CommentTok{\#\#  [ 0.09 {-}0.8 ]}
\CommentTok{\#\#  [{-}1.    1.55]}
\CommentTok{\#\#  [{-}0.71  1.4 ]}
\CommentTok{\#\#  [{-}1.3   0.5 ]}
\CommentTok{\#\#  [{-}0.31  0.04]}
\CommentTok{\#\#  [{-}0.11  0.01]}
\CommentTok{\#\#  [{-}0.31 {-}0.89]}
\CommentTok{\#\#  [ 0.88 {-}1.35]}
\CommentTok{\#\#  [{-}0.31  2.24]}
\CommentTok{\#\#  [ 0.98  1.98]}
\CommentTok{\#\#  [{-}1.2   0.48]}
\CommentTok{\#\#  [{-}1.3   0.27]}
\CommentTok{\#\#  [ 1.37  1.98]}
\CommentTok{\#\#  [ 1.27 {-}1.35]}
\CommentTok{\#\#  [{-}0.31 {-}0.28]}
\CommentTok{\#\#  [{-}0.51  1.26]}
\CommentTok{\#\#  [{-}0.8   1.08]}
\CommentTok{\#\#  [ 0.98 {-}1.06]}
\CommentTok{\#\#  [ 0.28  0.3 ]}
\CommentTok{\#\#  [ 0.98  0.77]}
\CommentTok{\#\#  [{-}0.71 {-}1.5 ]}
\CommentTok{\#\#  [{-}0.71  0.04]}
\CommentTok{\#\#  [ 0.48  1.72]}
\CommentTok{\#\#  [ 2.07  0.19]}
\CommentTok{\#\#  [{-}1.99 {-}0.74]}
\CommentTok{\#\#  [{-}0.21  1.4 ]}
\CommentTok{\#\#  [ 0.38  0.59]}
\CommentTok{\#\#  [ 0.88 {-}1.15]}
\CommentTok{\#\#  [{-}1.2  {-}0.77]}
\CommentTok{\#\#  [ 0.19  0.24]}
\CommentTok{\#\#  [ 0.78 {-}0.31]}
\CommentTok{\#\#  [ 2.07 {-}0.8 ]}
\CommentTok{\#\#  [ 0.78  0.13]}
\CommentTok{\#\#  [{-}0.31  0.62]}
\CommentTok{\#\#  [{-}1.   {-}0.31]}
\CommentTok{\#\#  [ 0.19 {-}0.36]}
\CommentTok{\#\#  [ 2.07  2.13]}
\CommentTok{\#\#  [ 1.87 {-}1.26]}
\CommentTok{\#\#  [ 1.37 {-}0.92]}
\CommentTok{\#\#  [ 0.88  1.26]}
\CommentTok{\#\#  [ 1.47  2.13]}
\CommentTok{\#\#  [{-}0.31 {-}1.23]}
\CommentTok{\#\#  [ 1.97  0.91]}
\CommentTok{\#\#  [ 0.68 {-}0.71]}
\CommentTok{\#\#  [{-}1.5   0.36]}
\CommentTok{\#\#  [ 0.78 {-}1.35]}
\CommentTok{\#\#  [ 0.38 {-}0.13]}
\CommentTok{\#\#  [{-}1.    0.42]}
\CommentTok{\#\#  [{-}0.01 {-}0.31]}
\CommentTok{\#\#  [{-}1.2   0.42]}
\CommentTok{\#\#  [{-}0.9  {-}1.21]}
\CommentTok{\#\#  [{-}0.11  0.04]}
\CommentTok{\#\#  [{-}1.6  {-}0.42]}
\CommentTok{\#\#  [ 0.98 {-}1.  ]}
\CommentTok{\#\#  [ 1.08 {-}1.21]}
\CommentTok{\#\#  [{-}0.01 {-}0.13]}
\CommentTok{\#\#  [{-}1.1  {-}1.52]}
\CommentTok{\#\#  [ 0.78 {-}1.21]}
\CommentTok{\#\#  [ 0.98  2.07]}
\CommentTok{\#\#  [{-}1.2  {-}1.52]}
\CommentTok{\#\#  [{-}0.31  0.79]}
\CommentTok{\#\#  [ 0.09 {-}0.31]}
\CommentTok{\#\#  [{-}1.4  {-}1.23]}
\CommentTok{\#\#  [{-}0.61 {-}1.5 ]}
\CommentTok{\#\#  [ 0.78  0.53]}
\CommentTok{\#\#  [{-}0.31 {-}0.34]}
\CommentTok{\#\#  [ 1.77 {-}0.28]}
\CommentTok{\#\#  [ 0.88 {-}1.03]}
\CommentTok{\#\#  [ 0.19  0.07]}
\CommentTok{\#\#  [{-}0.61  0.88]}
\CommentTok{\#\#  [{-}1.89 {-}1.41]}
\CommentTok{\#\#  [{-}1.3   0.59]}
\CommentTok{\#\#  [{-}0.31  0.53]}
\CommentTok{\#\#  [{-}1.   {-}1.09]}
\CommentTok{\#\#  [ 1.18 {-}1.44]}
\CommentTok{\#\#  [ 0.19 {-}0.31]}
\CommentTok{\#\#  [ 1.18 {-}0.74]}
\CommentTok{\#\#  [{-}0.31  0.07]}
\CommentTok{\#\#  [ 0.19  2.1 ]}
\CommentTok{\#\#  [ 0.78 {-}1.09]}
\CommentTok{\#\#  [ 0.09  0.04]}
\CommentTok{\#\#  [{-}1.8   0.13]}
\CommentTok{\#\#  [{-}0.9   0.16]}
\CommentTok{\#\#  [{-}0.71  0.19]}
\CommentTok{\#\#  [ 0.88 {-}1.29]}
\CommentTok{\#\#  [ 0.19 {-}0.25]}
\CommentTok{\#\#  [{-}0.41  1.23]}
\CommentTok{\#\#  [{-}0.01  0.3 ]}
\CommentTok{\#\#  [ 0.38  0.16]}
\CommentTok{\#\#  [ 0.88 {-}0.65]}
\CommentTok{\#\#  [ 0.09  0.16]}
\CommentTok{\#\#  [{-}1.89 {-}1.29]}
\CommentTok{\#\#  [{-}0.11  0.3 ]}
\CommentTok{\#\#  [{-}0.21 {-}0.28]}
\CommentTok{\#\#  [ 0.28 {-}0.51]}
\CommentTok{\#\#  [{-}0.21  1.61]}
\CommentTok{\#\#  [ 0.98 {-}1.18]}
\CommentTok{\#\#  [{-}0.21  1.64]}
\CommentTok{\#\#  [ 1.27  1.87]}
\CommentTok{\#\#  [{-}1.1  {-}0.36]}
\CommentTok{\#\#  [{-}0.01  0.04]}
\CommentTok{\#\#  [ 0.09 {-}0.25]}
\CommentTok{\#\#  [{-}1.6  {-}1.23]}
\CommentTok{\#\#  [{-}0.51 {-}0.28]}
\CommentTok{\#\#  [ 0.98  0.13]}
\CommentTok{\#\#  [ 1.97 {-}1.35]}
\CommentTok{\#\#  [ 1.47  0.07]}
\CommentTok{\#\#  [{-}0.61  1.37]}
\CommentTok{\#\#  [ 1.57  0.01]}
\CommentTok{\#\#  [{-}0.8   0.3 ]}
\CommentTok{\#\#  [ 1.97  0.74]}
\CommentTok{\#\#  [{-}1.2  {-}0.51]}
\CommentTok{\#\#  [ 0.68  0.27]}
\CommentTok{\#\#  [{-}1.4  {-}0.42]}
\CommentTok{\#\#  [ 0.19  0.16]}
\CommentTok{\#\#  [{-}0.51 {-}1.21]}
\CommentTok{\#\#  [ 0.58  2.01]}
\CommentTok{\#\#  [{-}1.6  {-}1.5 ]}
\CommentTok{\#\#  [{-}0.51 {-}0.54]}
\CommentTok{\#\#  [ 0.48  1.84]}
\CommentTok{\#\#  [{-}1.4  {-}1.09]}
\CommentTok{\#\#  [ 0.78 {-}1.38]}
\CommentTok{\#\#  [{-}0.31 {-}0.42]}
\CommentTok{\#\#  [ 1.57  1.  ]}
\CommentTok{\#\#  [ 0.98  1.43]}
\CommentTok{\#\#  [{-}0.31 {-}0.48]}
\CommentTok{\#\#  [{-}0.11  2.16]}
\CommentTok{\#\#  [{-}1.5  {-}0.1 ]}
\CommentTok{\#\#  [{-}0.11  1.95]}
\CommentTok{\#\#  [{-}0.71 {-}0.34]}
\CommentTok{\#\#  [{-}0.51 {-}0.83]}
\CommentTok{\#\#  [ 0.68 {-}1.38]}
\CommentTok{\#\#  [{-}0.8  {-}1.58]}
\CommentTok{\#\#  [{-}1.89 {-}1.47]}
\CommentTok{\#\#  [ 1.08  0.13]}
\CommentTok{\#\#  [ 0.09  1.52]}
\CommentTok{\#\#  [{-}0.31  0.1 ]}
\CommentTok{\#\#  [ 0.09  0.04]}
\CommentTok{\#\#  [{-}1.4  {-}1.35]}
\CommentTok{\#\#  [ 0.28  0.07]}
\CommentTok{\#\#  [{-}0.9   0.39]}
\CommentTok{\#\#  [ 1.57 {-}1.26]}
\CommentTok{\#\#  [{-}0.31 {-}0.74]}
\CommentTok{\#\#  [{-}0.11  0.16]}
\CommentTok{\#\#  [{-}0.9  {-}0.65]}
\CommentTok{\#\#  [{-}0.71 {-}0.05]}
\CommentTok{\#\#  [ 0.38 {-}0.45]}
\CommentTok{\#\#  [{-}0.8   1.9 ]}
\CommentTok{\#\#  [ 1.37  1.29]}
\CommentTok{\#\#  [ 1.18 {-}0.97]}
\CommentTok{\#\#  [ 1.77  1.84]}
\CommentTok{\#\#  [{-}0.9  {-}0.25]}
\CommentTok{\#\#  [{-}0.8   0.56]}
\CommentTok{\#\#  [{-}1.2  {-}1.55]}
\CommentTok{\#\#  [{-}0.51 {-}1.12]}
\CommentTok{\#\#  [ 0.28  0.07]}
\CommentTok{\#\#  [{-}0.21 {-}1.06]}
\CommentTok{\#\#  [ 1.67  1.61]}
\CommentTok{\#\#  [ 0.98  1.78]}
\CommentTok{\#\#  [ 0.28  0.04]}
\CommentTok{\#\#  [{-}0.8  {-}0.22]}
\CommentTok{\#\#  [{-}0.11  0.07]}
\CommentTok{\#\#  [ 0.28 {-}0.19]}
\CommentTok{\#\#  [ 1.97 {-}0.65]}
\CommentTok{\#\#  [{-}0.8   1.35]}
\CommentTok{\#\#  [{-}1.8  {-}0.6 ]}
\CommentTok{\#\#  [{-}0.11  0.13]}
\CommentTok{\#\#  [ 0.28 {-}0.31]}
\CommentTok{\#\#  [ 1.08  0.56]}
\CommentTok{\#\#  [{-}1.    0.27]}
\CommentTok{\#\#  [ 1.47  0.36]}
\CommentTok{\#\#  [ 0.19 {-}0.36]}
\CommentTok{\#\#  [ 2.17 {-}1.03]}
\CommentTok{\#\#  [{-}0.31  1.11]}
\CommentTok{\#\#  [{-}1.7   0.07]}
\CommentTok{\#\#  [{-}0.01  0.04]}
\CommentTok{\#\#  [ 0.09  1.06]}
\CommentTok{\#\#  [{-}0.11 {-}0.36]}
\CommentTok{\#\#  [{-}1.2   0.07]}
\CommentTok{\#\#  [{-}0.31 {-}1.35]}
\CommentTok{\#\#  [ 1.57  1.11]}
\CommentTok{\#\#  [{-}0.8  {-}1.52]}
\CommentTok{\#\#  [ 0.09  1.87]}
\CommentTok{\#\#  [{-}0.9  {-}0.77]}
\CommentTok{\#\#  [{-}0.51 {-}0.77]}
\CommentTok{\#\#  [{-}0.31 {-}0.92]}
\CommentTok{\#\#  [ 0.28 {-}0.71]}
\CommentTok{\#\#  [ 0.28  0.07]}
\CommentTok{\#\#  [ 0.09  1.87]}
\CommentTok{\#\#  [{-}1.1   1.95]}
\CommentTok{\#\#  [{-}1.7  {-}1.55]}
\CommentTok{\#\#  [{-}1.2  {-}1.09]}
\CommentTok{\#\#  [{-}0.71 {-}0.1 ]}
\CommentTok{\#\#  [ 0.09  0.1 ]}
\CommentTok{\#\#  [ 0.28  0.27]}
\CommentTok{\#\#  [ 0.88 {-}0.57]}
\CommentTok{\#\#  [ 0.28 {-}1.15]}
\CommentTok{\#\#  [{-}0.11  0.68]}
\CommentTok{\#\#  [ 2.17 {-}0.68]}
\CommentTok{\#\#  [{-}1.3  {-}1.38]}
\CommentTok{\#\#  [{-}1.   {-}0.94]}
\CommentTok{\#\#  [{-}0.01 {-}0.42]}
\CommentTok{\#\#  [{-}0.21 {-}0.45]}
\CommentTok{\#\#  [{-}1.8  {-}0.97]}
\CommentTok{\#\#  [ 1.77  1.  ]}
\CommentTok{\#\#  [ 0.19 {-}0.36]}
\CommentTok{\#\#  [ 0.38  1.11]}
\CommentTok{\#\#  [{-}1.8  {-}1.35]}
\CommentTok{\#\#  [ 0.19 {-}0.13]}
\CommentTok{\#\#  [ 0.88 {-}1.44]}
\CommentTok{\#\#  [{-}1.99  0.48]}
\CommentTok{\#\#  [{-}0.31  0.27]}
\CommentTok{\#\#  [ 1.87 {-}1.06]}
\CommentTok{\#\#  [{-}0.41  0.07]}
\CommentTok{\#\#  [ 1.08 {-}0.89]}
\CommentTok{\#\#  [{-}1.1  {-}1.12]}
\CommentTok{\#\#  [{-}1.89  0.01]}
\CommentTok{\#\#  [ 0.09  0.27]}
\CommentTok{\#\#  [{-}1.2   0.33]}
\CommentTok{\#\#  [{-}1.3   0.3 ]}
\CommentTok{\#\#  [{-}1.    0.45]}
\CommentTok{\#\#  [ 1.67 {-}0.89]}
\CommentTok{\#\#  [ 1.18  0.53]}
\CommentTok{\#\#  [ 1.08  0.53]}
\CommentTok{\#\#  [ 1.37  2.33]}
\CommentTok{\#\#  [{-}0.31 {-}0.13]}
\CommentTok{\#\#  [ 0.38 {-}0.45]}
\CommentTok{\#\#  [{-}0.41 {-}0.77]}
\CommentTok{\#\#  [{-}0.11 {-}0.51]}
\CommentTok{\#\#  [ 0.98 {-}1.15]}
\CommentTok{\#\#  [{-}0.9  {-}0.77]}
\CommentTok{\#\#  [{-}0.21 {-}0.51]}
\CommentTok{\#\#  [{-}1.1  {-}0.45]}
\CommentTok{\#\#  [{-}1.2   1.4 ]]}
\BuiltInTok{print}\NormalTok{(X\_test)}
\CommentTok{\#\# [[{-}0.8   0.5 ]}
\CommentTok{\#\#  [{-}0.01 {-}0.57]}
\CommentTok{\#\#  [{-}0.31  0.16]}
\CommentTok{\#\#  [{-}0.8   0.27]}
\CommentTok{\#\#  [{-}0.31 {-}0.57]}
\CommentTok{\#\#  [{-}1.1  {-}1.44]}
\CommentTok{\#\#  [{-}0.71 {-}1.58]}
\CommentTok{\#\#  [{-}0.21  2.16]}
\CommentTok{\#\#  [{-}1.99 {-}0.05]}
\CommentTok{\#\#  [ 0.88 {-}0.77]}
\CommentTok{\#\#  [{-}0.8  {-}0.6 ]}
\CommentTok{\#\#  [{-}1.   {-}0.42]}
\CommentTok{\#\#  [{-}0.11 {-}0.42]}
\CommentTok{\#\#  [ 0.09  0.22]}
\CommentTok{\#\#  [{-}1.8   0.48]}
\CommentTok{\#\#  [{-}0.61  1.37]}
\CommentTok{\#\#  [{-}0.11  0.22]}
\CommentTok{\#\#  [{-}1.89  0.45]}
\CommentTok{\#\#  [ 1.67  1.75]}
\CommentTok{\#\#  [{-}0.31 {-}1.38]}
\CommentTok{\#\#  [{-}0.31 {-}0.65]}
\CommentTok{\#\#  [ 0.88  2.16]}
\CommentTok{\#\#  [ 0.28 {-}0.54]}
\CommentTok{\#\#  [ 0.88  1.03]}
\CommentTok{\#\#  [{-}1.5  {-}1.21]}
\CommentTok{\#\#  [ 1.08  2.07]}
\CommentTok{\#\#  [{-}1.    0.5 ]}
\CommentTok{\#\#  [{-}0.9   0.3 ]}
\CommentTok{\#\#  [{-}0.11 {-}0.22]}
\CommentTok{\#\#  [{-}0.61  0.48]}
\CommentTok{\#\#  [{-}1.7   0.53]}
\CommentTok{\#\#  [{-}0.11  0.27]}
\CommentTok{\#\#  [ 1.87 {-}0.28]}
\CommentTok{\#\#  [{-}0.11 {-}0.48]}
\CommentTok{\#\#  [{-}1.4  {-}0.34]}
\CommentTok{\#\#  [{-}1.99 {-}0.51]}
\CommentTok{\#\#  [{-}1.6   0.33]}
\CommentTok{\#\#  [{-}0.41 {-}0.77]}
\CommentTok{\#\#  [{-}0.71 {-}1.03]}
\CommentTok{\#\#  [ 1.08 {-}0.97]}
\CommentTok{\#\#  [{-}1.1   0.53]}
\CommentTok{\#\#  [ 0.28 {-}0.51]}
\CommentTok{\#\#  [{-}1.1   0.42]}
\CommentTok{\#\#  [{-}0.31 {-}1.44]}
\CommentTok{\#\#  [ 0.48  1.23]}
\CommentTok{\#\#  [{-}1.1  {-}0.34]}
\CommentTok{\#\#  [{-}0.11  0.3 ]}
\CommentTok{\#\#  [ 1.37  0.59]}
\CommentTok{\#\#  [{-}1.2  {-}1.15]}
\CommentTok{\#\#  [ 1.08  0.48]}
\CommentTok{\#\#  [ 1.87  1.52]}
\CommentTok{\#\#  [{-}0.41 {-}1.29]}
\CommentTok{\#\#  [{-}0.31 {-}0.36]}
\CommentTok{\#\#  [{-}0.41  1.32]}
\CommentTok{\#\#  [ 2.07  0.53]}
\CommentTok{\#\#  [ 0.68 {-}1.09]}
\CommentTok{\#\#  [{-}0.9   0.39]}
\CommentTok{\#\#  [{-}1.2   0.3 ]}
\CommentTok{\#\#  [ 1.08 {-}1.21]}
\CommentTok{\#\#  [{-}1.5  {-}1.44]}
\CommentTok{\#\#  [{-}0.61 {-}1.5 ]}
\CommentTok{\#\#  [ 2.17 {-}0.8 ]}
\CommentTok{\#\#  [{-}1.89  0.19]}
\CommentTok{\#\#  [{-}0.21  0.85]}
\CommentTok{\#\#  [{-}1.89 {-}1.26]}
\CommentTok{\#\#  [ 2.17  0.39]}
\CommentTok{\#\#  [{-}1.4   0.56]}
\CommentTok{\#\#  [{-}1.1  {-}0.34]}
\CommentTok{\#\#  [ 0.19 {-}0.65]}
\CommentTok{\#\#  [ 0.38  0.01]}
\CommentTok{\#\#  [{-}0.61  2.33]}
\CommentTok{\#\#  [{-}0.31  0.22]}
\CommentTok{\#\#  [{-}1.6  {-}0.19]}
\CommentTok{\#\#  [ 0.68 {-}1.38]}
\CommentTok{\#\#  [{-}1.1   0.56]}
\CommentTok{\#\#  [{-}1.99  0.36]}
\CommentTok{\#\#  [ 0.38  0.27]}
\CommentTok{\#\#  [ 0.19 {-}0.28]}
\CommentTok{\#\#  [ 1.47 {-}1.03]}
\CommentTok{\#\#  [ 0.88  1.08]}
\CommentTok{\#\#  [ 1.97  2.16]}
\CommentTok{\#\#  [ 2.07  0.39]}
\CommentTok{\#\#  [{-}1.4  {-}0.42]}
\CommentTok{\#\#  [{-}1.2  {-}1.  ]}
\CommentTok{\#\#  [ 1.97 {-}0.92]}
\CommentTok{\#\#  [ 0.38  0.3 ]}
\CommentTok{\#\#  [ 0.19  0.16]}
\CommentTok{\#\#  [ 2.07  1.75]}
\CommentTok{\#\#  [ 0.78 {-}0.83]}
\CommentTok{\#\#  [ 0.28 {-}0.28]}
\CommentTok{\#\#  [ 0.38 {-}0.16]}
\CommentTok{\#\#  [{-}0.11  2.22]}
\CommentTok{\#\#  [{-}1.5  {-}0.63]}
\CommentTok{\#\#  [{-}1.3  {-}1.06]}
\CommentTok{\#\#  [{-}1.4   0.42]}
\CommentTok{\#\#  [{-}1.1   0.77]}
\CommentTok{\#\#  [{-}1.5  {-}0.19]}
\CommentTok{\#\#  [ 0.98 {-}1.06]}
\CommentTok{\#\#  [ 0.98  0.59]}
\CommentTok{\#\#  [ 0.38  1.  ]]}
\end{Highlighting}
\end{Shaded}

R

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{training\_set[}\SpecialCharTok{{-}}\DecValTok{3}\NormalTok{] }\OtherTok{=} \FunctionTok{scale}\NormalTok{(training\_set[}\SpecialCharTok{{-}}\DecValTok{3}\NormalTok{])}
\NormalTok{test\_set[}\SpecialCharTok{{-}}\DecValTok{3}\NormalTok{] }\OtherTok{=} \FunctionTok{scale}\NormalTok{(test\_set[}\SpecialCharTok{{-}}\DecValTok{3}\NormalTok{])}
\end{Highlighting}
\end{Shaded}

\hypertarget{training-the-logistic-regression-model-on-the-training-set}{%
\subsection{Training the Logistic Regression model on the Training set}\label{training-the-logistic-regression-model-on-the-training-set}}

Python

\begin{Shaded}
\begin{Highlighting}[]
\ImportTok{from}\NormalTok{ sklearn.linear\_model }\ImportTok{import}\NormalTok{ LogisticRegression}
\NormalTok{classifier }\OperatorTok{=}\NormalTok{ LogisticRegression(random\_state }\OperatorTok{=} \DecValTok{0}\NormalTok{)}
\NormalTok{classifier.fit(X\_train, y\_train)}
\CommentTok{\#\# LogisticRegression(random\_state=0)}
\end{Highlighting}
\end{Shaded}

R

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{classifier }\OtherTok{=} \FunctionTok{glm}\NormalTok{(}\AttributeTok{formula =}\NormalTok{ Purchased }\SpecialCharTok{\textasciitilde{}}\NormalTok{ .,}
                 \AttributeTok{family =}\NormalTok{ binomial,}
                 \AttributeTok{data =}\NormalTok{ training\_set)}
\end{Highlighting}
\end{Shaded}

\hypertarget{predicting-a-new-result-3}{%
\subsection{Predicting a new result}\label{predicting-a-new-result-3}}

Python

\begin{Shaded}
\begin{Highlighting}[]
\BuiltInTok{print}\NormalTok{(classifier.predict(sc.transform([[}\DecValTok{30}\NormalTok{,}\DecValTok{87000}\NormalTok{]])))}
\CommentTok{\#\# [0]}
\end{Highlighting}
\end{Shaded}

\hypertarget{predicting-the-test-set-results-2}{%
\subsection{Predicting the Test set results}\label{predicting-the-test-set-results-2}}

Python

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{y\_pred }\OperatorTok{=}\NormalTok{ classifier.predict(X\_test)}
\BuiltInTok{print}\NormalTok{(np.concatenate((y\_pred.reshape(}\BuiltInTok{len}\NormalTok{(y\_pred),}\DecValTok{1}\NormalTok{), y\_test.reshape(}\BuiltInTok{len}\NormalTok{(y\_test),}\DecValTok{1}\NormalTok{)),}\DecValTok{1}\NormalTok{))}
\CommentTok{\#\# [[0 0]}
\CommentTok{\#\#  [0 0]}
\CommentTok{\#\#  [0 0]}
\CommentTok{\#\#  [0 0]}
\CommentTok{\#\#  [0 0]}
\CommentTok{\#\#  [0 0]}
\CommentTok{\#\#  [0 0]}
\CommentTok{\#\#  [1 1]}
\CommentTok{\#\#  [0 0]}
\CommentTok{\#\#  [1 0]}
\CommentTok{\#\#  [0 0]}
\CommentTok{\#\#  [0 0]}
\CommentTok{\#\#  [0 0]}
\CommentTok{\#\#  [0 0]}
\CommentTok{\#\#  [0 0]}
\CommentTok{\#\#  [0 0]}
\CommentTok{\#\#  [0 0]}
\CommentTok{\#\#  [0 0]}
\CommentTok{\#\#  [1 1]}
\CommentTok{\#\#  [0 0]}
\CommentTok{\#\#  [0 0]}
\CommentTok{\#\#  [1 1]}
\CommentTok{\#\#  [0 0]}
\CommentTok{\#\#  [1 1]}
\CommentTok{\#\#  [0 0]}
\CommentTok{\#\#  [1 1]}
\CommentTok{\#\#  [0 0]}
\CommentTok{\#\#  [0 0]}
\CommentTok{\#\#  [0 0]}
\CommentTok{\#\#  [0 0]}
\CommentTok{\#\#  [0 0]}
\CommentTok{\#\#  [0 1]}
\CommentTok{\#\#  [1 1]}
\CommentTok{\#\#  [0 0]}
\CommentTok{\#\#  [0 0]}
\CommentTok{\#\#  [0 0]}
\CommentTok{\#\#  [0 0]}
\CommentTok{\#\#  [0 0]}
\CommentTok{\#\#  [0 0]}
\CommentTok{\#\#  [1 1]}
\CommentTok{\#\#  [0 0]}
\CommentTok{\#\#  [0 0]}
\CommentTok{\#\#  [0 0]}
\CommentTok{\#\#  [0 0]}
\CommentTok{\#\#  [1 1]}
\CommentTok{\#\#  [0 0]}
\CommentTok{\#\#  [0 0]}
\CommentTok{\#\#  [1 1]}
\CommentTok{\#\#  [0 0]}
\CommentTok{\#\#  [1 1]}
\CommentTok{\#\#  [1 1]}
\CommentTok{\#\#  [0 0]}
\CommentTok{\#\#  [0 0]}
\CommentTok{\#\#  [0 0]}
\CommentTok{\#\#  [1 1]}
\CommentTok{\#\#  [0 1]}
\CommentTok{\#\#  [0 0]}
\CommentTok{\#\#  [0 0]}
\CommentTok{\#\#  [0 1]}
\CommentTok{\#\#  [0 0]}
\CommentTok{\#\#  [0 0]}
\CommentTok{\#\#  [1 1]}
\CommentTok{\#\#  [0 0]}
\CommentTok{\#\#  [0 1]}
\CommentTok{\#\#  [0 0]}
\CommentTok{\#\#  [1 1]}
\CommentTok{\#\#  [0 0]}
\CommentTok{\#\#  [0 0]}
\CommentTok{\#\#  [0 0]}
\CommentTok{\#\#  [0 0]}
\CommentTok{\#\#  [1 1]}
\CommentTok{\#\#  [0 0]}
\CommentTok{\#\#  [0 0]}
\CommentTok{\#\#  [0 1]}
\CommentTok{\#\#  [0 0]}
\CommentTok{\#\#  [0 0]}
\CommentTok{\#\#  [1 0]}
\CommentTok{\#\#  [0 0]}
\CommentTok{\#\#  [1 1]}
\CommentTok{\#\#  [1 1]}
\CommentTok{\#\#  [1 1]}
\CommentTok{\#\#  [1 0]}
\CommentTok{\#\#  [0 0]}
\CommentTok{\#\#  [0 0]}
\CommentTok{\#\#  [1 1]}
\CommentTok{\#\#  [1 1]}
\CommentTok{\#\#  [0 0]}
\CommentTok{\#\#  [1 1]}
\CommentTok{\#\#  [0 1]}
\CommentTok{\#\#  [0 0]}
\CommentTok{\#\#  [0 0]}
\CommentTok{\#\#  [1 1]}
\CommentTok{\#\#  [0 0]}
\CommentTok{\#\#  [0 0]}
\CommentTok{\#\#  [0 0]}
\CommentTok{\#\#  [0 1]}
\CommentTok{\#\#  [0 0]}
\CommentTok{\#\#  [0 1]}
\CommentTok{\#\#  [1 1]}
\CommentTok{\#\#  [1 1]]}
\end{Highlighting}
\end{Shaded}

R

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{prob\_pred }\OtherTok{=} \FunctionTok{predict}\NormalTok{(classifier, }\AttributeTok{type =} \StringTok{\textquotesingle{}response\textquotesingle{}}\NormalTok{, }\AttributeTok{newdata =}\NormalTok{ test\_set[}\SpecialCharTok{{-}}\DecValTok{3}\NormalTok{])}
\NormalTok{y\_pred }\OtherTok{=} \FunctionTok{ifelse}\NormalTok{(prob\_pred }\SpecialCharTok{\textgreater{}} \FloatTok{0.5}\NormalTok{, }\DecValTok{1}\NormalTok{, }\DecValTok{0}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\hypertarget{making-the-confusion-matrix}{%
\subsection{Making the Confusion Matrix}\label{making-the-confusion-matrix}}

Python

\begin{Shaded}
\begin{Highlighting}[]
\ImportTok{from}\NormalTok{ sklearn.metrics }\ImportTok{import}\NormalTok{ confusion\_matrix, accuracy\_score}
\NormalTok{cm }\OperatorTok{=}\NormalTok{ confusion\_matrix(y\_test, y\_pred)}
\BuiltInTok{print}\NormalTok{(cm)}
\CommentTok{\#\# [[65  3]}
\CommentTok{\#\#  [ 8 24]]}
\NormalTok{accuracy\_score(y\_test, y\_pred)}
\CommentTok{\#\# 0.89}
\end{Highlighting}
\end{Shaded}

R

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{cm }\OtherTok{=} \FunctionTok{table}\NormalTok{(test\_set[, }\DecValTok{3}\NormalTok{], y\_pred }\SpecialCharTok{\textgreater{}} \FloatTok{0.5}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\hypertarget{visualising-the-training-set-results-1}{%
\subsection{Visualising the Training set results}\label{visualising-the-training-set-results-1}}

Python

\begin{Shaded}
\begin{Highlighting}[]
\ImportTok{from}\NormalTok{ matplotlib.colors }\ImportTok{import}\NormalTok{ ListedColormap}
\NormalTok{X\_set, y\_set }\OperatorTok{=}\NormalTok{ sc.inverse\_transform(X\_train), y\_train}
\NormalTok{X1, X2 }\OperatorTok{=}\NormalTok{ np.meshgrid(np.arange(start }\OperatorTok{=}\NormalTok{ X\_set[:, }\DecValTok{0}\NormalTok{].}\BuiltInTok{min}\NormalTok{() }\OperatorTok{{-}} \DecValTok{10}\NormalTok{, stop }\OperatorTok{=}\NormalTok{ X\_set[:, }\DecValTok{0}\NormalTok{].}\BuiltInTok{max}\NormalTok{() }\OperatorTok{+} \DecValTok{10}\NormalTok{, step }\OperatorTok{=} \FloatTok{0.25}\NormalTok{),}
\NormalTok{                     np.arange(start }\OperatorTok{=}\NormalTok{ X\_set[:, }\DecValTok{1}\NormalTok{].}\BuiltInTok{min}\NormalTok{() }\OperatorTok{{-}} \DecValTok{1000}\NormalTok{, stop }\OperatorTok{=}\NormalTok{ X\_set[:, }\DecValTok{1}\NormalTok{].}\BuiltInTok{max}\NormalTok{() }\OperatorTok{+} \DecValTok{1000}\NormalTok{, step }\OperatorTok{=} \FloatTok{0.25}\NormalTok{))}
\NormalTok{plt.contourf(X1, X2, classifier.predict(sc.transform(np.array([X1.ravel(), X2.ravel()]).T)).reshape(X1.shape),}
\NormalTok{             alpha }\OperatorTok{=} \FloatTok{0.75}\NormalTok{, cmap }\OperatorTok{=}\NormalTok{ ListedColormap((}\StringTok{\textquotesingle{}red\textquotesingle{}}\NormalTok{, }\StringTok{\textquotesingle{}green\textquotesingle{}}\NormalTok{)))}
\NormalTok{plt.xlim(X1.}\BuiltInTok{min}\NormalTok{(), X1.}\BuiltInTok{max}\NormalTok{())}
\NormalTok{plt.ylim(X2.}\BuiltInTok{min}\NormalTok{(), X2.}\BuiltInTok{max}\NormalTok{())}
\ControlFlowTok{for}\NormalTok{ i, j }\KeywordTok{in} \BuiltInTok{enumerate}\NormalTok{(np.unique(y\_set)):}
\NormalTok{    plt.scatter(X\_set[y\_set }\OperatorTok{==}\NormalTok{ j, }\DecValTok{0}\NormalTok{], X\_set[y\_set }\OperatorTok{==}\NormalTok{ j, }\DecValTok{1}\NormalTok{], c }\OperatorTok{=}\NormalTok{ ListedColormap((}\StringTok{\textquotesingle{}red\textquotesingle{}}\NormalTok{, }\StringTok{\textquotesingle{}green\textquotesingle{}}\NormalTok{))(i), label }\OperatorTok{=}\NormalTok{ j)}
\NormalTok{plt.title(}\StringTok{\textquotesingle{}Logistic Regression (Training set)\textquotesingle{}}\NormalTok{)}
\NormalTok{plt.xlabel(}\StringTok{\textquotesingle{}Age\textquotesingle{}}\NormalTok{)}
\NormalTok{plt.ylabel(}\StringTok{\textquotesingle{}Estimated Salary\textquotesingle{}}\NormalTok{)}
\NormalTok{plt.legend()}
\NormalTok{plt.show()}
\end{Highlighting}
\end{Shaded}

R

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{library}\NormalTok{(ElemStatLearn)}
\NormalTok{set }\OtherTok{=}\NormalTok{ training\_set}
\NormalTok{X1 }\OtherTok{=} \FunctionTok{seq}\NormalTok{(}\FunctionTok{min}\NormalTok{(set[, }\DecValTok{1}\NormalTok{]) }\SpecialCharTok{{-}} \DecValTok{1}\NormalTok{, }\FunctionTok{max}\NormalTok{(set[, }\DecValTok{1}\NormalTok{]) }\SpecialCharTok{+} \DecValTok{1}\NormalTok{, }\AttributeTok{by =} \FloatTok{0.01}\NormalTok{)}
\NormalTok{X2 }\OtherTok{=} \FunctionTok{seq}\NormalTok{(}\FunctionTok{min}\NormalTok{(set[, }\DecValTok{2}\NormalTok{]) }\SpecialCharTok{{-}} \DecValTok{1}\NormalTok{, }\FunctionTok{max}\NormalTok{(set[, }\DecValTok{2}\NormalTok{]) }\SpecialCharTok{+} \DecValTok{1}\NormalTok{, }\AttributeTok{by =} \FloatTok{0.01}\NormalTok{)}
\NormalTok{grid\_set }\OtherTok{=} \FunctionTok{expand.grid}\NormalTok{(X1, X2)}
\FunctionTok{colnames}\NormalTok{(grid\_set) }\OtherTok{=} \FunctionTok{c}\NormalTok{(}\StringTok{\textquotesingle{}Age\textquotesingle{}}\NormalTok{, }\StringTok{\textquotesingle{}EstimatedSalary\textquotesingle{}}\NormalTok{)}
\NormalTok{prob\_set }\OtherTok{=} \FunctionTok{predict}\NormalTok{(classifier, }\AttributeTok{type =} \StringTok{\textquotesingle{}response\textquotesingle{}}\NormalTok{, }\AttributeTok{newdata =}\NormalTok{ grid\_set)}
\NormalTok{y\_grid }\OtherTok{=} \FunctionTok{ifelse}\NormalTok{(prob\_set }\SpecialCharTok{\textgreater{}} \FloatTok{0.5}\NormalTok{, }\DecValTok{1}\NormalTok{, }\DecValTok{0}\NormalTok{)}
\FunctionTok{plot}\NormalTok{(set[, }\SpecialCharTok{{-}}\DecValTok{3}\NormalTok{],}
     \AttributeTok{main =} \StringTok{\textquotesingle{}Logistic Regression (Training set)\textquotesingle{}}\NormalTok{,}
     \AttributeTok{xlab =} \StringTok{\textquotesingle{}Age\textquotesingle{}}\NormalTok{, }\AttributeTok{ylab =} \StringTok{\textquotesingle{}Estimated Salary\textquotesingle{}}\NormalTok{,}
     \AttributeTok{xlim =} \FunctionTok{range}\NormalTok{(X1), }\AttributeTok{ylim =} \FunctionTok{range}\NormalTok{(X2))}
\FunctionTok{contour}\NormalTok{(X1, X2, }\FunctionTok{matrix}\NormalTok{(}\FunctionTok{as.numeric}\NormalTok{(y\_grid), }\FunctionTok{length}\NormalTok{(X1), }\FunctionTok{length}\NormalTok{(X2)), }\AttributeTok{add =} \ConstantTok{TRUE}\NormalTok{)}
\FunctionTok{points}\NormalTok{(grid\_set, }\AttributeTok{pch =} \StringTok{\textquotesingle{}.\textquotesingle{}}\NormalTok{, }\AttributeTok{col =} \FunctionTok{ifelse}\NormalTok{(y\_grid }\SpecialCharTok{==} \DecValTok{1}\NormalTok{, }\StringTok{\textquotesingle{}springgreen3\textquotesingle{}}\NormalTok{, }\StringTok{\textquotesingle{}tomato\textquotesingle{}}\NormalTok{))}
\FunctionTok{points}\NormalTok{(set, }\AttributeTok{pch =} \DecValTok{21}\NormalTok{, }\AttributeTok{bg =} \FunctionTok{ifelse}\NormalTok{(set[, }\DecValTok{3}\NormalTok{] }\SpecialCharTok{==} \DecValTok{1}\NormalTok{, }\StringTok{\textquotesingle{}green4\textquotesingle{}}\NormalTok{, }\StringTok{\textquotesingle{}red3\textquotesingle{}}\NormalTok{))}
\end{Highlighting}
\end{Shaded}

\includegraphics{_main_files/figure-latex/unnamed-chunk-101-1.pdf}

\hypertarget{visualising-the-test-set-results-1}{%
\subsection{Visualising the Test set results}\label{visualising-the-test-set-results-1}}

Python

\begin{Shaded}
\begin{Highlighting}[]
\ImportTok{from}\NormalTok{ matplotlib.colors }\ImportTok{import}\NormalTok{ ListedColormap}
\NormalTok{X\_set, y\_set }\OperatorTok{=}\NormalTok{ sc.inverse\_transform(X\_test), y\_test}
\NormalTok{X1, X2 }\OperatorTok{=}\NormalTok{ np.meshgrid(np.arange(start }\OperatorTok{=}\NormalTok{ X\_set[:, }\DecValTok{0}\NormalTok{].}\BuiltInTok{min}\NormalTok{() }\OperatorTok{{-}} \DecValTok{10}\NormalTok{, stop }\OperatorTok{=}\NormalTok{ X\_set[:, }\DecValTok{0}\NormalTok{].}\BuiltInTok{max}\NormalTok{() }\OperatorTok{+} \DecValTok{10}\NormalTok{, step }\OperatorTok{=} \FloatTok{0.25}\NormalTok{),}
\NormalTok{                     np.arange(start }\OperatorTok{=}\NormalTok{ X\_set[:, }\DecValTok{1}\NormalTok{].}\BuiltInTok{min}\NormalTok{() }\OperatorTok{{-}} \DecValTok{1000}\NormalTok{, stop }\OperatorTok{=}\NormalTok{ X\_set[:, }\DecValTok{1}\NormalTok{].}\BuiltInTok{max}\NormalTok{() }\OperatorTok{+} \DecValTok{1000}\NormalTok{, step }\OperatorTok{=} \FloatTok{0.25}\NormalTok{))}
\NormalTok{plt.contourf(X1, X2, classifier.predict(sc.transform(np.array([X1.ravel(), X2.ravel()]).T)).reshape(X1.shape),}
\NormalTok{             alpha }\OperatorTok{=} \FloatTok{0.75}\NormalTok{, cmap }\OperatorTok{=}\NormalTok{ ListedColormap((}\StringTok{\textquotesingle{}red\textquotesingle{}}\NormalTok{, }\StringTok{\textquotesingle{}green\textquotesingle{}}\NormalTok{)))}
\NormalTok{plt.xlim(X1.}\BuiltInTok{min}\NormalTok{(), X1.}\BuiltInTok{max}\NormalTok{())}
\NormalTok{plt.ylim(X2.}\BuiltInTok{min}\NormalTok{(), X2.}\BuiltInTok{max}\NormalTok{())}
\ControlFlowTok{for}\NormalTok{ i, j }\KeywordTok{in} \BuiltInTok{enumerate}\NormalTok{(np.unique(y\_set)):}
\NormalTok{    plt.scatter(X\_set[y\_set }\OperatorTok{==}\NormalTok{ j, }\DecValTok{0}\NormalTok{], X\_set[y\_set }\OperatorTok{==}\NormalTok{ j, }\DecValTok{1}\NormalTok{], c }\OperatorTok{=}\NormalTok{ ListedColormap((}\StringTok{\textquotesingle{}red\textquotesingle{}}\NormalTok{, }\StringTok{\textquotesingle{}green\textquotesingle{}}\NormalTok{))(i), label }\OperatorTok{=}\NormalTok{ j)}
\NormalTok{plt.title(}\StringTok{\textquotesingle{}Logistic Regression (Test set)\textquotesingle{}}\NormalTok{)}
\NormalTok{plt.xlabel(}\StringTok{\textquotesingle{}Age\textquotesingle{}}\NormalTok{)}
\NormalTok{plt.ylabel(}\StringTok{\textquotesingle{}Estimated Salary\textquotesingle{}}\NormalTok{)}
\NormalTok{plt.legend()}
\NormalTok{plt.show()}
\end{Highlighting}
\end{Shaded}

R

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{library}\NormalTok{(ElemStatLearn)}
\NormalTok{set }\OtherTok{=}\NormalTok{ test\_set}
\NormalTok{X1 }\OtherTok{=} \FunctionTok{seq}\NormalTok{(}\FunctionTok{min}\NormalTok{(set[, }\DecValTok{1}\NormalTok{]) }\SpecialCharTok{{-}} \DecValTok{1}\NormalTok{, }\FunctionTok{max}\NormalTok{(set[, }\DecValTok{1}\NormalTok{]) }\SpecialCharTok{+} \DecValTok{1}\NormalTok{, }\AttributeTok{by =} \FloatTok{0.01}\NormalTok{)}
\NormalTok{X2 }\OtherTok{=} \FunctionTok{seq}\NormalTok{(}\FunctionTok{min}\NormalTok{(set[, }\DecValTok{2}\NormalTok{]) }\SpecialCharTok{{-}} \DecValTok{1}\NormalTok{, }\FunctionTok{max}\NormalTok{(set[, }\DecValTok{2}\NormalTok{]) }\SpecialCharTok{+} \DecValTok{1}\NormalTok{, }\AttributeTok{by =} \FloatTok{0.01}\NormalTok{)}
\NormalTok{grid\_set }\OtherTok{=} \FunctionTok{expand.grid}\NormalTok{(X1, X2)}
\FunctionTok{colnames}\NormalTok{(grid\_set) }\OtherTok{=} \FunctionTok{c}\NormalTok{(}\StringTok{\textquotesingle{}Age\textquotesingle{}}\NormalTok{, }\StringTok{\textquotesingle{}EstimatedSalary\textquotesingle{}}\NormalTok{)}
\NormalTok{prob\_set }\OtherTok{=} \FunctionTok{predict}\NormalTok{(classifier, }\AttributeTok{type =} \StringTok{\textquotesingle{}response\textquotesingle{}}\NormalTok{, }\AttributeTok{newdata =}\NormalTok{ grid\_set)}
\NormalTok{y\_grid }\OtherTok{=} \FunctionTok{ifelse}\NormalTok{(prob\_set }\SpecialCharTok{\textgreater{}} \FloatTok{0.5}\NormalTok{, }\DecValTok{1}\NormalTok{, }\DecValTok{0}\NormalTok{)}
\FunctionTok{plot}\NormalTok{(set[, }\SpecialCharTok{{-}}\DecValTok{3}\NormalTok{],}
     \AttributeTok{main =} \StringTok{\textquotesingle{}Logistic Regression (Test set)\textquotesingle{}}\NormalTok{,}
     \AttributeTok{xlab =} \StringTok{\textquotesingle{}Age\textquotesingle{}}\NormalTok{, }\AttributeTok{ylab =} \StringTok{\textquotesingle{}Estimated Salary\textquotesingle{}}\NormalTok{,}
     \AttributeTok{xlim =} \FunctionTok{range}\NormalTok{(X1), }\AttributeTok{ylim =} \FunctionTok{range}\NormalTok{(X2))}
\FunctionTok{contour}\NormalTok{(X1, X2, }\FunctionTok{matrix}\NormalTok{(}\FunctionTok{as.numeric}\NormalTok{(y\_grid), }\FunctionTok{length}\NormalTok{(X1), }\FunctionTok{length}\NormalTok{(X2)), }\AttributeTok{add =} \ConstantTok{TRUE}\NormalTok{)}
\FunctionTok{points}\NormalTok{(grid\_set, }\AttributeTok{pch =} \StringTok{\textquotesingle{}.\textquotesingle{}}\NormalTok{, }\AttributeTok{col =} \FunctionTok{ifelse}\NormalTok{(y\_grid }\SpecialCharTok{==} \DecValTok{1}\NormalTok{, }\StringTok{\textquotesingle{}springgreen3\textquotesingle{}}\NormalTok{, }\StringTok{\textquotesingle{}tomato\textquotesingle{}}\NormalTok{))}
\FunctionTok{points}\NormalTok{(set, }\AttributeTok{pch =} \DecValTok{21}\NormalTok{, }\AttributeTok{bg =} \FunctionTok{ifelse}\NormalTok{(set[, }\DecValTok{3}\NormalTok{] }\SpecialCharTok{==} \DecValTok{1}\NormalTok{, }\StringTok{\textquotesingle{}green4\textquotesingle{}}\NormalTok{, }\StringTok{\textquotesingle{}red3\textquotesingle{}}\NormalTok{))}
\end{Highlighting}
\end{Shaded}

\includegraphics{_main_files/figure-latex/unnamed-chunk-103-1.pdf}

\hypertarget{k-nearest-neighbours-k-nn}{%
\section{K-Nearest Neighbours (K-NN)}\label{k-nearest-neighbours-k-nn}}

\hypertarget{importing-the-libraries-8}{%
\subsection{Importing the libraries}\label{importing-the-libraries-8}}

Python

\begin{Shaded}
\begin{Highlighting}[]
\ImportTok{import}\NormalTok{ numpy }\ImportTok{as}\NormalTok{ np}
\ImportTok{import}\NormalTok{ matplotlib.pyplot }\ImportTok{as}\NormalTok{ plt}
\ImportTok{import}\NormalTok{ pandas }\ImportTok{as}\NormalTok{ pd}
\end{Highlighting}
\end{Shaded}

\hypertarget{importing-the-dataset-8}{%
\subsection{Importing the dataset}\label{importing-the-dataset-8}}

Python

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{dataset }\OperatorTok{=}\NormalTok{ pd.read\_csv(}\StringTok{\textquotesingle{}Social\_Network\_Ads.csv\textquotesingle{}}\NormalTok{)}
\NormalTok{X }\OperatorTok{=}\NormalTok{ dataset.iloc[:, :}\OperatorTok{{-}}\DecValTok{1}\NormalTok{].values}
\NormalTok{y }\OperatorTok{=}\NormalTok{ dataset.iloc[:, }\OperatorTok{{-}}\DecValTok{1}\NormalTok{].values}
\end{Highlighting}
\end{Shaded}

R

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{dataset }\OtherTok{=} \FunctionTok{read.csv}\NormalTok{(}\StringTok{\textquotesingle{}Social\_Network\_Ads.csv\textquotesingle{}}\NormalTok{)}
\CommentTok{\# dataset = dataset[3:5]}
\end{Highlighting}
\end{Shaded}

\hypertarget{encoding-the-target-feature-as-factor-1}{%
\subsection{Encoding the target feature as factor}\label{encoding-the-target-feature-as-factor-1}}

R

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{dataset}\SpecialCharTok{$}\NormalTok{Purchased }\OtherTok{=} \FunctionTok{factor}\NormalTok{(dataset}\SpecialCharTok{$}\NormalTok{Purchased, }\AttributeTok{levels =} \FunctionTok{c}\NormalTok{(}\DecValTok{0}\NormalTok{, }\DecValTok{1}\NormalTok{))}
\end{Highlighting}
\end{Shaded}

\hypertarget{splitting-the-dataset-into-the-training-set-and-test-set-4}{%
\subsection{Splitting the dataset into the Training set and Test set}\label{splitting-the-dataset-into-the-training-set-and-test-set-4}}

Python

\begin{Shaded}
\begin{Highlighting}[]
\ImportTok{from}\NormalTok{ sklearn.model\_selection }\ImportTok{import}\NormalTok{ train\_test\_split}
\NormalTok{X\_train, X\_test, y\_train, y\_test }\OperatorTok{=}\NormalTok{ train\_test\_split(X, y, test\_size }\OperatorTok{=} \FloatTok{0.25}\NormalTok{, random\_state }\OperatorTok{=} \DecValTok{0}\NormalTok{)}
\BuiltInTok{print}\NormalTok{(X\_train)}
\CommentTok{\#\# [[    44  39000]}
\CommentTok{\#\#  [    32 120000]}
\CommentTok{\#\#  [    38  50000]}
\CommentTok{\#\#  [    32 135000]}
\CommentTok{\#\#  [    52  21000]}
\CommentTok{\#\#  [    53 104000]}
\CommentTok{\#\#  [    39  42000]}
\CommentTok{\#\#  [    38  61000]}
\CommentTok{\#\#  [    36  50000]}
\CommentTok{\#\#  [    36  63000]}
\CommentTok{\#\#  [    35  25000]}
\CommentTok{\#\#  [    35  50000]}
\CommentTok{\#\#  [    42  73000]}
\CommentTok{\#\#  [    47  49000]}
\CommentTok{\#\#  [    59  29000]}
\CommentTok{\#\#  [    49  65000]}
\CommentTok{\#\#  [    45 131000]}
\CommentTok{\#\#  [    31  89000]}
\CommentTok{\#\#  [    46  82000]}
\CommentTok{\#\#  [    47  51000]}
\CommentTok{\#\#  [    26  15000]}
\CommentTok{\#\#  [    60 102000]}
\CommentTok{\#\#  [    38 112000]}
\CommentTok{\#\#  [    40 107000]}
\CommentTok{\#\#  [    42  53000]}
\CommentTok{\#\#  [    35  59000]}
\CommentTok{\#\#  [    48  41000]}
\CommentTok{\#\#  [    48 134000]}
\CommentTok{\#\#  [    38 113000]}
\CommentTok{\#\#  [    29 148000]}
\CommentTok{\#\#  [    26  15000]}
\CommentTok{\#\#  [    60  42000]}
\CommentTok{\#\#  [    24  19000]}
\CommentTok{\#\#  [    42 149000]}
\CommentTok{\#\#  [    46  96000]}
\CommentTok{\#\#  [    28  59000]}
\CommentTok{\#\#  [    39  96000]}
\CommentTok{\#\#  [    28  89000]}
\CommentTok{\#\#  [    41  72000]}
\CommentTok{\#\#  [    45  26000]}
\CommentTok{\#\#  [    33  69000]}
\CommentTok{\#\#  [    20  82000]}
\CommentTok{\#\#  [    31  74000]}
\CommentTok{\#\#  [    42  80000]}
\CommentTok{\#\#  [    35  72000]}
\CommentTok{\#\#  [    33 149000]}
\CommentTok{\#\#  [    40  71000]}
\CommentTok{\#\#  [    51 146000]}
\CommentTok{\#\#  [    46  79000]}
\CommentTok{\#\#  [    35  75000]}
\CommentTok{\#\#  [    38  51000]}
\CommentTok{\#\#  [    36  75000]}
\CommentTok{\#\#  [    37  78000]}
\CommentTok{\#\#  [    38  61000]}
\CommentTok{\#\#  [    60 108000]}
\CommentTok{\#\#  [    20  82000]}
\CommentTok{\#\#  [    57  74000]}
\CommentTok{\#\#  [    42  65000]}
\CommentTok{\#\#  [    26  80000]}
\CommentTok{\#\#  [    46 117000]}
\CommentTok{\#\#  [    35  61000]}
\CommentTok{\#\#  [    21  68000]}
\CommentTok{\#\#  [    28  44000]}
\CommentTok{\#\#  [    41  87000]}
\CommentTok{\#\#  [    37  33000]}
\CommentTok{\#\#  [    27  90000]}
\CommentTok{\#\#  [    39  42000]}
\CommentTok{\#\#  [    28 123000]}
\CommentTok{\#\#  [    31 118000]}
\CommentTok{\#\#  [    25  87000]}
\CommentTok{\#\#  [    35  71000]}
\CommentTok{\#\#  [    37  70000]}
\CommentTok{\#\#  [    35  39000]}
\CommentTok{\#\#  [    47  23000]}
\CommentTok{\#\#  [    35 147000]}
\CommentTok{\#\#  [    48 138000]}
\CommentTok{\#\#  [    26  86000]}
\CommentTok{\#\#  [    25  79000]}
\CommentTok{\#\#  [    52 138000]}
\CommentTok{\#\#  [    51  23000]}
\CommentTok{\#\#  [    35  60000]}
\CommentTok{\#\#  [    33 113000]}
\CommentTok{\#\#  [    30 107000]}
\CommentTok{\#\#  [    48  33000]}
\CommentTok{\#\#  [    41  80000]}
\CommentTok{\#\#  [    48  96000]}
\CommentTok{\#\#  [    31  18000]}
\CommentTok{\#\#  [    31  71000]}
\CommentTok{\#\#  [    43 129000]}
\CommentTok{\#\#  [    59  76000]}
\CommentTok{\#\#  [    18  44000]}
\CommentTok{\#\#  [    36 118000]}
\CommentTok{\#\#  [    42  90000]}
\CommentTok{\#\#  [    47  30000]}
\CommentTok{\#\#  [    26  43000]}
\CommentTok{\#\#  [    40  78000]}
\CommentTok{\#\#  [    46  59000]}
\CommentTok{\#\#  [    59  42000]}
\CommentTok{\#\#  [    46  74000]}
\CommentTok{\#\#  [    35  91000]}
\CommentTok{\#\#  [    28  59000]}
\CommentTok{\#\#  [    40  57000]}
\CommentTok{\#\#  [    59 143000]}
\CommentTok{\#\#  [    57  26000]}
\CommentTok{\#\#  [    52  38000]}
\CommentTok{\#\#  [    47 113000]}
\CommentTok{\#\#  [    53 143000]}
\CommentTok{\#\#  [    35  27000]}
\CommentTok{\#\#  [    58 101000]}
\CommentTok{\#\#  [    45  45000]}
\CommentTok{\#\#  [    23  82000]}
\CommentTok{\#\#  [    46  23000]}
\CommentTok{\#\#  [    42  65000]}
\CommentTok{\#\#  [    28  84000]}
\CommentTok{\#\#  [    38  59000]}
\CommentTok{\#\#  [    26  84000]}
\CommentTok{\#\#  [    29  28000]}
\CommentTok{\#\#  [    37  71000]}
\CommentTok{\#\#  [    22  55000]}
\CommentTok{\#\#  [    48  35000]}
\CommentTok{\#\#  [    49  28000]}
\CommentTok{\#\#  [    38  65000]}
\CommentTok{\#\#  [    27  17000]}
\CommentTok{\#\#  [    46  28000]}
\CommentTok{\#\#  [    48 141000]}
\CommentTok{\#\#  [    26  17000]}
\CommentTok{\#\#  [    35  97000]}
\CommentTok{\#\#  [    39  59000]}
\CommentTok{\#\#  [    24  27000]}
\CommentTok{\#\#  [    32  18000]}
\CommentTok{\#\#  [    46  88000]}
\CommentTok{\#\#  [    35  58000]}
\CommentTok{\#\#  [    56  60000]}
\CommentTok{\#\#  [    47  34000]}
\CommentTok{\#\#  [    40  72000]}
\CommentTok{\#\#  [    32 100000]}
\CommentTok{\#\#  [    19  21000]}
\CommentTok{\#\#  [    25  90000]}
\CommentTok{\#\#  [    35  88000]}
\CommentTok{\#\#  [    28  32000]}
\CommentTok{\#\#  [    50  20000]}
\CommentTok{\#\#  [    40  59000]}
\CommentTok{\#\#  [    50  44000]}
\CommentTok{\#\#  [    35  72000]}
\CommentTok{\#\#  [    40 142000]}
\CommentTok{\#\#  [    46  32000]}
\CommentTok{\#\#  [    39  71000]}
\CommentTok{\#\#  [    20  74000]}
\CommentTok{\#\#  [    29  75000]}
\CommentTok{\#\#  [    31  76000]}
\CommentTok{\#\#  [    47  25000]}
\CommentTok{\#\#  [    40  61000]}
\CommentTok{\#\#  [    34 112000]}
\CommentTok{\#\#  [    38  80000]}
\CommentTok{\#\#  [    42  75000]}
\CommentTok{\#\#  [    47  47000]}
\CommentTok{\#\#  [    39  75000]}
\CommentTok{\#\#  [    19  25000]}
\CommentTok{\#\#  [    37  80000]}
\CommentTok{\#\#  [    36  60000]}
\CommentTok{\#\#  [    41  52000]}
\CommentTok{\#\#  [    36 125000]}
\CommentTok{\#\#  [    48  29000]}
\CommentTok{\#\#  [    36 126000]}
\CommentTok{\#\#  [    51 134000]}
\CommentTok{\#\#  [    27  57000]}
\CommentTok{\#\#  [    38  71000]}
\CommentTok{\#\#  [    39  61000]}
\CommentTok{\#\#  [    22  27000]}
\CommentTok{\#\#  [    33  60000]}
\CommentTok{\#\#  [    48  74000]}
\CommentTok{\#\#  [    58  23000]}
\CommentTok{\#\#  [    53  72000]}
\CommentTok{\#\#  [    32 117000]}
\CommentTok{\#\#  [    54  70000]}
\CommentTok{\#\#  [    30  80000]}
\CommentTok{\#\#  [    58  95000]}
\CommentTok{\#\#  [    26  52000]}
\CommentTok{\#\#  [    45  79000]}
\CommentTok{\#\#  [    24  55000]}
\CommentTok{\#\#  [    40  75000]}
\CommentTok{\#\#  [    33  28000]}
\CommentTok{\#\#  [    44 139000]}
\CommentTok{\#\#  [    22  18000]}
\CommentTok{\#\#  [    33  51000]}
\CommentTok{\#\#  [    43 133000]}
\CommentTok{\#\#  [    24  32000]}
\CommentTok{\#\#  [    46  22000]}
\CommentTok{\#\#  [    35  55000]}
\CommentTok{\#\#  [    54 104000]}
\CommentTok{\#\#  [    48 119000]}
\CommentTok{\#\#  [    35  53000]}
\CommentTok{\#\#  [    37 144000]}
\CommentTok{\#\#  [    23  66000]}
\CommentTok{\#\#  [    37 137000]}
\CommentTok{\#\#  [    31  58000]}
\CommentTok{\#\#  [    33  41000]}
\CommentTok{\#\#  [    45  22000]}
\CommentTok{\#\#  [    30  15000]}
\CommentTok{\#\#  [    19  19000]}
\CommentTok{\#\#  [    49  74000]}
\CommentTok{\#\#  [    39 122000]}
\CommentTok{\#\#  [    35  73000]}
\CommentTok{\#\#  [    39  71000]}
\CommentTok{\#\#  [    24  23000]}
\CommentTok{\#\#  [    41  72000]}
\CommentTok{\#\#  [    29  83000]}
\CommentTok{\#\#  [    54  26000]}
\CommentTok{\#\#  [    35  44000]}
\CommentTok{\#\#  [    37  75000]}
\CommentTok{\#\#  [    29  47000]}
\CommentTok{\#\#  [    31  68000]}
\CommentTok{\#\#  [    42  54000]}
\CommentTok{\#\#  [    30 135000]}
\CommentTok{\#\#  [    52 114000]}
\CommentTok{\#\#  [    50  36000]}
\CommentTok{\#\#  [    56 133000]}
\CommentTok{\#\#  [    29  61000]}
\CommentTok{\#\#  [    30  89000]}
\CommentTok{\#\#  [    26  16000]}
\CommentTok{\#\#  [    33  31000]}
\CommentTok{\#\#  [    41  72000]}
\CommentTok{\#\#  [    36  33000]}
\CommentTok{\#\#  [    55 125000]}
\CommentTok{\#\#  [    48 131000]}
\CommentTok{\#\#  [    41  71000]}
\CommentTok{\#\#  [    30  62000]}
\CommentTok{\#\#  [    37  72000]}
\CommentTok{\#\#  [    41  63000]}
\CommentTok{\#\#  [    58  47000]}
\CommentTok{\#\#  [    30 116000]}
\CommentTok{\#\#  [    20  49000]}
\CommentTok{\#\#  [    37  74000]}
\CommentTok{\#\#  [    41  59000]}
\CommentTok{\#\#  [    49  89000]}
\CommentTok{\#\#  [    28  79000]}
\CommentTok{\#\#  [    53  82000]}
\CommentTok{\#\#  [    40  57000]}
\CommentTok{\#\#  [    60  34000]}
\CommentTok{\#\#  [    35 108000]}
\CommentTok{\#\#  [    21  72000]}
\CommentTok{\#\#  [    38  71000]}
\CommentTok{\#\#  [    39 106000]}
\CommentTok{\#\#  [    37  57000]}
\CommentTok{\#\#  [    26  72000]}
\CommentTok{\#\#  [    35  23000]}
\CommentTok{\#\#  [    54 108000]}
\CommentTok{\#\#  [    30  17000]}
\CommentTok{\#\#  [    39 134000]}
\CommentTok{\#\#  [    29  43000]}
\CommentTok{\#\#  [    33  43000]}
\CommentTok{\#\#  [    35  38000]}
\CommentTok{\#\#  [    41  45000]}
\CommentTok{\#\#  [    41  72000]}
\CommentTok{\#\#  [    39 134000]}
\CommentTok{\#\#  [    27 137000]}
\CommentTok{\#\#  [    21  16000]}
\CommentTok{\#\#  [    26  32000]}
\CommentTok{\#\#  [    31  66000]}
\CommentTok{\#\#  [    39  73000]}
\CommentTok{\#\#  [    41  79000]}
\CommentTok{\#\#  [    47  50000]}
\CommentTok{\#\#  [    41  30000]}
\CommentTok{\#\#  [    37  93000]}
\CommentTok{\#\#  [    60  46000]}
\CommentTok{\#\#  [    25  22000]}
\CommentTok{\#\#  [    28  37000]}
\CommentTok{\#\#  [    38  55000]}
\CommentTok{\#\#  [    36  54000]}
\CommentTok{\#\#  [    20  36000]}
\CommentTok{\#\#  [    56 104000]}
\CommentTok{\#\#  [    40  57000]}
\CommentTok{\#\#  [    42 108000]}
\CommentTok{\#\#  [    20  23000]}
\CommentTok{\#\#  [    40  65000]}
\CommentTok{\#\#  [    47  20000]}
\CommentTok{\#\#  [    18  86000]}
\CommentTok{\#\#  [    35  79000]}
\CommentTok{\#\#  [    57  33000]}
\CommentTok{\#\#  [    34  72000]}
\CommentTok{\#\#  [    49  39000]}
\CommentTok{\#\#  [    27  31000]}
\CommentTok{\#\#  [    19  70000]}
\CommentTok{\#\#  [    39  79000]}
\CommentTok{\#\#  [    26  81000]}
\CommentTok{\#\#  [    25  80000]}
\CommentTok{\#\#  [    28  85000]}
\CommentTok{\#\#  [    55  39000]}
\CommentTok{\#\#  [    50  88000]}
\CommentTok{\#\#  [    49  88000]}
\CommentTok{\#\#  [    52 150000]}
\CommentTok{\#\#  [    35  65000]}
\CommentTok{\#\#  [    42  54000]}
\CommentTok{\#\#  [    34  43000]}
\CommentTok{\#\#  [    37  52000]}
\CommentTok{\#\#  [    48  30000]}
\CommentTok{\#\#  [    29  43000]}
\CommentTok{\#\#  [    36  52000]}
\CommentTok{\#\#  [    27  54000]}
\CommentTok{\#\#  [    26 118000]]}
\BuiltInTok{print}\NormalTok{(y\_train)}
\CommentTok{\#\# [0 1 0 1 1 1 0 0 0 0 0 0 1 1 1 0 1 0 0 1 0 1 0 1 0 0 1 1 1 1 0 1 0 1 0 0 1}
\CommentTok{\#\#  0 0 1 0 0 0 0 0 1 1 1 1 0 0 0 1 0 1 0 1 0 0 1 0 0 0 1 0 0 0 1 1 0 0 1 0 1}
\CommentTok{\#\#  1 1 0 0 1 1 0 0 1 1 0 1 0 0 1 1 0 1 1 1 0 0 0 0 0 1 0 0 1 1 1 1 1 0 1 1 0}
\CommentTok{\#\#  1 0 0 0 0 0 0 0 1 1 0 0 1 0 0 1 0 0 0 1 0 1 1 0 1 0 0 0 0 1 0 0 0 1 1 0 0}
\CommentTok{\#\#  0 0 1 0 1 0 0 0 1 0 0 0 0 1 1 1 0 0 0 0 0 0 1 1 1 1 1 0 1 0 0 0 0 0 1 0 0}
\CommentTok{\#\#  0 0 0 0 1 1 0 1 0 1 0 0 1 0 0 0 1 0 0 0 0 0 1 0 0 0 0 0 1 0 1 1 0 0 0 0 0}
\CommentTok{\#\#  0 1 1 0 0 0 0 1 0 0 0 0 1 0 1 0 1 0 0 0 1 0 0 0 1 0 1 0 0 0 0 0 1 1 0 0 0}
\CommentTok{\#\#  0 0 1 0 1 1 0 0 0 0 0 1 0 1 0 0 1 0 0 1 0 1 0 0 0 0 0 0 1 1 1 1 0 0 0 0 1}
\CommentTok{\#\#  0 0 0 0]}
\BuiltInTok{print}\NormalTok{(X\_test)}
\CommentTok{\#\# [[    30  87000]}
\CommentTok{\#\#  [    38  50000]}
\CommentTok{\#\#  [    35  75000]}
\CommentTok{\#\#  [    30  79000]}
\CommentTok{\#\#  [    35  50000]}
\CommentTok{\#\#  [    27  20000]}
\CommentTok{\#\#  [    31  15000]}
\CommentTok{\#\#  [    36 144000]}
\CommentTok{\#\#  [    18  68000]}
\CommentTok{\#\#  [    47  43000]}
\CommentTok{\#\#  [    30  49000]}
\CommentTok{\#\#  [    28  55000]}
\CommentTok{\#\#  [    37  55000]}
\CommentTok{\#\#  [    39  77000]}
\CommentTok{\#\#  [    20  86000]}
\CommentTok{\#\#  [    32 117000]}
\CommentTok{\#\#  [    37  77000]}
\CommentTok{\#\#  [    19  85000]}
\CommentTok{\#\#  [    55 130000]}
\CommentTok{\#\#  [    35  22000]}
\CommentTok{\#\#  [    35  47000]}
\CommentTok{\#\#  [    47 144000]}
\CommentTok{\#\#  [    41  51000]}
\CommentTok{\#\#  [    47 105000]}
\CommentTok{\#\#  [    23  28000]}
\CommentTok{\#\#  [    49 141000]}
\CommentTok{\#\#  [    28  87000]}
\CommentTok{\#\#  [    29  80000]}
\CommentTok{\#\#  [    37  62000]}
\CommentTok{\#\#  [    32  86000]}
\CommentTok{\#\#  [    21  88000]}
\CommentTok{\#\#  [    37  79000]}
\CommentTok{\#\#  [    57  60000]}
\CommentTok{\#\#  [    37  53000]}
\CommentTok{\#\#  [    24  58000]}
\CommentTok{\#\#  [    18  52000]}
\CommentTok{\#\#  [    22  81000]}
\CommentTok{\#\#  [    34  43000]}
\CommentTok{\#\#  [    31  34000]}
\CommentTok{\#\#  [    49  36000]}
\CommentTok{\#\#  [    27  88000]}
\CommentTok{\#\#  [    41  52000]}
\CommentTok{\#\#  [    27  84000]}
\CommentTok{\#\#  [    35  20000]}
\CommentTok{\#\#  [    43 112000]}
\CommentTok{\#\#  [    27  58000]}
\CommentTok{\#\#  [    37  80000]}
\CommentTok{\#\#  [    52  90000]}
\CommentTok{\#\#  [    26  30000]}
\CommentTok{\#\#  [    49  86000]}
\CommentTok{\#\#  [    57 122000]}
\CommentTok{\#\#  [    34  25000]}
\CommentTok{\#\#  [    35  57000]}
\CommentTok{\#\#  [    34 115000]}
\CommentTok{\#\#  [    59  88000]}
\CommentTok{\#\#  [    45  32000]}
\CommentTok{\#\#  [    29  83000]}
\CommentTok{\#\#  [    26  80000]}
\CommentTok{\#\#  [    49  28000]}
\CommentTok{\#\#  [    23  20000]}
\CommentTok{\#\#  [    32  18000]}
\CommentTok{\#\#  [    60  42000]}
\CommentTok{\#\#  [    19  76000]}
\CommentTok{\#\#  [    36  99000]}
\CommentTok{\#\#  [    19  26000]}
\CommentTok{\#\#  [    60  83000]}
\CommentTok{\#\#  [    24  89000]}
\CommentTok{\#\#  [    27  58000]}
\CommentTok{\#\#  [    40  47000]}
\CommentTok{\#\#  [    42  70000]}
\CommentTok{\#\#  [    32 150000]}
\CommentTok{\#\#  [    35  77000]}
\CommentTok{\#\#  [    22  63000]}
\CommentTok{\#\#  [    45  22000]}
\CommentTok{\#\#  [    27  89000]}
\CommentTok{\#\#  [    18  82000]}
\CommentTok{\#\#  [    42  79000]}
\CommentTok{\#\#  [    40  60000]}
\CommentTok{\#\#  [    53  34000]}
\CommentTok{\#\#  [    47 107000]}
\CommentTok{\#\#  [    58 144000]}
\CommentTok{\#\#  [    59  83000]}
\CommentTok{\#\#  [    24  55000]}
\CommentTok{\#\#  [    26  35000]}
\CommentTok{\#\#  [    58  38000]}
\CommentTok{\#\#  [    42  80000]}
\CommentTok{\#\#  [    40  75000]}
\CommentTok{\#\#  [    59 130000]}
\CommentTok{\#\#  [    46  41000]}
\CommentTok{\#\#  [    41  60000]}
\CommentTok{\#\#  [    42  64000]}
\CommentTok{\#\#  [    37 146000]}
\CommentTok{\#\#  [    23  48000]}
\CommentTok{\#\#  [    25  33000]}
\CommentTok{\#\#  [    24  84000]}
\CommentTok{\#\#  [    27  96000]}
\CommentTok{\#\#  [    23  63000]}
\CommentTok{\#\#  [    48  33000]}
\CommentTok{\#\#  [    48  90000]}
\CommentTok{\#\#  [    42 104000]]}
\BuiltInTok{print}\NormalTok{(y\_test)}
\CommentTok{\#\# [0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 1 0 0 1 0 1 0 1 0 0 0 0 0 1 1 0 0 0 0}
\CommentTok{\#\#  0 0 1 0 0 0 0 1 0 0 1 0 1 1 0 0 0 1 1 0 0 1 0 0 1 0 1 0 1 0 0 0 0 1 0 0 1}
\CommentTok{\#\#  0 0 0 0 1 1 1 0 0 0 1 1 0 1 1 0 0 1 0 0 0 1 0 1 1 1]}
\end{Highlighting}
\end{Shaded}

R

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\# install.packages(\textquotesingle{}caTools\textquotesingle{})}
\FunctionTok{library}\NormalTok{(caTools)}
\FunctionTok{set.seed}\NormalTok{(}\DecValTok{123}\NormalTok{)}
\NormalTok{split }\OtherTok{=} \FunctionTok{sample.split}\NormalTok{(dataset}\SpecialCharTok{$}\NormalTok{Purchased, }\AttributeTok{SplitRatio =} \FloatTok{0.75}\NormalTok{)}
\NormalTok{training\_set }\OtherTok{=} \FunctionTok{subset}\NormalTok{(dataset, split }\SpecialCharTok{==} \ConstantTok{TRUE}\NormalTok{)}
\NormalTok{test\_set }\OtherTok{=} \FunctionTok{subset}\NormalTok{(dataset, split }\SpecialCharTok{==} \ConstantTok{FALSE}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\hypertarget{feature-scaling-3}{%
\subsection{Feature Scaling}\label{feature-scaling-3}}

Python

\begin{Shaded}
\begin{Highlighting}[]
\ImportTok{from}\NormalTok{ sklearn.preprocessing }\ImportTok{import}\NormalTok{ StandardScaler}
\NormalTok{sc }\OperatorTok{=}\NormalTok{ StandardScaler()}
\NormalTok{X\_train }\OperatorTok{=}\NormalTok{ sc.fit\_transform(X\_train)}
\NormalTok{X\_test }\OperatorTok{=}\NormalTok{ sc.transform(X\_test)}
\BuiltInTok{print}\NormalTok{(X\_train)}
\CommentTok{\#\# [[ 0.58 {-}0.89]}
\CommentTok{\#\#  [{-}0.61  1.46]}
\CommentTok{\#\#  [{-}0.01 {-}0.57]}
\CommentTok{\#\#  [{-}0.61  1.9 ]}
\CommentTok{\#\#  [ 1.37 {-}1.41]}
\CommentTok{\#\#  [ 1.47  1.  ]}
\CommentTok{\#\#  [ 0.09 {-}0.8 ]}
\CommentTok{\#\#  [{-}0.01 {-}0.25]}
\CommentTok{\#\#  [{-}0.21 {-}0.57]}
\CommentTok{\#\#  [{-}0.21 {-}0.19]}
\CommentTok{\#\#  [{-}0.31 {-}1.29]}
\CommentTok{\#\#  [{-}0.31 {-}0.57]}
\CommentTok{\#\#  [ 0.38  0.1 ]}
\CommentTok{\#\#  [ 0.88 {-}0.6 ]}
\CommentTok{\#\#  [ 2.07 {-}1.18]}
\CommentTok{\#\#  [ 1.08 {-}0.13]}
\CommentTok{\#\#  [ 0.68  1.78]}
\CommentTok{\#\#  [{-}0.71  0.56]}
\CommentTok{\#\#  [ 0.78  0.36]}
\CommentTok{\#\#  [ 0.88 {-}0.54]}
\CommentTok{\#\#  [{-}1.2  {-}1.58]}
\CommentTok{\#\#  [ 2.17  0.94]}
\CommentTok{\#\#  [{-}0.01  1.23]}
\CommentTok{\#\#  [ 0.19  1.08]}
\CommentTok{\#\#  [ 0.38 {-}0.48]}
\CommentTok{\#\#  [{-}0.31 {-}0.31]}
\CommentTok{\#\#  [ 0.98 {-}0.83]}
\CommentTok{\#\#  [ 0.98  1.87]}
\CommentTok{\#\#  [{-}0.01  1.26]}
\CommentTok{\#\#  [{-}0.9   2.27]}
\CommentTok{\#\#  [{-}1.2  {-}1.58]}
\CommentTok{\#\#  [ 2.17 {-}0.8 ]}
\CommentTok{\#\#  [{-}1.4  {-}1.47]}
\CommentTok{\#\#  [ 0.38  2.3 ]}
\CommentTok{\#\#  [ 0.78  0.77]}
\CommentTok{\#\#  [{-}1.   {-}0.31]}
\CommentTok{\#\#  [ 0.09  0.77]}
\CommentTok{\#\#  [{-}1.    0.56]}
\CommentTok{\#\#  [ 0.28  0.07]}
\CommentTok{\#\#  [ 0.68 {-}1.26]}
\CommentTok{\#\#  [{-}0.51 {-}0.02]}
\CommentTok{\#\#  [{-}1.8   0.36]}
\CommentTok{\#\#  [{-}0.71  0.13]}
\CommentTok{\#\#  [ 0.38  0.3 ]}
\CommentTok{\#\#  [{-}0.31  0.07]}
\CommentTok{\#\#  [{-}0.51  2.3 ]}
\CommentTok{\#\#  [ 0.19  0.04]}
\CommentTok{\#\#  [ 1.27  2.22]}
\CommentTok{\#\#  [ 0.78  0.27]}
\CommentTok{\#\#  [{-}0.31  0.16]}
\CommentTok{\#\#  [{-}0.01 {-}0.54]}
\CommentTok{\#\#  [{-}0.21  0.16]}
\CommentTok{\#\#  [{-}0.11  0.24]}
\CommentTok{\#\#  [{-}0.01 {-}0.25]}
\CommentTok{\#\#  [ 2.17  1.11]}
\CommentTok{\#\#  [{-}1.8   0.36]}
\CommentTok{\#\#  [ 1.87  0.13]}
\CommentTok{\#\#  [ 0.38 {-}0.13]}
\CommentTok{\#\#  [{-}1.2   0.3 ]}
\CommentTok{\#\#  [ 0.78  1.37]}
\CommentTok{\#\#  [{-}0.31 {-}0.25]}
\CommentTok{\#\#  [{-}1.7  {-}0.05]}
\CommentTok{\#\#  [{-}1.   {-}0.74]}
\CommentTok{\#\#  [ 0.28  0.5 ]}
\CommentTok{\#\#  [{-}0.11 {-}1.06]}
\CommentTok{\#\#  [{-}1.1   0.59]}
\CommentTok{\#\#  [ 0.09 {-}0.8 ]}
\CommentTok{\#\#  [{-}1.    1.55]}
\CommentTok{\#\#  [{-}0.71  1.4 ]}
\CommentTok{\#\#  [{-}1.3   0.5 ]}
\CommentTok{\#\#  [{-}0.31  0.04]}
\CommentTok{\#\#  [{-}0.11  0.01]}
\CommentTok{\#\#  [{-}0.31 {-}0.89]}
\CommentTok{\#\#  [ 0.88 {-}1.35]}
\CommentTok{\#\#  [{-}0.31  2.24]}
\CommentTok{\#\#  [ 0.98  1.98]}
\CommentTok{\#\#  [{-}1.2   0.48]}
\CommentTok{\#\#  [{-}1.3   0.27]}
\CommentTok{\#\#  [ 1.37  1.98]}
\CommentTok{\#\#  [ 1.27 {-}1.35]}
\CommentTok{\#\#  [{-}0.31 {-}0.28]}
\CommentTok{\#\#  [{-}0.51  1.26]}
\CommentTok{\#\#  [{-}0.8   1.08]}
\CommentTok{\#\#  [ 0.98 {-}1.06]}
\CommentTok{\#\#  [ 0.28  0.3 ]}
\CommentTok{\#\#  [ 0.98  0.77]}
\CommentTok{\#\#  [{-}0.71 {-}1.5 ]}
\CommentTok{\#\#  [{-}0.71  0.04]}
\CommentTok{\#\#  [ 0.48  1.72]}
\CommentTok{\#\#  [ 2.07  0.19]}
\CommentTok{\#\#  [{-}1.99 {-}0.74]}
\CommentTok{\#\#  [{-}0.21  1.4 ]}
\CommentTok{\#\#  [ 0.38  0.59]}
\CommentTok{\#\#  [ 0.88 {-}1.15]}
\CommentTok{\#\#  [{-}1.2  {-}0.77]}
\CommentTok{\#\#  [ 0.19  0.24]}
\CommentTok{\#\#  [ 0.78 {-}0.31]}
\CommentTok{\#\#  [ 2.07 {-}0.8 ]}
\CommentTok{\#\#  [ 0.78  0.13]}
\CommentTok{\#\#  [{-}0.31  0.62]}
\CommentTok{\#\#  [{-}1.   {-}0.31]}
\CommentTok{\#\#  [ 0.19 {-}0.36]}
\CommentTok{\#\#  [ 2.07  2.13]}
\CommentTok{\#\#  [ 1.87 {-}1.26]}
\CommentTok{\#\#  [ 1.37 {-}0.92]}
\CommentTok{\#\#  [ 0.88  1.26]}
\CommentTok{\#\#  [ 1.47  2.13]}
\CommentTok{\#\#  [{-}0.31 {-}1.23]}
\CommentTok{\#\#  [ 1.97  0.91]}
\CommentTok{\#\#  [ 0.68 {-}0.71]}
\CommentTok{\#\#  [{-}1.5   0.36]}
\CommentTok{\#\#  [ 0.78 {-}1.35]}
\CommentTok{\#\#  [ 0.38 {-}0.13]}
\CommentTok{\#\#  [{-}1.    0.42]}
\CommentTok{\#\#  [{-}0.01 {-}0.31]}
\CommentTok{\#\#  [{-}1.2   0.42]}
\CommentTok{\#\#  [{-}0.9  {-}1.21]}
\CommentTok{\#\#  [{-}0.11  0.04]}
\CommentTok{\#\#  [{-}1.6  {-}0.42]}
\CommentTok{\#\#  [ 0.98 {-}1.  ]}
\CommentTok{\#\#  [ 1.08 {-}1.21]}
\CommentTok{\#\#  [{-}0.01 {-}0.13]}
\CommentTok{\#\#  [{-}1.1  {-}1.52]}
\CommentTok{\#\#  [ 0.78 {-}1.21]}
\CommentTok{\#\#  [ 0.98  2.07]}
\CommentTok{\#\#  [{-}1.2  {-}1.52]}
\CommentTok{\#\#  [{-}0.31  0.79]}
\CommentTok{\#\#  [ 0.09 {-}0.31]}
\CommentTok{\#\#  [{-}1.4  {-}1.23]}
\CommentTok{\#\#  [{-}0.61 {-}1.5 ]}
\CommentTok{\#\#  [ 0.78  0.53]}
\CommentTok{\#\#  [{-}0.31 {-}0.34]}
\CommentTok{\#\#  [ 1.77 {-}0.28]}
\CommentTok{\#\#  [ 0.88 {-}1.03]}
\CommentTok{\#\#  [ 0.19  0.07]}
\CommentTok{\#\#  [{-}0.61  0.88]}
\CommentTok{\#\#  [{-}1.89 {-}1.41]}
\CommentTok{\#\#  [{-}1.3   0.59]}
\CommentTok{\#\#  [{-}0.31  0.53]}
\CommentTok{\#\#  [{-}1.   {-}1.09]}
\CommentTok{\#\#  [ 1.18 {-}1.44]}
\CommentTok{\#\#  [ 0.19 {-}0.31]}
\CommentTok{\#\#  [ 1.18 {-}0.74]}
\CommentTok{\#\#  [{-}0.31  0.07]}
\CommentTok{\#\#  [ 0.19  2.1 ]}
\CommentTok{\#\#  [ 0.78 {-}1.09]}
\CommentTok{\#\#  [ 0.09  0.04]}
\CommentTok{\#\#  [{-}1.8   0.13]}
\CommentTok{\#\#  [{-}0.9   0.16]}
\CommentTok{\#\#  [{-}0.71  0.19]}
\CommentTok{\#\#  [ 0.88 {-}1.29]}
\CommentTok{\#\#  [ 0.19 {-}0.25]}
\CommentTok{\#\#  [{-}0.41  1.23]}
\CommentTok{\#\#  [{-}0.01  0.3 ]}
\CommentTok{\#\#  [ 0.38  0.16]}
\CommentTok{\#\#  [ 0.88 {-}0.65]}
\CommentTok{\#\#  [ 0.09  0.16]}
\CommentTok{\#\#  [{-}1.89 {-}1.29]}
\CommentTok{\#\#  [{-}0.11  0.3 ]}
\CommentTok{\#\#  [{-}0.21 {-}0.28]}
\CommentTok{\#\#  [ 0.28 {-}0.51]}
\CommentTok{\#\#  [{-}0.21  1.61]}
\CommentTok{\#\#  [ 0.98 {-}1.18]}
\CommentTok{\#\#  [{-}0.21  1.64]}
\CommentTok{\#\#  [ 1.27  1.87]}
\CommentTok{\#\#  [{-}1.1  {-}0.36]}
\CommentTok{\#\#  [{-}0.01  0.04]}
\CommentTok{\#\#  [ 0.09 {-}0.25]}
\CommentTok{\#\#  [{-}1.6  {-}1.23]}
\CommentTok{\#\#  [{-}0.51 {-}0.28]}
\CommentTok{\#\#  [ 0.98  0.13]}
\CommentTok{\#\#  [ 1.97 {-}1.35]}
\CommentTok{\#\#  [ 1.47  0.07]}
\CommentTok{\#\#  [{-}0.61  1.37]}
\CommentTok{\#\#  [ 1.57  0.01]}
\CommentTok{\#\#  [{-}0.8   0.3 ]}
\CommentTok{\#\#  [ 1.97  0.74]}
\CommentTok{\#\#  [{-}1.2  {-}0.51]}
\CommentTok{\#\#  [ 0.68  0.27]}
\CommentTok{\#\#  [{-}1.4  {-}0.42]}
\CommentTok{\#\#  [ 0.19  0.16]}
\CommentTok{\#\#  [{-}0.51 {-}1.21]}
\CommentTok{\#\#  [ 0.58  2.01]}
\CommentTok{\#\#  [{-}1.6  {-}1.5 ]}
\CommentTok{\#\#  [{-}0.51 {-}0.54]}
\CommentTok{\#\#  [ 0.48  1.84]}
\CommentTok{\#\#  [{-}1.4  {-}1.09]}
\CommentTok{\#\#  [ 0.78 {-}1.38]}
\CommentTok{\#\#  [{-}0.31 {-}0.42]}
\CommentTok{\#\#  [ 1.57  1.  ]}
\CommentTok{\#\#  [ 0.98  1.43]}
\CommentTok{\#\#  [{-}0.31 {-}0.48]}
\CommentTok{\#\#  [{-}0.11  2.16]}
\CommentTok{\#\#  [{-}1.5  {-}0.1 ]}
\CommentTok{\#\#  [{-}0.11  1.95]}
\CommentTok{\#\#  [{-}0.71 {-}0.34]}
\CommentTok{\#\#  [{-}0.51 {-}0.83]}
\CommentTok{\#\#  [ 0.68 {-}1.38]}
\CommentTok{\#\#  [{-}0.8  {-}1.58]}
\CommentTok{\#\#  [{-}1.89 {-}1.47]}
\CommentTok{\#\#  [ 1.08  0.13]}
\CommentTok{\#\#  [ 0.09  1.52]}
\CommentTok{\#\#  [{-}0.31  0.1 ]}
\CommentTok{\#\#  [ 0.09  0.04]}
\CommentTok{\#\#  [{-}1.4  {-}1.35]}
\CommentTok{\#\#  [ 0.28  0.07]}
\CommentTok{\#\#  [{-}0.9   0.39]}
\CommentTok{\#\#  [ 1.57 {-}1.26]}
\CommentTok{\#\#  [{-}0.31 {-}0.74]}
\CommentTok{\#\#  [{-}0.11  0.16]}
\CommentTok{\#\#  [{-}0.9  {-}0.65]}
\CommentTok{\#\#  [{-}0.71 {-}0.05]}
\CommentTok{\#\#  [ 0.38 {-}0.45]}
\CommentTok{\#\#  [{-}0.8   1.9 ]}
\CommentTok{\#\#  [ 1.37  1.29]}
\CommentTok{\#\#  [ 1.18 {-}0.97]}
\CommentTok{\#\#  [ 1.77  1.84]}
\CommentTok{\#\#  [{-}0.9  {-}0.25]}
\CommentTok{\#\#  [{-}0.8   0.56]}
\CommentTok{\#\#  [{-}1.2  {-}1.55]}
\CommentTok{\#\#  [{-}0.51 {-}1.12]}
\CommentTok{\#\#  [ 0.28  0.07]}
\CommentTok{\#\#  [{-}0.21 {-}1.06]}
\CommentTok{\#\#  [ 1.67  1.61]}
\CommentTok{\#\#  [ 0.98  1.78]}
\CommentTok{\#\#  [ 0.28  0.04]}
\CommentTok{\#\#  [{-}0.8  {-}0.22]}
\CommentTok{\#\#  [{-}0.11  0.07]}
\CommentTok{\#\#  [ 0.28 {-}0.19]}
\CommentTok{\#\#  [ 1.97 {-}0.65]}
\CommentTok{\#\#  [{-}0.8   1.35]}
\CommentTok{\#\#  [{-}1.8  {-}0.6 ]}
\CommentTok{\#\#  [{-}0.11  0.13]}
\CommentTok{\#\#  [ 0.28 {-}0.31]}
\CommentTok{\#\#  [ 1.08  0.56]}
\CommentTok{\#\#  [{-}1.    0.27]}
\CommentTok{\#\#  [ 1.47  0.36]}
\CommentTok{\#\#  [ 0.19 {-}0.36]}
\CommentTok{\#\#  [ 2.17 {-}1.03]}
\CommentTok{\#\#  [{-}0.31  1.11]}
\CommentTok{\#\#  [{-}1.7   0.07]}
\CommentTok{\#\#  [{-}0.01  0.04]}
\CommentTok{\#\#  [ 0.09  1.06]}
\CommentTok{\#\#  [{-}0.11 {-}0.36]}
\CommentTok{\#\#  [{-}1.2   0.07]}
\CommentTok{\#\#  [{-}0.31 {-}1.35]}
\CommentTok{\#\#  [ 1.57  1.11]}
\CommentTok{\#\#  [{-}0.8  {-}1.52]}
\CommentTok{\#\#  [ 0.09  1.87]}
\CommentTok{\#\#  [{-}0.9  {-}0.77]}
\CommentTok{\#\#  [{-}0.51 {-}0.77]}
\CommentTok{\#\#  [{-}0.31 {-}0.92]}
\CommentTok{\#\#  [ 0.28 {-}0.71]}
\CommentTok{\#\#  [ 0.28  0.07]}
\CommentTok{\#\#  [ 0.09  1.87]}
\CommentTok{\#\#  [{-}1.1   1.95]}
\CommentTok{\#\#  [{-}1.7  {-}1.55]}
\CommentTok{\#\#  [{-}1.2  {-}1.09]}
\CommentTok{\#\#  [{-}0.71 {-}0.1 ]}
\CommentTok{\#\#  [ 0.09  0.1 ]}
\CommentTok{\#\#  [ 0.28  0.27]}
\CommentTok{\#\#  [ 0.88 {-}0.57]}
\CommentTok{\#\#  [ 0.28 {-}1.15]}
\CommentTok{\#\#  [{-}0.11  0.68]}
\CommentTok{\#\#  [ 2.17 {-}0.68]}
\CommentTok{\#\#  [{-}1.3  {-}1.38]}
\CommentTok{\#\#  [{-}1.   {-}0.94]}
\CommentTok{\#\#  [{-}0.01 {-}0.42]}
\CommentTok{\#\#  [{-}0.21 {-}0.45]}
\CommentTok{\#\#  [{-}1.8  {-}0.97]}
\CommentTok{\#\#  [ 1.77  1.  ]}
\CommentTok{\#\#  [ 0.19 {-}0.36]}
\CommentTok{\#\#  [ 0.38  1.11]}
\CommentTok{\#\#  [{-}1.8  {-}1.35]}
\CommentTok{\#\#  [ 0.19 {-}0.13]}
\CommentTok{\#\#  [ 0.88 {-}1.44]}
\CommentTok{\#\#  [{-}1.99  0.48]}
\CommentTok{\#\#  [{-}0.31  0.27]}
\CommentTok{\#\#  [ 1.87 {-}1.06]}
\CommentTok{\#\#  [{-}0.41  0.07]}
\CommentTok{\#\#  [ 1.08 {-}0.89]}
\CommentTok{\#\#  [{-}1.1  {-}1.12]}
\CommentTok{\#\#  [{-}1.89  0.01]}
\CommentTok{\#\#  [ 0.09  0.27]}
\CommentTok{\#\#  [{-}1.2   0.33]}
\CommentTok{\#\#  [{-}1.3   0.3 ]}
\CommentTok{\#\#  [{-}1.    0.45]}
\CommentTok{\#\#  [ 1.67 {-}0.89]}
\CommentTok{\#\#  [ 1.18  0.53]}
\CommentTok{\#\#  [ 1.08  0.53]}
\CommentTok{\#\#  [ 1.37  2.33]}
\CommentTok{\#\#  [{-}0.31 {-}0.13]}
\CommentTok{\#\#  [ 0.38 {-}0.45]}
\CommentTok{\#\#  [{-}0.41 {-}0.77]}
\CommentTok{\#\#  [{-}0.11 {-}0.51]}
\CommentTok{\#\#  [ 0.98 {-}1.15]}
\CommentTok{\#\#  [{-}0.9  {-}0.77]}
\CommentTok{\#\#  [{-}0.21 {-}0.51]}
\CommentTok{\#\#  [{-}1.1  {-}0.45]}
\CommentTok{\#\#  [{-}1.2   1.4 ]]}
\BuiltInTok{print}\NormalTok{(X\_test)}
\CommentTok{\#\# [[{-}0.8   0.5 ]}
\CommentTok{\#\#  [{-}0.01 {-}0.57]}
\CommentTok{\#\#  [{-}0.31  0.16]}
\CommentTok{\#\#  [{-}0.8   0.27]}
\CommentTok{\#\#  [{-}0.31 {-}0.57]}
\CommentTok{\#\#  [{-}1.1  {-}1.44]}
\CommentTok{\#\#  [{-}0.71 {-}1.58]}
\CommentTok{\#\#  [{-}0.21  2.16]}
\CommentTok{\#\#  [{-}1.99 {-}0.05]}
\CommentTok{\#\#  [ 0.88 {-}0.77]}
\CommentTok{\#\#  [{-}0.8  {-}0.6 ]}
\CommentTok{\#\#  [{-}1.   {-}0.42]}
\CommentTok{\#\#  [{-}0.11 {-}0.42]}
\CommentTok{\#\#  [ 0.09  0.22]}
\CommentTok{\#\#  [{-}1.8   0.48]}
\CommentTok{\#\#  [{-}0.61  1.37]}
\CommentTok{\#\#  [{-}0.11  0.22]}
\CommentTok{\#\#  [{-}1.89  0.45]}
\CommentTok{\#\#  [ 1.67  1.75]}
\CommentTok{\#\#  [{-}0.31 {-}1.38]}
\CommentTok{\#\#  [{-}0.31 {-}0.65]}
\CommentTok{\#\#  [ 0.88  2.16]}
\CommentTok{\#\#  [ 0.28 {-}0.54]}
\CommentTok{\#\#  [ 0.88  1.03]}
\CommentTok{\#\#  [{-}1.5  {-}1.21]}
\CommentTok{\#\#  [ 1.08  2.07]}
\CommentTok{\#\#  [{-}1.    0.5 ]}
\CommentTok{\#\#  [{-}0.9   0.3 ]}
\CommentTok{\#\#  [{-}0.11 {-}0.22]}
\CommentTok{\#\#  [{-}0.61  0.48]}
\CommentTok{\#\#  [{-}1.7   0.53]}
\CommentTok{\#\#  [{-}0.11  0.27]}
\CommentTok{\#\#  [ 1.87 {-}0.28]}
\CommentTok{\#\#  [{-}0.11 {-}0.48]}
\CommentTok{\#\#  [{-}1.4  {-}0.34]}
\CommentTok{\#\#  [{-}1.99 {-}0.51]}
\CommentTok{\#\#  [{-}1.6   0.33]}
\CommentTok{\#\#  [{-}0.41 {-}0.77]}
\CommentTok{\#\#  [{-}0.71 {-}1.03]}
\CommentTok{\#\#  [ 1.08 {-}0.97]}
\CommentTok{\#\#  [{-}1.1   0.53]}
\CommentTok{\#\#  [ 0.28 {-}0.51]}
\CommentTok{\#\#  [{-}1.1   0.42]}
\CommentTok{\#\#  [{-}0.31 {-}1.44]}
\CommentTok{\#\#  [ 0.48  1.23]}
\CommentTok{\#\#  [{-}1.1  {-}0.34]}
\CommentTok{\#\#  [{-}0.11  0.3 ]}
\CommentTok{\#\#  [ 1.37  0.59]}
\CommentTok{\#\#  [{-}1.2  {-}1.15]}
\CommentTok{\#\#  [ 1.08  0.48]}
\CommentTok{\#\#  [ 1.87  1.52]}
\CommentTok{\#\#  [{-}0.41 {-}1.29]}
\CommentTok{\#\#  [{-}0.31 {-}0.36]}
\CommentTok{\#\#  [{-}0.41  1.32]}
\CommentTok{\#\#  [ 2.07  0.53]}
\CommentTok{\#\#  [ 0.68 {-}1.09]}
\CommentTok{\#\#  [{-}0.9   0.39]}
\CommentTok{\#\#  [{-}1.2   0.3 ]}
\CommentTok{\#\#  [ 1.08 {-}1.21]}
\CommentTok{\#\#  [{-}1.5  {-}1.44]}
\CommentTok{\#\#  [{-}0.61 {-}1.5 ]}
\CommentTok{\#\#  [ 2.17 {-}0.8 ]}
\CommentTok{\#\#  [{-}1.89  0.19]}
\CommentTok{\#\#  [{-}0.21  0.85]}
\CommentTok{\#\#  [{-}1.89 {-}1.26]}
\CommentTok{\#\#  [ 2.17  0.39]}
\CommentTok{\#\#  [{-}1.4   0.56]}
\CommentTok{\#\#  [{-}1.1  {-}0.34]}
\CommentTok{\#\#  [ 0.19 {-}0.65]}
\CommentTok{\#\#  [ 0.38  0.01]}
\CommentTok{\#\#  [{-}0.61  2.33]}
\CommentTok{\#\#  [{-}0.31  0.22]}
\CommentTok{\#\#  [{-}1.6  {-}0.19]}
\CommentTok{\#\#  [ 0.68 {-}1.38]}
\CommentTok{\#\#  [{-}1.1   0.56]}
\CommentTok{\#\#  [{-}1.99  0.36]}
\CommentTok{\#\#  [ 0.38  0.27]}
\CommentTok{\#\#  [ 0.19 {-}0.28]}
\CommentTok{\#\#  [ 1.47 {-}1.03]}
\CommentTok{\#\#  [ 0.88  1.08]}
\CommentTok{\#\#  [ 1.97  2.16]}
\CommentTok{\#\#  [ 2.07  0.39]}
\CommentTok{\#\#  [{-}1.4  {-}0.42]}
\CommentTok{\#\#  [{-}1.2  {-}1.  ]}
\CommentTok{\#\#  [ 1.97 {-}0.92]}
\CommentTok{\#\#  [ 0.38  0.3 ]}
\CommentTok{\#\#  [ 0.19  0.16]}
\CommentTok{\#\#  [ 2.07  1.75]}
\CommentTok{\#\#  [ 0.78 {-}0.83]}
\CommentTok{\#\#  [ 0.28 {-}0.28]}
\CommentTok{\#\#  [ 0.38 {-}0.16]}
\CommentTok{\#\#  [{-}0.11  2.22]}
\CommentTok{\#\#  [{-}1.5  {-}0.63]}
\CommentTok{\#\#  [{-}1.3  {-}1.06]}
\CommentTok{\#\#  [{-}1.4   0.42]}
\CommentTok{\#\#  [{-}1.1   0.77]}
\CommentTok{\#\#  [{-}1.5  {-}0.19]}
\CommentTok{\#\#  [ 0.98 {-}1.06]}
\CommentTok{\#\#  [ 0.98  0.59]}
\CommentTok{\#\#  [ 0.38  1.  ]]}
\end{Highlighting}
\end{Shaded}

R

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{training\_set[}\SpecialCharTok{{-}}\DecValTok{3}\NormalTok{] }\OtherTok{=} \FunctionTok{scale}\NormalTok{(training\_set[}\SpecialCharTok{{-}}\DecValTok{3}\NormalTok{])}
\NormalTok{test\_set[}\SpecialCharTok{{-}}\DecValTok{3}\NormalTok{] }\OtherTok{=} \FunctionTok{scale}\NormalTok{(test\_set[}\SpecialCharTok{{-}}\DecValTok{3}\NormalTok{])}
\end{Highlighting}
\end{Shaded}

\hypertarget{training-the-k-nn-model-on-the-training-set}{%
\subsection{Training the K-NN model on the Training set}\label{training-the-k-nn-model-on-the-training-set}}

Python

\begin{Shaded}
\begin{Highlighting}[]
\ImportTok{from}\NormalTok{ sklearn.neighbors }\ImportTok{import}\NormalTok{ KNeighborsClassifier}
\NormalTok{classifier }\OperatorTok{=}\NormalTok{ KNeighborsClassifier(n\_neighbors }\OperatorTok{=} \DecValTok{5}\NormalTok{, metric }\OperatorTok{=} \StringTok{\textquotesingle{}minkowski\textquotesingle{}}\NormalTok{, p }\OperatorTok{=} \DecValTok{2}\NormalTok{)}
\NormalTok{classifier.fit(X\_train, y\_train)}
\CommentTok{\#\# KNeighborsClassifier()}
\end{Highlighting}
\end{Shaded}

R (Fitting K-NN to the Training set and Predicting the Test set results)

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{library}\NormalTok{(class)}
\NormalTok{y\_pred }\OtherTok{=} \FunctionTok{knn}\NormalTok{(}\AttributeTok{train =}\NormalTok{ training\_set[, }\SpecialCharTok{{-}}\DecValTok{3}\NormalTok{],}
             \AttributeTok{test =}\NormalTok{ test\_set[, }\SpecialCharTok{{-}}\DecValTok{3}\NormalTok{],}
             \AttributeTok{cl =}\NormalTok{ training\_set[, }\DecValTok{3}\NormalTok{],}
             \AttributeTok{k =} \DecValTok{5}\NormalTok{,}
             \AttributeTok{prob =} \ConstantTok{TRUE}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\hypertarget{predicting-a-new-result-4}{%
\subsection{Predicting a new result}\label{predicting-a-new-result-4}}

Python

\begin{Shaded}
\begin{Highlighting}[]
\BuiltInTok{print}\NormalTok{(classifier.predict(sc.transform([[}\DecValTok{30}\NormalTok{,}\DecValTok{87000}\NormalTok{]])))}
\CommentTok{\#\# [0]}
\end{Highlighting}
\end{Shaded}

\hypertarget{predicting-the-test-set-results-3}{%
\subsection{Predicting the Test set results}\label{predicting-the-test-set-results-3}}

Python

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{y\_pred }\OperatorTok{=}\NormalTok{ classifier.predict(X\_test)}
\BuiltInTok{print}\NormalTok{(np.concatenate((y\_pred.reshape(}\BuiltInTok{len}\NormalTok{(y\_pred),}\DecValTok{1}\NormalTok{), y\_test.reshape(}\BuiltInTok{len}\NormalTok{(y\_test),}\DecValTok{1}\NormalTok{)),}\DecValTok{1}\NormalTok{))}
\CommentTok{\#\# [[0 0]}
\CommentTok{\#\#  [0 0]}
\CommentTok{\#\#  [0 0]}
\CommentTok{\#\#  [0 0]}
\CommentTok{\#\#  [0 0]}
\CommentTok{\#\#  [0 0]}
\CommentTok{\#\#  [0 0]}
\CommentTok{\#\#  [1 1]}
\CommentTok{\#\#  [0 0]}
\CommentTok{\#\#  [1 0]}
\CommentTok{\#\#  [0 0]}
\CommentTok{\#\#  [0 0]}
\CommentTok{\#\#  [0 0]}
\CommentTok{\#\#  [0 0]}
\CommentTok{\#\#  [0 0]}
\CommentTok{\#\#  [1 0]}
\CommentTok{\#\#  [0 0]}
\CommentTok{\#\#  [0 0]}
\CommentTok{\#\#  [1 1]}
\CommentTok{\#\#  [0 0]}
\CommentTok{\#\#  [0 0]}
\CommentTok{\#\#  [1 1]}
\CommentTok{\#\#  [0 0]}
\CommentTok{\#\#  [1 1]}
\CommentTok{\#\#  [0 0]}
\CommentTok{\#\#  [1 1]}
\CommentTok{\#\#  [0 0]}
\CommentTok{\#\#  [0 0]}
\CommentTok{\#\#  [0 0]}
\CommentTok{\#\#  [0 0]}
\CommentTok{\#\#  [0 0]}
\CommentTok{\#\#  [0 1]}
\CommentTok{\#\#  [1 1]}
\CommentTok{\#\#  [0 0]}
\CommentTok{\#\#  [0 0]}
\CommentTok{\#\#  [0 0]}
\CommentTok{\#\#  [0 0]}
\CommentTok{\#\#  [0 0]}
\CommentTok{\#\#  [0 0]}
\CommentTok{\#\#  [1 1]}
\CommentTok{\#\#  [0 0]}
\CommentTok{\#\#  [0 0]}
\CommentTok{\#\#  [0 0]}
\CommentTok{\#\#  [0 0]}
\CommentTok{\#\#  [1 1]}
\CommentTok{\#\#  [0 0]}
\CommentTok{\#\#  [0 0]}
\CommentTok{\#\#  [1 1]}
\CommentTok{\#\#  [0 0]}
\CommentTok{\#\#  [1 1]}
\CommentTok{\#\#  [1 1]}
\CommentTok{\#\#  [0 0]}
\CommentTok{\#\#  [0 0]}
\CommentTok{\#\#  [1 0]}
\CommentTok{\#\#  [1 1]}
\CommentTok{\#\#  [1 1]}
\CommentTok{\#\#  [0 0]}
\CommentTok{\#\#  [0 0]}
\CommentTok{\#\#  [1 1]}
\CommentTok{\#\#  [0 0]}
\CommentTok{\#\#  [0 0]}
\CommentTok{\#\#  [1 1]}
\CommentTok{\#\#  [0 0]}
\CommentTok{\#\#  [1 1]}
\CommentTok{\#\#  [0 0]}
\CommentTok{\#\#  [1 1]}
\CommentTok{\#\#  [0 0]}
\CommentTok{\#\#  [0 0]}
\CommentTok{\#\#  [0 0]}
\CommentTok{\#\#  [0 0]}
\CommentTok{\#\#  [1 1]}
\CommentTok{\#\#  [0 0]}
\CommentTok{\#\#  [0 0]}
\CommentTok{\#\#  [1 1]}
\CommentTok{\#\#  [0 0]}
\CommentTok{\#\#  [0 0]}
\CommentTok{\#\#  [0 0]}
\CommentTok{\#\#  [0 0]}
\CommentTok{\#\#  [1 1]}
\CommentTok{\#\#  [1 1]}
\CommentTok{\#\#  [1 1]}
\CommentTok{\#\#  [1 0]}
\CommentTok{\#\#  [0 0]}
\CommentTok{\#\#  [0 0]}
\CommentTok{\#\#  [1 1]}
\CommentTok{\#\#  [0 1]}
\CommentTok{\#\#  [0 0]}
\CommentTok{\#\#  [1 1]}
\CommentTok{\#\#  [1 1]}
\CommentTok{\#\#  [0 0]}
\CommentTok{\#\#  [0 0]}
\CommentTok{\#\#  [1 1]}
\CommentTok{\#\#  [0 0]}
\CommentTok{\#\#  [0 0]}
\CommentTok{\#\#  [0 0]}
\CommentTok{\#\#  [0 1]}
\CommentTok{\#\#  [0 0]}
\CommentTok{\#\#  [1 1]}
\CommentTok{\#\#  [1 1]}
\CommentTok{\#\#  [1 1]]}
\end{Highlighting}
\end{Shaded}

\hypertarget{making-the-confusion-matrix-1}{%
\subsection{Making the Confusion Matrix}\label{making-the-confusion-matrix-1}}

Python

\begin{Shaded}
\begin{Highlighting}[]
\ImportTok{from}\NormalTok{ sklearn.metrics }\ImportTok{import}\NormalTok{ confusion\_matrix, accuracy\_score}
\NormalTok{cm }\OperatorTok{=}\NormalTok{ confusion\_matrix(y\_test, y\_pred)}
\BuiltInTok{print}\NormalTok{(cm)}
\CommentTok{\#\# [[64  4]}
\CommentTok{\#\#  [ 3 29]]}
\NormalTok{accuracy\_score(y\_test, y\_pred)}
\CommentTok{\#\# 0.93}
\end{Highlighting}
\end{Shaded}

R

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{cm }\OtherTok{=} \FunctionTok{table}\NormalTok{(test\_set[, }\DecValTok{3}\NormalTok{], y\_pred)}
\end{Highlighting}
\end{Shaded}

\hypertarget{visualising-the-training-set-results-2}{%
\subsection{Visualising the Training set results}\label{visualising-the-training-set-results-2}}

Python

\begin{Shaded}
\begin{Highlighting}[]
\ImportTok{from}\NormalTok{ matplotlib.colors }\ImportTok{import}\NormalTok{ ListedColormap}
\NormalTok{X\_set, y\_set }\OperatorTok{=}\NormalTok{ sc.inverse\_transform(X\_train), y\_train}
\NormalTok{X1, X2 }\OperatorTok{=}\NormalTok{ np.meshgrid(np.arange(start }\OperatorTok{=}\NormalTok{ X\_set[:, }\DecValTok{0}\NormalTok{].}\BuiltInTok{min}\NormalTok{() }\OperatorTok{{-}} \DecValTok{10}\NormalTok{, stop }\OperatorTok{=}\NormalTok{ X\_set[:, }\DecValTok{0}\NormalTok{].}\BuiltInTok{max}\NormalTok{() }\OperatorTok{+} \DecValTok{10}\NormalTok{, step }\OperatorTok{=} \DecValTok{1}\NormalTok{),}
\NormalTok{                     np.arange(start }\OperatorTok{=}\NormalTok{ X\_set[:, }\DecValTok{1}\NormalTok{].}\BuiltInTok{min}\NormalTok{() }\OperatorTok{{-}} \DecValTok{1000}\NormalTok{, stop }\OperatorTok{=}\NormalTok{ X\_set[:, }\DecValTok{1}\NormalTok{].}\BuiltInTok{max}\NormalTok{() }\OperatorTok{+} \DecValTok{1000}\NormalTok{, step }\OperatorTok{=} \DecValTok{1}\NormalTok{))}
\NormalTok{plt.contourf(X1, X2, classifier.predict(sc.transform(np.array([X1.ravel(), X2.ravel()]).T)).reshape(X1.shape),}
\NormalTok{             alpha }\OperatorTok{=} \FloatTok{0.75}\NormalTok{, cmap }\OperatorTok{=}\NormalTok{ ListedColormap((}\StringTok{\textquotesingle{}red\textquotesingle{}}\NormalTok{, }\StringTok{\textquotesingle{}green\textquotesingle{}}\NormalTok{)))}
\NormalTok{plt.xlim(X1.}\BuiltInTok{min}\NormalTok{(), X1.}\BuiltInTok{max}\NormalTok{())}
\NormalTok{plt.ylim(X2.}\BuiltInTok{min}\NormalTok{(), X2.}\BuiltInTok{max}\NormalTok{())}
\ControlFlowTok{for}\NormalTok{ i, j }\KeywordTok{in} \BuiltInTok{enumerate}\NormalTok{(np.unique(y\_set)):}
\NormalTok{    plt.scatter(X\_set[y\_set }\OperatorTok{==}\NormalTok{ j, }\DecValTok{0}\NormalTok{], X\_set[y\_set }\OperatorTok{==}\NormalTok{ j, }\DecValTok{1}\NormalTok{], c }\OperatorTok{=}\NormalTok{ ListedColormap((}\StringTok{\textquotesingle{}red\textquotesingle{}}\NormalTok{, }\StringTok{\textquotesingle{}green\textquotesingle{}}\NormalTok{))(i), label }\OperatorTok{=}\NormalTok{ j)}
\NormalTok{plt.title(}\StringTok{\textquotesingle{}K{-}NN (Training set)\textquotesingle{}}\NormalTok{)}
\NormalTok{plt.xlabel(}\StringTok{\textquotesingle{}Age\textquotesingle{}}\NormalTok{)}
\NormalTok{plt.ylabel(}\StringTok{\textquotesingle{}Estimated Salary\textquotesingle{}}\NormalTok{)}
\NormalTok{plt.legend()}
\NormalTok{plt.show()}
\end{Highlighting}
\end{Shaded}

R

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{library}\NormalTok{(ElemStatLearn)}
\NormalTok{set }\OtherTok{=}\NormalTok{ training\_set}
\NormalTok{X1 }\OtherTok{=} \FunctionTok{seq}\NormalTok{(}\FunctionTok{min}\NormalTok{(set[, }\DecValTok{1}\NormalTok{]) }\SpecialCharTok{{-}} \DecValTok{1}\NormalTok{, }\FunctionTok{max}\NormalTok{(set[, }\DecValTok{1}\NormalTok{]) }\SpecialCharTok{+} \DecValTok{1}\NormalTok{, }\AttributeTok{by =} \FloatTok{0.01}\NormalTok{)}
\NormalTok{X2 }\OtherTok{=} \FunctionTok{seq}\NormalTok{(}\FunctionTok{min}\NormalTok{(set[, }\DecValTok{2}\NormalTok{]) }\SpecialCharTok{{-}} \DecValTok{1}\NormalTok{, }\FunctionTok{max}\NormalTok{(set[, }\DecValTok{2}\NormalTok{]) }\SpecialCharTok{+} \DecValTok{1}\NormalTok{, }\AttributeTok{by =} \FloatTok{0.01}\NormalTok{)}
\NormalTok{grid\_set }\OtherTok{=} \FunctionTok{expand.grid}\NormalTok{(X1, X2)}
\FunctionTok{colnames}\NormalTok{(grid\_set) }\OtherTok{=} \FunctionTok{c}\NormalTok{(}\StringTok{\textquotesingle{}Age\textquotesingle{}}\NormalTok{, }\StringTok{\textquotesingle{}EstimatedSalary\textquotesingle{}}\NormalTok{)}
\NormalTok{y\_grid }\OtherTok{=} \FunctionTok{knn}\NormalTok{(}\AttributeTok{train =}\NormalTok{ training\_set[, }\SpecialCharTok{{-}}\DecValTok{3}\NormalTok{], }\AttributeTok{test =}\NormalTok{ grid\_set, }\AttributeTok{cl =}\NormalTok{ training\_set[, }\DecValTok{3}\NormalTok{], }\AttributeTok{k =} \DecValTok{5}\NormalTok{)}
\FunctionTok{plot}\NormalTok{(set[, }\SpecialCharTok{{-}}\DecValTok{3}\NormalTok{],}
     \AttributeTok{main =} \StringTok{\textquotesingle{}K{-}NN (Training set)\textquotesingle{}}\NormalTok{,}
     \AttributeTok{xlab =} \StringTok{\textquotesingle{}Age\textquotesingle{}}\NormalTok{, }\AttributeTok{ylab =} \StringTok{\textquotesingle{}Estimated Salary\textquotesingle{}}\NormalTok{,}
     \AttributeTok{xlim =} \FunctionTok{range}\NormalTok{(X1), }\AttributeTok{ylim =} \FunctionTok{range}\NormalTok{(X2))}
\FunctionTok{contour}\NormalTok{(X1, X2, }\FunctionTok{matrix}\NormalTok{(}\FunctionTok{as.numeric}\NormalTok{(y\_grid), }\FunctionTok{length}\NormalTok{(X1), }\FunctionTok{length}\NormalTok{(X2)), }\AttributeTok{add =} \ConstantTok{TRUE}\NormalTok{)}
\FunctionTok{points}\NormalTok{(grid\_set, }\AttributeTok{pch =} \StringTok{\textquotesingle{}.\textquotesingle{}}\NormalTok{, }\AttributeTok{col =} \FunctionTok{ifelse}\NormalTok{(y\_grid }\SpecialCharTok{==} \DecValTok{1}\NormalTok{, }\StringTok{\textquotesingle{}springgreen3\textquotesingle{}}\NormalTok{, }\StringTok{\textquotesingle{}tomato\textquotesingle{}}\NormalTok{))}
\FunctionTok{points}\NormalTok{(set, }\AttributeTok{pch =} \DecValTok{21}\NormalTok{, }\AttributeTok{bg =} \FunctionTok{ifelse}\NormalTok{(set[, }\DecValTok{3}\NormalTok{] }\SpecialCharTok{==} \DecValTok{1}\NormalTok{, }\StringTok{\textquotesingle{}green4\textquotesingle{}}\NormalTok{, }\StringTok{\textquotesingle{}red3\textquotesingle{}}\NormalTok{))}
\end{Highlighting}
\end{Shaded}

\includegraphics{_main_files/figure-latex/unnamed-chunk-119-1.pdf}

\hypertarget{visualising-the-test-set-results-2}{%
\subsection{Visualising the Test set results}\label{visualising-the-test-set-results-2}}

Python

\begin{Shaded}
\begin{Highlighting}[]
\ImportTok{from}\NormalTok{ matplotlib.colors }\ImportTok{import}\NormalTok{ ListedColormap}
\NormalTok{X\_set, y\_set }\OperatorTok{=}\NormalTok{ sc.inverse\_transform(X\_test), y\_test}
\NormalTok{X1, X2 }\OperatorTok{=}\NormalTok{ np.meshgrid(np.arange(start }\OperatorTok{=}\NormalTok{ X\_set[:, }\DecValTok{0}\NormalTok{].}\BuiltInTok{min}\NormalTok{() }\OperatorTok{{-}} \DecValTok{10}\NormalTok{, stop }\OperatorTok{=}\NormalTok{ X\_set[:, }\DecValTok{0}\NormalTok{].}\BuiltInTok{max}\NormalTok{() }\OperatorTok{+} \DecValTok{10}\NormalTok{, step }\OperatorTok{=} \DecValTok{1}\NormalTok{),}
\NormalTok{                     np.arange(start }\OperatorTok{=}\NormalTok{ X\_set[:, }\DecValTok{1}\NormalTok{].}\BuiltInTok{min}\NormalTok{() }\OperatorTok{{-}} \DecValTok{1000}\NormalTok{, stop }\OperatorTok{=}\NormalTok{ X\_set[:, }\DecValTok{1}\NormalTok{].}\BuiltInTok{max}\NormalTok{() }\OperatorTok{+} \DecValTok{1000}\NormalTok{, step }\OperatorTok{=} \DecValTok{1}\NormalTok{))}
\NormalTok{plt.contourf(X1, X2, classifier.predict(sc.transform(np.array([X1.ravel(), X2.ravel()]).T)).reshape(X1.shape),}
\NormalTok{             alpha }\OperatorTok{=} \FloatTok{0.75}\NormalTok{, cmap }\OperatorTok{=}\NormalTok{ ListedColormap((}\StringTok{\textquotesingle{}red\textquotesingle{}}\NormalTok{, }\StringTok{\textquotesingle{}green\textquotesingle{}}\NormalTok{)))}
\NormalTok{plt.xlim(X1.}\BuiltInTok{min}\NormalTok{(), X1.}\BuiltInTok{max}\NormalTok{())}
\NormalTok{plt.ylim(X2.}\BuiltInTok{min}\NormalTok{(), X2.}\BuiltInTok{max}\NormalTok{())}
\ControlFlowTok{for}\NormalTok{ i, j }\KeywordTok{in} \BuiltInTok{enumerate}\NormalTok{(np.unique(y\_set)):}
\NormalTok{    plt.scatter(X\_set[y\_set }\OperatorTok{==}\NormalTok{ j, }\DecValTok{0}\NormalTok{], X\_set[y\_set }\OperatorTok{==}\NormalTok{ j, }\DecValTok{1}\NormalTok{], c }\OperatorTok{=}\NormalTok{ ListedColormap((}\StringTok{\textquotesingle{}red\textquotesingle{}}\NormalTok{, }\StringTok{\textquotesingle{}green\textquotesingle{}}\NormalTok{))(i), label }\OperatorTok{=}\NormalTok{ j)}
\NormalTok{plt.title(}\StringTok{\textquotesingle{}K{-}NN (Test set)\textquotesingle{}}\NormalTok{)}
\NormalTok{plt.xlabel(}\StringTok{\textquotesingle{}Age\textquotesingle{}}\NormalTok{)}
\NormalTok{plt.ylabel(}\StringTok{\textquotesingle{}Estimated Salary\textquotesingle{}}\NormalTok{)}
\NormalTok{plt.legend()}
\NormalTok{plt.show()}
\end{Highlighting}
\end{Shaded}

R

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{library}\NormalTok{(ElemStatLearn)}
\NormalTok{set }\OtherTok{=}\NormalTok{ test\_set}
\NormalTok{X1 }\OtherTok{=} \FunctionTok{seq}\NormalTok{(}\FunctionTok{min}\NormalTok{(set[, }\DecValTok{1}\NormalTok{]) }\SpecialCharTok{{-}} \DecValTok{1}\NormalTok{, }\FunctionTok{max}\NormalTok{(set[, }\DecValTok{1}\NormalTok{]) }\SpecialCharTok{+} \DecValTok{1}\NormalTok{, }\AttributeTok{by =} \FloatTok{0.01}\NormalTok{)}
\NormalTok{X2 }\OtherTok{=} \FunctionTok{seq}\NormalTok{(}\FunctionTok{min}\NormalTok{(set[, }\DecValTok{2}\NormalTok{]) }\SpecialCharTok{{-}} \DecValTok{1}\NormalTok{, }\FunctionTok{max}\NormalTok{(set[, }\DecValTok{2}\NormalTok{]) }\SpecialCharTok{+} \DecValTok{1}\NormalTok{, }\AttributeTok{by =} \FloatTok{0.01}\NormalTok{)}
\NormalTok{grid\_set }\OtherTok{=} \FunctionTok{expand.grid}\NormalTok{(X1, X2)}
\FunctionTok{colnames}\NormalTok{(grid\_set) }\OtherTok{=} \FunctionTok{c}\NormalTok{(}\StringTok{\textquotesingle{}Age\textquotesingle{}}\NormalTok{, }\StringTok{\textquotesingle{}EstimatedSalary\textquotesingle{}}\NormalTok{)}
\NormalTok{y\_grid }\OtherTok{=} \FunctionTok{knn}\NormalTok{(}\AttributeTok{train =}\NormalTok{ training\_set[, }\SpecialCharTok{{-}}\DecValTok{3}\NormalTok{], }\AttributeTok{test =}\NormalTok{ grid\_set, }\AttributeTok{cl =}\NormalTok{ training\_set[, }\DecValTok{3}\NormalTok{], }\AttributeTok{k =} \DecValTok{5}\NormalTok{)}
\FunctionTok{plot}\NormalTok{(set[, }\SpecialCharTok{{-}}\DecValTok{3}\NormalTok{],}
     \AttributeTok{main =} \StringTok{\textquotesingle{}K{-}NN (Test set)\textquotesingle{}}\NormalTok{,}
     \AttributeTok{xlab =} \StringTok{\textquotesingle{}Age\textquotesingle{}}\NormalTok{, }\AttributeTok{ylab =} \StringTok{\textquotesingle{}Estimated Salary\textquotesingle{}}\NormalTok{,}
     \AttributeTok{xlim =} \FunctionTok{range}\NormalTok{(X1), }\AttributeTok{ylim =} \FunctionTok{range}\NormalTok{(X2))}
\FunctionTok{contour}\NormalTok{(X1, X2, }\FunctionTok{matrix}\NormalTok{(}\FunctionTok{as.numeric}\NormalTok{(y\_grid), }\FunctionTok{length}\NormalTok{(X1), }\FunctionTok{length}\NormalTok{(X2)), }\AttributeTok{add =} \ConstantTok{TRUE}\NormalTok{)}
\FunctionTok{points}\NormalTok{(grid\_set, }\AttributeTok{pch =} \StringTok{\textquotesingle{}.\textquotesingle{}}\NormalTok{, }\AttributeTok{col =} \FunctionTok{ifelse}\NormalTok{(y\_grid }\SpecialCharTok{==} \DecValTok{1}\NormalTok{, }\StringTok{\textquotesingle{}springgreen3\textquotesingle{}}\NormalTok{, }\StringTok{\textquotesingle{}tomato\textquotesingle{}}\NormalTok{))}
\FunctionTok{points}\NormalTok{(set, }\AttributeTok{pch =} \DecValTok{21}\NormalTok{, }\AttributeTok{bg =} \FunctionTok{ifelse}\NormalTok{(set[, }\DecValTok{3}\NormalTok{] }\SpecialCharTok{==} \DecValTok{1}\NormalTok{, }\StringTok{\textquotesingle{}green4\textquotesingle{}}\NormalTok{, }\StringTok{\textquotesingle{}red3\textquotesingle{}}\NormalTok{))}
\end{Highlighting}
\end{Shaded}

\includegraphics{_main_files/figure-latex/unnamed-chunk-121-1.pdf}

\hypertarget{support-vector-machine-svm}{%
\section{Support Vector Machine (SVM)}\label{support-vector-machine-svm}}

\hypertarget{importing-the-libraries-9}{%
\subsection{Importing the libraries}\label{importing-the-libraries-9}}

Python

\begin{Shaded}
\begin{Highlighting}[]
\ImportTok{import}\NormalTok{ numpy }\ImportTok{as}\NormalTok{ np}
\ImportTok{import}\NormalTok{ matplotlib.pyplot }\ImportTok{as}\NormalTok{ plt}
\ImportTok{import}\NormalTok{ pandas }\ImportTok{as}\NormalTok{ pd}
\end{Highlighting}
\end{Shaded}

\hypertarget{importing-the-dataset-9}{%
\subsection{Importing the dataset}\label{importing-the-dataset-9}}

Python

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{dataset }\OperatorTok{=}\NormalTok{ pd.read\_csv(}\StringTok{\textquotesingle{}Social\_Network\_Ads.csv\textquotesingle{}}\NormalTok{)}
\NormalTok{X }\OperatorTok{=}\NormalTok{ dataset.iloc[:, :}\OperatorTok{{-}}\DecValTok{1}\NormalTok{].values}
\NormalTok{y }\OperatorTok{=}\NormalTok{ dataset.iloc[:, }\OperatorTok{{-}}\DecValTok{1}\NormalTok{].values}
\end{Highlighting}
\end{Shaded}

R

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{dataset }\OtherTok{=} \FunctionTok{read.csv}\NormalTok{(}\StringTok{\textquotesingle{}Social\_Network\_Ads.csv\textquotesingle{}}\NormalTok{)}
\CommentTok{\# dataset = dataset[3:5]}
\end{Highlighting}
\end{Shaded}

\hypertarget{encoding-the-target-feature-as-factor-2}{%
\subsection{Encoding the target feature as factor}\label{encoding-the-target-feature-as-factor-2}}

R

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{dataset}\SpecialCharTok{$}\NormalTok{Purchased }\OtherTok{=} \FunctionTok{factor}\NormalTok{(dataset}\SpecialCharTok{$}\NormalTok{Purchased, }\AttributeTok{levels =} \FunctionTok{c}\NormalTok{(}\DecValTok{0}\NormalTok{, }\DecValTok{1}\NormalTok{))}
\end{Highlighting}
\end{Shaded}

\hypertarget{splitting-the-dataset-into-the-training-set-and-test-set-5}{%
\subsection{Splitting the dataset into the Training set and Test set}\label{splitting-the-dataset-into-the-training-set-and-test-set-5}}

Python

\begin{Shaded}
\begin{Highlighting}[]
\ImportTok{from}\NormalTok{ sklearn.model\_selection }\ImportTok{import}\NormalTok{ train\_test\_split}
\NormalTok{X\_train, X\_test, y\_train, y\_test }\OperatorTok{=}\NormalTok{ train\_test\_split(X, y, test\_size }\OperatorTok{=} \FloatTok{0.25}\NormalTok{, random\_state }\OperatorTok{=} \DecValTok{0}\NormalTok{)}
\BuiltInTok{print}\NormalTok{(X\_train)}
\CommentTok{\#\# [[    44  39000]}
\CommentTok{\#\#  [    32 120000]}
\CommentTok{\#\#  [    38  50000]}
\CommentTok{\#\#  [    32 135000]}
\CommentTok{\#\#  [    52  21000]}
\CommentTok{\#\#  [    53 104000]}
\CommentTok{\#\#  [    39  42000]}
\CommentTok{\#\#  [    38  61000]}
\CommentTok{\#\#  [    36  50000]}
\CommentTok{\#\#  [    36  63000]}
\CommentTok{\#\#  [    35  25000]}
\CommentTok{\#\#  [    35  50000]}
\CommentTok{\#\#  [    42  73000]}
\CommentTok{\#\#  [    47  49000]}
\CommentTok{\#\#  [    59  29000]}
\CommentTok{\#\#  [    49  65000]}
\CommentTok{\#\#  [    45 131000]}
\CommentTok{\#\#  [    31  89000]}
\CommentTok{\#\#  [    46  82000]}
\CommentTok{\#\#  [    47  51000]}
\CommentTok{\#\#  [    26  15000]}
\CommentTok{\#\#  [    60 102000]}
\CommentTok{\#\#  [    38 112000]}
\CommentTok{\#\#  [    40 107000]}
\CommentTok{\#\#  [    42  53000]}
\CommentTok{\#\#  [    35  59000]}
\CommentTok{\#\#  [    48  41000]}
\CommentTok{\#\#  [    48 134000]}
\CommentTok{\#\#  [    38 113000]}
\CommentTok{\#\#  [    29 148000]}
\CommentTok{\#\#  [    26  15000]}
\CommentTok{\#\#  [    60  42000]}
\CommentTok{\#\#  [    24  19000]}
\CommentTok{\#\#  [    42 149000]}
\CommentTok{\#\#  [    46  96000]}
\CommentTok{\#\#  [    28  59000]}
\CommentTok{\#\#  [    39  96000]}
\CommentTok{\#\#  [    28  89000]}
\CommentTok{\#\#  [    41  72000]}
\CommentTok{\#\#  [    45  26000]}
\CommentTok{\#\#  [    33  69000]}
\CommentTok{\#\#  [    20  82000]}
\CommentTok{\#\#  [    31  74000]}
\CommentTok{\#\#  [    42  80000]}
\CommentTok{\#\#  [    35  72000]}
\CommentTok{\#\#  [    33 149000]}
\CommentTok{\#\#  [    40  71000]}
\CommentTok{\#\#  [    51 146000]}
\CommentTok{\#\#  [    46  79000]}
\CommentTok{\#\#  [    35  75000]}
\CommentTok{\#\#  [    38  51000]}
\CommentTok{\#\#  [    36  75000]}
\CommentTok{\#\#  [    37  78000]}
\CommentTok{\#\#  [    38  61000]}
\CommentTok{\#\#  [    60 108000]}
\CommentTok{\#\#  [    20  82000]}
\CommentTok{\#\#  [    57  74000]}
\CommentTok{\#\#  [    42  65000]}
\CommentTok{\#\#  [    26  80000]}
\CommentTok{\#\#  [    46 117000]}
\CommentTok{\#\#  [    35  61000]}
\CommentTok{\#\#  [    21  68000]}
\CommentTok{\#\#  [    28  44000]}
\CommentTok{\#\#  [    41  87000]}
\CommentTok{\#\#  [    37  33000]}
\CommentTok{\#\#  [    27  90000]}
\CommentTok{\#\#  [    39  42000]}
\CommentTok{\#\#  [    28 123000]}
\CommentTok{\#\#  [    31 118000]}
\CommentTok{\#\#  [    25  87000]}
\CommentTok{\#\#  [    35  71000]}
\CommentTok{\#\#  [    37  70000]}
\CommentTok{\#\#  [    35  39000]}
\CommentTok{\#\#  [    47  23000]}
\CommentTok{\#\#  [    35 147000]}
\CommentTok{\#\#  [    48 138000]}
\CommentTok{\#\#  [    26  86000]}
\CommentTok{\#\#  [    25  79000]}
\CommentTok{\#\#  [    52 138000]}
\CommentTok{\#\#  [    51  23000]}
\CommentTok{\#\#  [    35  60000]}
\CommentTok{\#\#  [    33 113000]}
\CommentTok{\#\#  [    30 107000]}
\CommentTok{\#\#  [    48  33000]}
\CommentTok{\#\#  [    41  80000]}
\CommentTok{\#\#  [    48  96000]}
\CommentTok{\#\#  [    31  18000]}
\CommentTok{\#\#  [    31  71000]}
\CommentTok{\#\#  [    43 129000]}
\CommentTok{\#\#  [    59  76000]}
\CommentTok{\#\#  [    18  44000]}
\CommentTok{\#\#  [    36 118000]}
\CommentTok{\#\#  [    42  90000]}
\CommentTok{\#\#  [    47  30000]}
\CommentTok{\#\#  [    26  43000]}
\CommentTok{\#\#  [    40  78000]}
\CommentTok{\#\#  [    46  59000]}
\CommentTok{\#\#  [    59  42000]}
\CommentTok{\#\#  [    46  74000]}
\CommentTok{\#\#  [    35  91000]}
\CommentTok{\#\#  [    28  59000]}
\CommentTok{\#\#  [    40  57000]}
\CommentTok{\#\#  [    59 143000]}
\CommentTok{\#\#  [    57  26000]}
\CommentTok{\#\#  [    52  38000]}
\CommentTok{\#\#  [    47 113000]}
\CommentTok{\#\#  [    53 143000]}
\CommentTok{\#\#  [    35  27000]}
\CommentTok{\#\#  [    58 101000]}
\CommentTok{\#\#  [    45  45000]}
\CommentTok{\#\#  [    23  82000]}
\CommentTok{\#\#  [    46  23000]}
\CommentTok{\#\#  [    42  65000]}
\CommentTok{\#\#  [    28  84000]}
\CommentTok{\#\#  [    38  59000]}
\CommentTok{\#\#  [    26  84000]}
\CommentTok{\#\#  [    29  28000]}
\CommentTok{\#\#  [    37  71000]}
\CommentTok{\#\#  [    22  55000]}
\CommentTok{\#\#  [    48  35000]}
\CommentTok{\#\#  [    49  28000]}
\CommentTok{\#\#  [    38  65000]}
\CommentTok{\#\#  [    27  17000]}
\CommentTok{\#\#  [    46  28000]}
\CommentTok{\#\#  [    48 141000]}
\CommentTok{\#\#  [    26  17000]}
\CommentTok{\#\#  [    35  97000]}
\CommentTok{\#\#  [    39  59000]}
\CommentTok{\#\#  [    24  27000]}
\CommentTok{\#\#  [    32  18000]}
\CommentTok{\#\#  [    46  88000]}
\CommentTok{\#\#  [    35  58000]}
\CommentTok{\#\#  [    56  60000]}
\CommentTok{\#\#  [    47  34000]}
\CommentTok{\#\#  [    40  72000]}
\CommentTok{\#\#  [    32 100000]}
\CommentTok{\#\#  [    19  21000]}
\CommentTok{\#\#  [    25  90000]}
\CommentTok{\#\#  [    35  88000]}
\CommentTok{\#\#  [    28  32000]}
\CommentTok{\#\#  [    50  20000]}
\CommentTok{\#\#  [    40  59000]}
\CommentTok{\#\#  [    50  44000]}
\CommentTok{\#\#  [    35  72000]}
\CommentTok{\#\#  [    40 142000]}
\CommentTok{\#\#  [    46  32000]}
\CommentTok{\#\#  [    39  71000]}
\CommentTok{\#\#  [    20  74000]}
\CommentTok{\#\#  [    29  75000]}
\CommentTok{\#\#  [    31  76000]}
\CommentTok{\#\#  [    47  25000]}
\CommentTok{\#\#  [    40  61000]}
\CommentTok{\#\#  [    34 112000]}
\CommentTok{\#\#  [    38  80000]}
\CommentTok{\#\#  [    42  75000]}
\CommentTok{\#\#  [    47  47000]}
\CommentTok{\#\#  [    39  75000]}
\CommentTok{\#\#  [    19  25000]}
\CommentTok{\#\#  [    37  80000]}
\CommentTok{\#\#  [    36  60000]}
\CommentTok{\#\#  [    41  52000]}
\CommentTok{\#\#  [    36 125000]}
\CommentTok{\#\#  [    48  29000]}
\CommentTok{\#\#  [    36 126000]}
\CommentTok{\#\#  [    51 134000]}
\CommentTok{\#\#  [    27  57000]}
\CommentTok{\#\#  [    38  71000]}
\CommentTok{\#\#  [    39  61000]}
\CommentTok{\#\#  [    22  27000]}
\CommentTok{\#\#  [    33  60000]}
\CommentTok{\#\#  [    48  74000]}
\CommentTok{\#\#  [    58  23000]}
\CommentTok{\#\#  [    53  72000]}
\CommentTok{\#\#  [    32 117000]}
\CommentTok{\#\#  [    54  70000]}
\CommentTok{\#\#  [    30  80000]}
\CommentTok{\#\#  [    58  95000]}
\CommentTok{\#\#  [    26  52000]}
\CommentTok{\#\#  [    45  79000]}
\CommentTok{\#\#  [    24  55000]}
\CommentTok{\#\#  [    40  75000]}
\CommentTok{\#\#  [    33  28000]}
\CommentTok{\#\#  [    44 139000]}
\CommentTok{\#\#  [    22  18000]}
\CommentTok{\#\#  [    33  51000]}
\CommentTok{\#\#  [    43 133000]}
\CommentTok{\#\#  [    24  32000]}
\CommentTok{\#\#  [    46  22000]}
\CommentTok{\#\#  [    35  55000]}
\CommentTok{\#\#  [    54 104000]}
\CommentTok{\#\#  [    48 119000]}
\CommentTok{\#\#  [    35  53000]}
\CommentTok{\#\#  [    37 144000]}
\CommentTok{\#\#  [    23  66000]}
\CommentTok{\#\#  [    37 137000]}
\CommentTok{\#\#  [    31  58000]}
\CommentTok{\#\#  [    33  41000]}
\CommentTok{\#\#  [    45  22000]}
\CommentTok{\#\#  [    30  15000]}
\CommentTok{\#\#  [    19  19000]}
\CommentTok{\#\#  [    49  74000]}
\CommentTok{\#\#  [    39 122000]}
\CommentTok{\#\#  [    35  73000]}
\CommentTok{\#\#  [    39  71000]}
\CommentTok{\#\#  [    24  23000]}
\CommentTok{\#\#  [    41  72000]}
\CommentTok{\#\#  [    29  83000]}
\CommentTok{\#\#  [    54  26000]}
\CommentTok{\#\#  [    35  44000]}
\CommentTok{\#\#  [    37  75000]}
\CommentTok{\#\#  [    29  47000]}
\CommentTok{\#\#  [    31  68000]}
\CommentTok{\#\#  [    42  54000]}
\CommentTok{\#\#  [    30 135000]}
\CommentTok{\#\#  [    52 114000]}
\CommentTok{\#\#  [    50  36000]}
\CommentTok{\#\#  [    56 133000]}
\CommentTok{\#\#  [    29  61000]}
\CommentTok{\#\#  [    30  89000]}
\CommentTok{\#\#  [    26  16000]}
\CommentTok{\#\#  [    33  31000]}
\CommentTok{\#\#  [    41  72000]}
\CommentTok{\#\#  [    36  33000]}
\CommentTok{\#\#  [    55 125000]}
\CommentTok{\#\#  [    48 131000]}
\CommentTok{\#\#  [    41  71000]}
\CommentTok{\#\#  [    30  62000]}
\CommentTok{\#\#  [    37  72000]}
\CommentTok{\#\#  [    41  63000]}
\CommentTok{\#\#  [    58  47000]}
\CommentTok{\#\#  [    30 116000]}
\CommentTok{\#\#  [    20  49000]}
\CommentTok{\#\#  [    37  74000]}
\CommentTok{\#\#  [    41  59000]}
\CommentTok{\#\#  [    49  89000]}
\CommentTok{\#\#  [    28  79000]}
\CommentTok{\#\#  [    53  82000]}
\CommentTok{\#\#  [    40  57000]}
\CommentTok{\#\#  [    60  34000]}
\CommentTok{\#\#  [    35 108000]}
\CommentTok{\#\#  [    21  72000]}
\CommentTok{\#\#  [    38  71000]}
\CommentTok{\#\#  [    39 106000]}
\CommentTok{\#\#  [    37  57000]}
\CommentTok{\#\#  [    26  72000]}
\CommentTok{\#\#  [    35  23000]}
\CommentTok{\#\#  [    54 108000]}
\CommentTok{\#\#  [    30  17000]}
\CommentTok{\#\#  [    39 134000]}
\CommentTok{\#\#  [    29  43000]}
\CommentTok{\#\#  [    33  43000]}
\CommentTok{\#\#  [    35  38000]}
\CommentTok{\#\#  [    41  45000]}
\CommentTok{\#\#  [    41  72000]}
\CommentTok{\#\#  [    39 134000]}
\CommentTok{\#\#  [    27 137000]}
\CommentTok{\#\#  [    21  16000]}
\CommentTok{\#\#  [    26  32000]}
\CommentTok{\#\#  [    31  66000]}
\CommentTok{\#\#  [    39  73000]}
\CommentTok{\#\#  [    41  79000]}
\CommentTok{\#\#  [    47  50000]}
\CommentTok{\#\#  [    41  30000]}
\CommentTok{\#\#  [    37  93000]}
\CommentTok{\#\#  [    60  46000]}
\CommentTok{\#\#  [    25  22000]}
\CommentTok{\#\#  [    28  37000]}
\CommentTok{\#\#  [    38  55000]}
\CommentTok{\#\#  [    36  54000]}
\CommentTok{\#\#  [    20  36000]}
\CommentTok{\#\#  [    56 104000]}
\CommentTok{\#\#  [    40  57000]}
\CommentTok{\#\#  [    42 108000]}
\CommentTok{\#\#  [    20  23000]}
\CommentTok{\#\#  [    40  65000]}
\CommentTok{\#\#  [    47  20000]}
\CommentTok{\#\#  [    18  86000]}
\CommentTok{\#\#  [    35  79000]}
\CommentTok{\#\#  [    57  33000]}
\CommentTok{\#\#  [    34  72000]}
\CommentTok{\#\#  [    49  39000]}
\CommentTok{\#\#  [    27  31000]}
\CommentTok{\#\#  [    19  70000]}
\CommentTok{\#\#  [    39  79000]}
\CommentTok{\#\#  [    26  81000]}
\CommentTok{\#\#  [    25  80000]}
\CommentTok{\#\#  [    28  85000]}
\CommentTok{\#\#  [    55  39000]}
\CommentTok{\#\#  [    50  88000]}
\CommentTok{\#\#  [    49  88000]}
\CommentTok{\#\#  [    52 150000]}
\CommentTok{\#\#  [    35  65000]}
\CommentTok{\#\#  [    42  54000]}
\CommentTok{\#\#  [    34  43000]}
\CommentTok{\#\#  [    37  52000]}
\CommentTok{\#\#  [    48  30000]}
\CommentTok{\#\#  [    29  43000]}
\CommentTok{\#\#  [    36  52000]}
\CommentTok{\#\#  [    27  54000]}
\CommentTok{\#\#  [    26 118000]]}
\BuiltInTok{print}\NormalTok{(y\_train)}
\CommentTok{\#\# [0 1 0 1 1 1 0 0 0 0 0 0 1 1 1 0 1 0 0 1 0 1 0 1 0 0 1 1 1 1 0 1 0 1 0 0 1}
\CommentTok{\#\#  0 0 1 0 0 0 0 0 1 1 1 1 0 0 0 1 0 1 0 1 0 0 1 0 0 0 1 0 0 0 1 1 0 0 1 0 1}
\CommentTok{\#\#  1 1 0 0 1 1 0 0 1 1 0 1 0 0 1 1 0 1 1 1 0 0 0 0 0 1 0 0 1 1 1 1 1 0 1 1 0}
\CommentTok{\#\#  1 0 0 0 0 0 0 0 1 1 0 0 1 0 0 1 0 0 0 1 0 1 1 0 1 0 0 0 0 1 0 0 0 1 1 0 0}
\CommentTok{\#\#  0 0 1 0 1 0 0 0 1 0 0 0 0 1 1 1 0 0 0 0 0 0 1 1 1 1 1 0 1 0 0 0 0 0 1 0 0}
\CommentTok{\#\#  0 0 0 0 1 1 0 1 0 1 0 0 1 0 0 0 1 0 0 0 0 0 1 0 0 0 0 0 1 0 1 1 0 0 0 0 0}
\CommentTok{\#\#  0 1 1 0 0 0 0 1 0 0 0 0 1 0 1 0 1 0 0 0 1 0 0 0 1 0 1 0 0 0 0 0 1 1 0 0 0}
\CommentTok{\#\#  0 0 1 0 1 1 0 0 0 0 0 1 0 1 0 0 1 0 0 1 0 1 0 0 0 0 0 0 1 1 1 1 0 0 0 0 1}
\CommentTok{\#\#  0 0 0 0]}
\BuiltInTok{print}\NormalTok{(X\_test)}
\CommentTok{\#\# [[    30  87000]}
\CommentTok{\#\#  [    38  50000]}
\CommentTok{\#\#  [    35  75000]}
\CommentTok{\#\#  [    30  79000]}
\CommentTok{\#\#  [    35  50000]}
\CommentTok{\#\#  [    27  20000]}
\CommentTok{\#\#  [    31  15000]}
\CommentTok{\#\#  [    36 144000]}
\CommentTok{\#\#  [    18  68000]}
\CommentTok{\#\#  [    47  43000]}
\CommentTok{\#\#  [    30  49000]}
\CommentTok{\#\#  [    28  55000]}
\CommentTok{\#\#  [    37  55000]}
\CommentTok{\#\#  [    39  77000]}
\CommentTok{\#\#  [    20  86000]}
\CommentTok{\#\#  [    32 117000]}
\CommentTok{\#\#  [    37  77000]}
\CommentTok{\#\#  [    19  85000]}
\CommentTok{\#\#  [    55 130000]}
\CommentTok{\#\#  [    35  22000]}
\CommentTok{\#\#  [    35  47000]}
\CommentTok{\#\#  [    47 144000]}
\CommentTok{\#\#  [    41  51000]}
\CommentTok{\#\#  [    47 105000]}
\CommentTok{\#\#  [    23  28000]}
\CommentTok{\#\#  [    49 141000]}
\CommentTok{\#\#  [    28  87000]}
\CommentTok{\#\#  [    29  80000]}
\CommentTok{\#\#  [    37  62000]}
\CommentTok{\#\#  [    32  86000]}
\CommentTok{\#\#  [    21  88000]}
\CommentTok{\#\#  [    37  79000]}
\CommentTok{\#\#  [    57  60000]}
\CommentTok{\#\#  [    37  53000]}
\CommentTok{\#\#  [    24  58000]}
\CommentTok{\#\#  [    18  52000]}
\CommentTok{\#\#  [    22  81000]}
\CommentTok{\#\#  [    34  43000]}
\CommentTok{\#\#  [    31  34000]}
\CommentTok{\#\#  [    49  36000]}
\CommentTok{\#\#  [    27  88000]}
\CommentTok{\#\#  [    41  52000]}
\CommentTok{\#\#  [    27  84000]}
\CommentTok{\#\#  [    35  20000]}
\CommentTok{\#\#  [    43 112000]}
\CommentTok{\#\#  [    27  58000]}
\CommentTok{\#\#  [    37  80000]}
\CommentTok{\#\#  [    52  90000]}
\CommentTok{\#\#  [    26  30000]}
\CommentTok{\#\#  [    49  86000]}
\CommentTok{\#\#  [    57 122000]}
\CommentTok{\#\#  [    34  25000]}
\CommentTok{\#\#  [    35  57000]}
\CommentTok{\#\#  [    34 115000]}
\CommentTok{\#\#  [    59  88000]}
\CommentTok{\#\#  [    45  32000]}
\CommentTok{\#\#  [    29  83000]}
\CommentTok{\#\#  [    26  80000]}
\CommentTok{\#\#  [    49  28000]}
\CommentTok{\#\#  [    23  20000]}
\CommentTok{\#\#  [    32  18000]}
\CommentTok{\#\#  [    60  42000]}
\CommentTok{\#\#  [    19  76000]}
\CommentTok{\#\#  [    36  99000]}
\CommentTok{\#\#  [    19  26000]}
\CommentTok{\#\#  [    60  83000]}
\CommentTok{\#\#  [    24  89000]}
\CommentTok{\#\#  [    27  58000]}
\CommentTok{\#\#  [    40  47000]}
\CommentTok{\#\#  [    42  70000]}
\CommentTok{\#\#  [    32 150000]}
\CommentTok{\#\#  [    35  77000]}
\CommentTok{\#\#  [    22  63000]}
\CommentTok{\#\#  [    45  22000]}
\CommentTok{\#\#  [    27  89000]}
\CommentTok{\#\#  [    18  82000]}
\CommentTok{\#\#  [    42  79000]}
\CommentTok{\#\#  [    40  60000]}
\CommentTok{\#\#  [    53  34000]}
\CommentTok{\#\#  [    47 107000]}
\CommentTok{\#\#  [    58 144000]}
\CommentTok{\#\#  [    59  83000]}
\CommentTok{\#\#  [    24  55000]}
\CommentTok{\#\#  [    26  35000]}
\CommentTok{\#\#  [    58  38000]}
\CommentTok{\#\#  [    42  80000]}
\CommentTok{\#\#  [    40  75000]}
\CommentTok{\#\#  [    59 130000]}
\CommentTok{\#\#  [    46  41000]}
\CommentTok{\#\#  [    41  60000]}
\CommentTok{\#\#  [    42  64000]}
\CommentTok{\#\#  [    37 146000]}
\CommentTok{\#\#  [    23  48000]}
\CommentTok{\#\#  [    25  33000]}
\CommentTok{\#\#  [    24  84000]}
\CommentTok{\#\#  [    27  96000]}
\CommentTok{\#\#  [    23  63000]}
\CommentTok{\#\#  [    48  33000]}
\CommentTok{\#\#  [    48  90000]}
\CommentTok{\#\#  [    42 104000]]}
\BuiltInTok{print}\NormalTok{(y\_test)}
\CommentTok{\#\# [0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 1 0 0 1 0 1 0 1 0 0 0 0 0 1 1 0 0 0 0}
\CommentTok{\#\#  0 0 1 0 0 0 0 1 0 0 1 0 1 1 0 0 0 1 1 0 0 1 0 0 1 0 1 0 1 0 0 0 0 1 0 0 1}
\CommentTok{\#\#  0 0 0 0 1 1 1 0 0 0 1 1 0 1 1 0 0 1 0 0 0 1 0 1 1 1]}
\end{Highlighting}
\end{Shaded}

R

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\# install.packages(\textquotesingle{}caTools\textquotesingle{})}
\FunctionTok{library}\NormalTok{(caTools)}
\FunctionTok{set.seed}\NormalTok{(}\DecValTok{123}\NormalTok{)}
\NormalTok{split }\OtherTok{=} \FunctionTok{sample.split}\NormalTok{(dataset}\SpecialCharTok{$}\NormalTok{Purchased, }\AttributeTok{SplitRatio =} \FloatTok{0.75}\NormalTok{)}
\NormalTok{training\_set }\OtherTok{=} \FunctionTok{subset}\NormalTok{(dataset, split }\SpecialCharTok{==} \ConstantTok{TRUE}\NormalTok{)}
\NormalTok{test\_set }\OtherTok{=} \FunctionTok{subset}\NormalTok{(dataset, split }\SpecialCharTok{==} \ConstantTok{FALSE}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\hypertarget{feature-scaling-4}{%
\subsection{Feature Scaling}\label{feature-scaling-4}}

Python

\begin{Shaded}
\begin{Highlighting}[]
\ImportTok{from}\NormalTok{ sklearn.preprocessing }\ImportTok{import}\NormalTok{ StandardScaler}
\NormalTok{sc }\OperatorTok{=}\NormalTok{ StandardScaler()}
\NormalTok{X\_train }\OperatorTok{=}\NormalTok{ sc.fit\_transform(X\_train)}
\NormalTok{X\_test }\OperatorTok{=}\NormalTok{ sc.transform(X\_test)}
\BuiltInTok{print}\NormalTok{(X\_train)}
\CommentTok{\#\# [[ 0.58 {-}0.89]}
\CommentTok{\#\#  [{-}0.61  1.46]}
\CommentTok{\#\#  [{-}0.01 {-}0.57]}
\CommentTok{\#\#  [{-}0.61  1.9 ]}
\CommentTok{\#\#  [ 1.37 {-}1.41]}
\CommentTok{\#\#  [ 1.47  1.  ]}
\CommentTok{\#\#  [ 0.09 {-}0.8 ]}
\CommentTok{\#\#  [{-}0.01 {-}0.25]}
\CommentTok{\#\#  [{-}0.21 {-}0.57]}
\CommentTok{\#\#  [{-}0.21 {-}0.19]}
\CommentTok{\#\#  [{-}0.31 {-}1.29]}
\CommentTok{\#\#  [{-}0.31 {-}0.57]}
\CommentTok{\#\#  [ 0.38  0.1 ]}
\CommentTok{\#\#  [ 0.88 {-}0.6 ]}
\CommentTok{\#\#  [ 2.07 {-}1.18]}
\CommentTok{\#\#  [ 1.08 {-}0.13]}
\CommentTok{\#\#  [ 0.68  1.78]}
\CommentTok{\#\#  [{-}0.71  0.56]}
\CommentTok{\#\#  [ 0.78  0.36]}
\CommentTok{\#\#  [ 0.88 {-}0.54]}
\CommentTok{\#\#  [{-}1.2  {-}1.58]}
\CommentTok{\#\#  [ 2.17  0.94]}
\CommentTok{\#\#  [{-}0.01  1.23]}
\CommentTok{\#\#  [ 0.19  1.08]}
\CommentTok{\#\#  [ 0.38 {-}0.48]}
\CommentTok{\#\#  [{-}0.31 {-}0.31]}
\CommentTok{\#\#  [ 0.98 {-}0.83]}
\CommentTok{\#\#  [ 0.98  1.87]}
\CommentTok{\#\#  [{-}0.01  1.26]}
\CommentTok{\#\#  [{-}0.9   2.27]}
\CommentTok{\#\#  [{-}1.2  {-}1.58]}
\CommentTok{\#\#  [ 2.17 {-}0.8 ]}
\CommentTok{\#\#  [{-}1.4  {-}1.47]}
\CommentTok{\#\#  [ 0.38  2.3 ]}
\CommentTok{\#\#  [ 0.78  0.77]}
\CommentTok{\#\#  [{-}1.   {-}0.31]}
\CommentTok{\#\#  [ 0.09  0.77]}
\CommentTok{\#\#  [{-}1.    0.56]}
\CommentTok{\#\#  [ 0.28  0.07]}
\CommentTok{\#\#  [ 0.68 {-}1.26]}
\CommentTok{\#\#  [{-}0.51 {-}0.02]}
\CommentTok{\#\#  [{-}1.8   0.36]}
\CommentTok{\#\#  [{-}0.71  0.13]}
\CommentTok{\#\#  [ 0.38  0.3 ]}
\CommentTok{\#\#  [{-}0.31  0.07]}
\CommentTok{\#\#  [{-}0.51  2.3 ]}
\CommentTok{\#\#  [ 0.19  0.04]}
\CommentTok{\#\#  [ 1.27  2.22]}
\CommentTok{\#\#  [ 0.78  0.27]}
\CommentTok{\#\#  [{-}0.31  0.16]}
\CommentTok{\#\#  [{-}0.01 {-}0.54]}
\CommentTok{\#\#  [{-}0.21  0.16]}
\CommentTok{\#\#  [{-}0.11  0.24]}
\CommentTok{\#\#  [{-}0.01 {-}0.25]}
\CommentTok{\#\#  [ 2.17  1.11]}
\CommentTok{\#\#  [{-}1.8   0.36]}
\CommentTok{\#\#  [ 1.87  0.13]}
\CommentTok{\#\#  [ 0.38 {-}0.13]}
\CommentTok{\#\#  [{-}1.2   0.3 ]}
\CommentTok{\#\#  [ 0.78  1.37]}
\CommentTok{\#\#  [{-}0.31 {-}0.25]}
\CommentTok{\#\#  [{-}1.7  {-}0.05]}
\CommentTok{\#\#  [{-}1.   {-}0.74]}
\CommentTok{\#\#  [ 0.28  0.5 ]}
\CommentTok{\#\#  [{-}0.11 {-}1.06]}
\CommentTok{\#\#  [{-}1.1   0.59]}
\CommentTok{\#\#  [ 0.09 {-}0.8 ]}
\CommentTok{\#\#  [{-}1.    1.55]}
\CommentTok{\#\#  [{-}0.71  1.4 ]}
\CommentTok{\#\#  [{-}1.3   0.5 ]}
\CommentTok{\#\#  [{-}0.31  0.04]}
\CommentTok{\#\#  [{-}0.11  0.01]}
\CommentTok{\#\#  [{-}0.31 {-}0.89]}
\CommentTok{\#\#  [ 0.88 {-}1.35]}
\CommentTok{\#\#  [{-}0.31  2.24]}
\CommentTok{\#\#  [ 0.98  1.98]}
\CommentTok{\#\#  [{-}1.2   0.48]}
\CommentTok{\#\#  [{-}1.3   0.27]}
\CommentTok{\#\#  [ 1.37  1.98]}
\CommentTok{\#\#  [ 1.27 {-}1.35]}
\CommentTok{\#\#  [{-}0.31 {-}0.28]}
\CommentTok{\#\#  [{-}0.51  1.26]}
\CommentTok{\#\#  [{-}0.8   1.08]}
\CommentTok{\#\#  [ 0.98 {-}1.06]}
\CommentTok{\#\#  [ 0.28  0.3 ]}
\CommentTok{\#\#  [ 0.98  0.77]}
\CommentTok{\#\#  [{-}0.71 {-}1.5 ]}
\CommentTok{\#\#  [{-}0.71  0.04]}
\CommentTok{\#\#  [ 0.48  1.72]}
\CommentTok{\#\#  [ 2.07  0.19]}
\CommentTok{\#\#  [{-}1.99 {-}0.74]}
\CommentTok{\#\#  [{-}0.21  1.4 ]}
\CommentTok{\#\#  [ 0.38  0.59]}
\CommentTok{\#\#  [ 0.88 {-}1.15]}
\CommentTok{\#\#  [{-}1.2  {-}0.77]}
\CommentTok{\#\#  [ 0.19  0.24]}
\CommentTok{\#\#  [ 0.78 {-}0.31]}
\CommentTok{\#\#  [ 2.07 {-}0.8 ]}
\CommentTok{\#\#  [ 0.78  0.13]}
\CommentTok{\#\#  [{-}0.31  0.62]}
\CommentTok{\#\#  [{-}1.   {-}0.31]}
\CommentTok{\#\#  [ 0.19 {-}0.36]}
\CommentTok{\#\#  [ 2.07  2.13]}
\CommentTok{\#\#  [ 1.87 {-}1.26]}
\CommentTok{\#\#  [ 1.37 {-}0.92]}
\CommentTok{\#\#  [ 0.88  1.26]}
\CommentTok{\#\#  [ 1.47  2.13]}
\CommentTok{\#\#  [{-}0.31 {-}1.23]}
\CommentTok{\#\#  [ 1.97  0.91]}
\CommentTok{\#\#  [ 0.68 {-}0.71]}
\CommentTok{\#\#  [{-}1.5   0.36]}
\CommentTok{\#\#  [ 0.78 {-}1.35]}
\CommentTok{\#\#  [ 0.38 {-}0.13]}
\CommentTok{\#\#  [{-}1.    0.42]}
\CommentTok{\#\#  [{-}0.01 {-}0.31]}
\CommentTok{\#\#  [{-}1.2   0.42]}
\CommentTok{\#\#  [{-}0.9  {-}1.21]}
\CommentTok{\#\#  [{-}0.11  0.04]}
\CommentTok{\#\#  [{-}1.6  {-}0.42]}
\CommentTok{\#\#  [ 0.98 {-}1.  ]}
\CommentTok{\#\#  [ 1.08 {-}1.21]}
\CommentTok{\#\#  [{-}0.01 {-}0.13]}
\CommentTok{\#\#  [{-}1.1  {-}1.52]}
\CommentTok{\#\#  [ 0.78 {-}1.21]}
\CommentTok{\#\#  [ 0.98  2.07]}
\CommentTok{\#\#  [{-}1.2  {-}1.52]}
\CommentTok{\#\#  [{-}0.31  0.79]}
\CommentTok{\#\#  [ 0.09 {-}0.31]}
\CommentTok{\#\#  [{-}1.4  {-}1.23]}
\CommentTok{\#\#  [{-}0.61 {-}1.5 ]}
\CommentTok{\#\#  [ 0.78  0.53]}
\CommentTok{\#\#  [{-}0.31 {-}0.34]}
\CommentTok{\#\#  [ 1.77 {-}0.28]}
\CommentTok{\#\#  [ 0.88 {-}1.03]}
\CommentTok{\#\#  [ 0.19  0.07]}
\CommentTok{\#\#  [{-}0.61  0.88]}
\CommentTok{\#\#  [{-}1.89 {-}1.41]}
\CommentTok{\#\#  [{-}1.3   0.59]}
\CommentTok{\#\#  [{-}0.31  0.53]}
\CommentTok{\#\#  [{-}1.   {-}1.09]}
\CommentTok{\#\#  [ 1.18 {-}1.44]}
\CommentTok{\#\#  [ 0.19 {-}0.31]}
\CommentTok{\#\#  [ 1.18 {-}0.74]}
\CommentTok{\#\#  [{-}0.31  0.07]}
\CommentTok{\#\#  [ 0.19  2.1 ]}
\CommentTok{\#\#  [ 0.78 {-}1.09]}
\CommentTok{\#\#  [ 0.09  0.04]}
\CommentTok{\#\#  [{-}1.8   0.13]}
\CommentTok{\#\#  [{-}0.9   0.16]}
\CommentTok{\#\#  [{-}0.71  0.19]}
\CommentTok{\#\#  [ 0.88 {-}1.29]}
\CommentTok{\#\#  [ 0.19 {-}0.25]}
\CommentTok{\#\#  [{-}0.41  1.23]}
\CommentTok{\#\#  [{-}0.01  0.3 ]}
\CommentTok{\#\#  [ 0.38  0.16]}
\CommentTok{\#\#  [ 0.88 {-}0.65]}
\CommentTok{\#\#  [ 0.09  0.16]}
\CommentTok{\#\#  [{-}1.89 {-}1.29]}
\CommentTok{\#\#  [{-}0.11  0.3 ]}
\CommentTok{\#\#  [{-}0.21 {-}0.28]}
\CommentTok{\#\#  [ 0.28 {-}0.51]}
\CommentTok{\#\#  [{-}0.21  1.61]}
\CommentTok{\#\#  [ 0.98 {-}1.18]}
\CommentTok{\#\#  [{-}0.21  1.64]}
\CommentTok{\#\#  [ 1.27  1.87]}
\CommentTok{\#\#  [{-}1.1  {-}0.36]}
\CommentTok{\#\#  [{-}0.01  0.04]}
\CommentTok{\#\#  [ 0.09 {-}0.25]}
\CommentTok{\#\#  [{-}1.6  {-}1.23]}
\CommentTok{\#\#  [{-}0.51 {-}0.28]}
\CommentTok{\#\#  [ 0.98  0.13]}
\CommentTok{\#\#  [ 1.97 {-}1.35]}
\CommentTok{\#\#  [ 1.47  0.07]}
\CommentTok{\#\#  [{-}0.61  1.37]}
\CommentTok{\#\#  [ 1.57  0.01]}
\CommentTok{\#\#  [{-}0.8   0.3 ]}
\CommentTok{\#\#  [ 1.97  0.74]}
\CommentTok{\#\#  [{-}1.2  {-}0.51]}
\CommentTok{\#\#  [ 0.68  0.27]}
\CommentTok{\#\#  [{-}1.4  {-}0.42]}
\CommentTok{\#\#  [ 0.19  0.16]}
\CommentTok{\#\#  [{-}0.51 {-}1.21]}
\CommentTok{\#\#  [ 0.58  2.01]}
\CommentTok{\#\#  [{-}1.6  {-}1.5 ]}
\CommentTok{\#\#  [{-}0.51 {-}0.54]}
\CommentTok{\#\#  [ 0.48  1.84]}
\CommentTok{\#\#  [{-}1.4  {-}1.09]}
\CommentTok{\#\#  [ 0.78 {-}1.38]}
\CommentTok{\#\#  [{-}0.31 {-}0.42]}
\CommentTok{\#\#  [ 1.57  1.  ]}
\CommentTok{\#\#  [ 0.98  1.43]}
\CommentTok{\#\#  [{-}0.31 {-}0.48]}
\CommentTok{\#\#  [{-}0.11  2.16]}
\CommentTok{\#\#  [{-}1.5  {-}0.1 ]}
\CommentTok{\#\#  [{-}0.11  1.95]}
\CommentTok{\#\#  [{-}0.71 {-}0.34]}
\CommentTok{\#\#  [{-}0.51 {-}0.83]}
\CommentTok{\#\#  [ 0.68 {-}1.38]}
\CommentTok{\#\#  [{-}0.8  {-}1.58]}
\CommentTok{\#\#  [{-}1.89 {-}1.47]}
\CommentTok{\#\#  [ 1.08  0.13]}
\CommentTok{\#\#  [ 0.09  1.52]}
\CommentTok{\#\#  [{-}0.31  0.1 ]}
\CommentTok{\#\#  [ 0.09  0.04]}
\CommentTok{\#\#  [{-}1.4  {-}1.35]}
\CommentTok{\#\#  [ 0.28  0.07]}
\CommentTok{\#\#  [{-}0.9   0.39]}
\CommentTok{\#\#  [ 1.57 {-}1.26]}
\CommentTok{\#\#  [{-}0.31 {-}0.74]}
\CommentTok{\#\#  [{-}0.11  0.16]}
\CommentTok{\#\#  [{-}0.9  {-}0.65]}
\CommentTok{\#\#  [{-}0.71 {-}0.05]}
\CommentTok{\#\#  [ 0.38 {-}0.45]}
\CommentTok{\#\#  [{-}0.8   1.9 ]}
\CommentTok{\#\#  [ 1.37  1.29]}
\CommentTok{\#\#  [ 1.18 {-}0.97]}
\CommentTok{\#\#  [ 1.77  1.84]}
\CommentTok{\#\#  [{-}0.9  {-}0.25]}
\CommentTok{\#\#  [{-}0.8   0.56]}
\CommentTok{\#\#  [{-}1.2  {-}1.55]}
\CommentTok{\#\#  [{-}0.51 {-}1.12]}
\CommentTok{\#\#  [ 0.28  0.07]}
\CommentTok{\#\#  [{-}0.21 {-}1.06]}
\CommentTok{\#\#  [ 1.67  1.61]}
\CommentTok{\#\#  [ 0.98  1.78]}
\CommentTok{\#\#  [ 0.28  0.04]}
\CommentTok{\#\#  [{-}0.8  {-}0.22]}
\CommentTok{\#\#  [{-}0.11  0.07]}
\CommentTok{\#\#  [ 0.28 {-}0.19]}
\CommentTok{\#\#  [ 1.97 {-}0.65]}
\CommentTok{\#\#  [{-}0.8   1.35]}
\CommentTok{\#\#  [{-}1.8  {-}0.6 ]}
\CommentTok{\#\#  [{-}0.11  0.13]}
\CommentTok{\#\#  [ 0.28 {-}0.31]}
\CommentTok{\#\#  [ 1.08  0.56]}
\CommentTok{\#\#  [{-}1.    0.27]}
\CommentTok{\#\#  [ 1.47  0.36]}
\CommentTok{\#\#  [ 0.19 {-}0.36]}
\CommentTok{\#\#  [ 2.17 {-}1.03]}
\CommentTok{\#\#  [{-}0.31  1.11]}
\CommentTok{\#\#  [{-}1.7   0.07]}
\CommentTok{\#\#  [{-}0.01  0.04]}
\CommentTok{\#\#  [ 0.09  1.06]}
\CommentTok{\#\#  [{-}0.11 {-}0.36]}
\CommentTok{\#\#  [{-}1.2   0.07]}
\CommentTok{\#\#  [{-}0.31 {-}1.35]}
\CommentTok{\#\#  [ 1.57  1.11]}
\CommentTok{\#\#  [{-}0.8  {-}1.52]}
\CommentTok{\#\#  [ 0.09  1.87]}
\CommentTok{\#\#  [{-}0.9  {-}0.77]}
\CommentTok{\#\#  [{-}0.51 {-}0.77]}
\CommentTok{\#\#  [{-}0.31 {-}0.92]}
\CommentTok{\#\#  [ 0.28 {-}0.71]}
\CommentTok{\#\#  [ 0.28  0.07]}
\CommentTok{\#\#  [ 0.09  1.87]}
\CommentTok{\#\#  [{-}1.1   1.95]}
\CommentTok{\#\#  [{-}1.7  {-}1.55]}
\CommentTok{\#\#  [{-}1.2  {-}1.09]}
\CommentTok{\#\#  [{-}0.71 {-}0.1 ]}
\CommentTok{\#\#  [ 0.09  0.1 ]}
\CommentTok{\#\#  [ 0.28  0.27]}
\CommentTok{\#\#  [ 0.88 {-}0.57]}
\CommentTok{\#\#  [ 0.28 {-}1.15]}
\CommentTok{\#\#  [{-}0.11  0.68]}
\CommentTok{\#\#  [ 2.17 {-}0.68]}
\CommentTok{\#\#  [{-}1.3  {-}1.38]}
\CommentTok{\#\#  [{-}1.   {-}0.94]}
\CommentTok{\#\#  [{-}0.01 {-}0.42]}
\CommentTok{\#\#  [{-}0.21 {-}0.45]}
\CommentTok{\#\#  [{-}1.8  {-}0.97]}
\CommentTok{\#\#  [ 1.77  1.  ]}
\CommentTok{\#\#  [ 0.19 {-}0.36]}
\CommentTok{\#\#  [ 0.38  1.11]}
\CommentTok{\#\#  [{-}1.8  {-}1.35]}
\CommentTok{\#\#  [ 0.19 {-}0.13]}
\CommentTok{\#\#  [ 0.88 {-}1.44]}
\CommentTok{\#\#  [{-}1.99  0.48]}
\CommentTok{\#\#  [{-}0.31  0.27]}
\CommentTok{\#\#  [ 1.87 {-}1.06]}
\CommentTok{\#\#  [{-}0.41  0.07]}
\CommentTok{\#\#  [ 1.08 {-}0.89]}
\CommentTok{\#\#  [{-}1.1  {-}1.12]}
\CommentTok{\#\#  [{-}1.89  0.01]}
\CommentTok{\#\#  [ 0.09  0.27]}
\CommentTok{\#\#  [{-}1.2   0.33]}
\CommentTok{\#\#  [{-}1.3   0.3 ]}
\CommentTok{\#\#  [{-}1.    0.45]}
\CommentTok{\#\#  [ 1.67 {-}0.89]}
\CommentTok{\#\#  [ 1.18  0.53]}
\CommentTok{\#\#  [ 1.08  0.53]}
\CommentTok{\#\#  [ 1.37  2.33]}
\CommentTok{\#\#  [{-}0.31 {-}0.13]}
\CommentTok{\#\#  [ 0.38 {-}0.45]}
\CommentTok{\#\#  [{-}0.41 {-}0.77]}
\CommentTok{\#\#  [{-}0.11 {-}0.51]}
\CommentTok{\#\#  [ 0.98 {-}1.15]}
\CommentTok{\#\#  [{-}0.9  {-}0.77]}
\CommentTok{\#\#  [{-}0.21 {-}0.51]}
\CommentTok{\#\#  [{-}1.1  {-}0.45]}
\CommentTok{\#\#  [{-}1.2   1.4 ]]}
\BuiltInTok{print}\NormalTok{(X\_test)}
\CommentTok{\#\# [[{-}0.8   0.5 ]}
\CommentTok{\#\#  [{-}0.01 {-}0.57]}
\CommentTok{\#\#  [{-}0.31  0.16]}
\CommentTok{\#\#  [{-}0.8   0.27]}
\CommentTok{\#\#  [{-}0.31 {-}0.57]}
\CommentTok{\#\#  [{-}1.1  {-}1.44]}
\CommentTok{\#\#  [{-}0.71 {-}1.58]}
\CommentTok{\#\#  [{-}0.21  2.16]}
\CommentTok{\#\#  [{-}1.99 {-}0.05]}
\CommentTok{\#\#  [ 0.88 {-}0.77]}
\CommentTok{\#\#  [{-}0.8  {-}0.6 ]}
\CommentTok{\#\#  [{-}1.   {-}0.42]}
\CommentTok{\#\#  [{-}0.11 {-}0.42]}
\CommentTok{\#\#  [ 0.09  0.22]}
\CommentTok{\#\#  [{-}1.8   0.48]}
\CommentTok{\#\#  [{-}0.61  1.37]}
\CommentTok{\#\#  [{-}0.11  0.22]}
\CommentTok{\#\#  [{-}1.89  0.45]}
\CommentTok{\#\#  [ 1.67  1.75]}
\CommentTok{\#\#  [{-}0.31 {-}1.38]}
\CommentTok{\#\#  [{-}0.31 {-}0.65]}
\CommentTok{\#\#  [ 0.88  2.16]}
\CommentTok{\#\#  [ 0.28 {-}0.54]}
\CommentTok{\#\#  [ 0.88  1.03]}
\CommentTok{\#\#  [{-}1.5  {-}1.21]}
\CommentTok{\#\#  [ 1.08  2.07]}
\CommentTok{\#\#  [{-}1.    0.5 ]}
\CommentTok{\#\#  [{-}0.9   0.3 ]}
\CommentTok{\#\#  [{-}0.11 {-}0.22]}
\CommentTok{\#\#  [{-}0.61  0.48]}
\CommentTok{\#\#  [{-}1.7   0.53]}
\CommentTok{\#\#  [{-}0.11  0.27]}
\CommentTok{\#\#  [ 1.87 {-}0.28]}
\CommentTok{\#\#  [{-}0.11 {-}0.48]}
\CommentTok{\#\#  [{-}1.4  {-}0.34]}
\CommentTok{\#\#  [{-}1.99 {-}0.51]}
\CommentTok{\#\#  [{-}1.6   0.33]}
\CommentTok{\#\#  [{-}0.41 {-}0.77]}
\CommentTok{\#\#  [{-}0.71 {-}1.03]}
\CommentTok{\#\#  [ 1.08 {-}0.97]}
\CommentTok{\#\#  [{-}1.1   0.53]}
\CommentTok{\#\#  [ 0.28 {-}0.51]}
\CommentTok{\#\#  [{-}1.1   0.42]}
\CommentTok{\#\#  [{-}0.31 {-}1.44]}
\CommentTok{\#\#  [ 0.48  1.23]}
\CommentTok{\#\#  [{-}1.1  {-}0.34]}
\CommentTok{\#\#  [{-}0.11  0.3 ]}
\CommentTok{\#\#  [ 1.37  0.59]}
\CommentTok{\#\#  [{-}1.2  {-}1.15]}
\CommentTok{\#\#  [ 1.08  0.48]}
\CommentTok{\#\#  [ 1.87  1.52]}
\CommentTok{\#\#  [{-}0.41 {-}1.29]}
\CommentTok{\#\#  [{-}0.31 {-}0.36]}
\CommentTok{\#\#  [{-}0.41  1.32]}
\CommentTok{\#\#  [ 2.07  0.53]}
\CommentTok{\#\#  [ 0.68 {-}1.09]}
\CommentTok{\#\#  [{-}0.9   0.39]}
\CommentTok{\#\#  [{-}1.2   0.3 ]}
\CommentTok{\#\#  [ 1.08 {-}1.21]}
\CommentTok{\#\#  [{-}1.5  {-}1.44]}
\CommentTok{\#\#  [{-}0.61 {-}1.5 ]}
\CommentTok{\#\#  [ 2.17 {-}0.8 ]}
\CommentTok{\#\#  [{-}1.89  0.19]}
\CommentTok{\#\#  [{-}0.21  0.85]}
\CommentTok{\#\#  [{-}1.89 {-}1.26]}
\CommentTok{\#\#  [ 2.17  0.39]}
\CommentTok{\#\#  [{-}1.4   0.56]}
\CommentTok{\#\#  [{-}1.1  {-}0.34]}
\CommentTok{\#\#  [ 0.19 {-}0.65]}
\CommentTok{\#\#  [ 0.38  0.01]}
\CommentTok{\#\#  [{-}0.61  2.33]}
\CommentTok{\#\#  [{-}0.31  0.22]}
\CommentTok{\#\#  [{-}1.6  {-}0.19]}
\CommentTok{\#\#  [ 0.68 {-}1.38]}
\CommentTok{\#\#  [{-}1.1   0.56]}
\CommentTok{\#\#  [{-}1.99  0.36]}
\CommentTok{\#\#  [ 0.38  0.27]}
\CommentTok{\#\#  [ 0.19 {-}0.28]}
\CommentTok{\#\#  [ 1.47 {-}1.03]}
\CommentTok{\#\#  [ 0.88  1.08]}
\CommentTok{\#\#  [ 1.97  2.16]}
\CommentTok{\#\#  [ 2.07  0.39]}
\CommentTok{\#\#  [{-}1.4  {-}0.42]}
\CommentTok{\#\#  [{-}1.2  {-}1.  ]}
\CommentTok{\#\#  [ 1.97 {-}0.92]}
\CommentTok{\#\#  [ 0.38  0.3 ]}
\CommentTok{\#\#  [ 0.19  0.16]}
\CommentTok{\#\#  [ 2.07  1.75]}
\CommentTok{\#\#  [ 0.78 {-}0.83]}
\CommentTok{\#\#  [ 0.28 {-}0.28]}
\CommentTok{\#\#  [ 0.38 {-}0.16]}
\CommentTok{\#\#  [{-}0.11  2.22]}
\CommentTok{\#\#  [{-}1.5  {-}0.63]}
\CommentTok{\#\#  [{-}1.3  {-}1.06]}
\CommentTok{\#\#  [{-}1.4   0.42]}
\CommentTok{\#\#  [{-}1.1   0.77]}
\CommentTok{\#\#  [{-}1.5  {-}0.19]}
\CommentTok{\#\#  [ 0.98 {-}1.06]}
\CommentTok{\#\#  [ 0.98  0.59]}
\CommentTok{\#\#  [ 0.38  1.  ]]}
\end{Highlighting}
\end{Shaded}

R

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{training\_set[}\SpecialCharTok{{-}}\DecValTok{3}\NormalTok{] }\OtherTok{=} \FunctionTok{scale}\NormalTok{(training\_set[}\SpecialCharTok{{-}}\DecValTok{3}\NormalTok{])}
\NormalTok{test\_set[}\SpecialCharTok{{-}}\DecValTok{3}\NormalTok{] }\OtherTok{=} \FunctionTok{scale}\NormalTok{(test\_set[}\SpecialCharTok{{-}}\DecValTok{3}\NormalTok{])}
\end{Highlighting}
\end{Shaded}

\hypertarget{training-the-svm-model-on-the-training-set}{%
\subsection{Training the SVM model on the Training set}\label{training-the-svm-model-on-the-training-set}}

Python

\begin{Shaded}
\begin{Highlighting}[]
\ImportTok{from}\NormalTok{ sklearn.svm }\ImportTok{import}\NormalTok{ SVC}
\NormalTok{classifier }\OperatorTok{=}\NormalTok{ SVC(kernel }\OperatorTok{=} \StringTok{\textquotesingle{}linear\textquotesingle{}}\NormalTok{, random\_state }\OperatorTok{=} \DecValTok{0}\NormalTok{)}
\NormalTok{classifier.fit(X\_train, y\_train)}
\CommentTok{\#\# SVC(kernel=\textquotesingle{}linear\textquotesingle{}, random\_state=0)}
\end{Highlighting}
\end{Shaded}

R

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\# install.packages(\textquotesingle{}e1071\textquotesingle{})}
\FunctionTok{library}\NormalTok{(e1071)}
\NormalTok{classifier }\OtherTok{=} \FunctionTok{svm}\NormalTok{(}\AttributeTok{formula =}\NormalTok{ Purchased }\SpecialCharTok{\textasciitilde{}}\NormalTok{ .,}
                 \AttributeTok{data =}\NormalTok{ training\_set,}
                 \AttributeTok{type =} \StringTok{\textquotesingle{}C{-}classification\textquotesingle{}}\NormalTok{,}
                 \AttributeTok{kernel =} \StringTok{\textquotesingle{}linear\textquotesingle{}}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\hypertarget{predicting-a-new-result-5}{%
\subsection{Predicting a new result}\label{predicting-a-new-result-5}}

Python

\begin{Shaded}
\begin{Highlighting}[]
\BuiltInTok{print}\NormalTok{(classifier.predict(sc.transform([[}\DecValTok{30}\NormalTok{,}\DecValTok{87000}\NormalTok{]])))}
\CommentTok{\#\# [0]}
\end{Highlighting}
\end{Shaded}

\hypertarget{predicting-the-test-set-results-4}{%
\subsection{Predicting the Test set results}\label{predicting-the-test-set-results-4}}

Python

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{y\_pred }\OperatorTok{=}\NormalTok{ classifier.predict(X\_test)}
\BuiltInTok{print}\NormalTok{(np.concatenate((y\_pred.reshape(}\BuiltInTok{len}\NormalTok{(y\_pred),}\DecValTok{1}\NormalTok{), y\_test.reshape(}\BuiltInTok{len}\NormalTok{(y\_test),}\DecValTok{1}\NormalTok{)),}\DecValTok{1}\NormalTok{))}
\CommentTok{\#\# [[0 0]}
\CommentTok{\#\#  [0 0]}
\CommentTok{\#\#  [0 0]}
\CommentTok{\#\#  [0 0]}
\CommentTok{\#\#  [0 0]}
\CommentTok{\#\#  [0 0]}
\CommentTok{\#\#  [0 0]}
\CommentTok{\#\#  [1 1]}
\CommentTok{\#\#  [0 0]}
\CommentTok{\#\#  [0 0]}
\CommentTok{\#\#  [0 0]}
\CommentTok{\#\#  [0 0]}
\CommentTok{\#\#  [0 0]}
\CommentTok{\#\#  [0 0]}
\CommentTok{\#\#  [0 0]}
\CommentTok{\#\#  [0 0]}
\CommentTok{\#\#  [0 0]}
\CommentTok{\#\#  [0 0]}
\CommentTok{\#\#  [1 1]}
\CommentTok{\#\#  [0 0]}
\CommentTok{\#\#  [0 0]}
\CommentTok{\#\#  [1 1]}
\CommentTok{\#\#  [0 0]}
\CommentTok{\#\#  [1 1]}
\CommentTok{\#\#  [0 0]}
\CommentTok{\#\#  [1 1]}
\CommentTok{\#\#  [0 0]}
\CommentTok{\#\#  [0 0]}
\CommentTok{\#\#  [0 0]}
\CommentTok{\#\#  [0 0]}
\CommentTok{\#\#  [0 0]}
\CommentTok{\#\#  [0 1]}
\CommentTok{\#\#  [1 1]}
\CommentTok{\#\#  [0 0]}
\CommentTok{\#\#  [0 0]}
\CommentTok{\#\#  [0 0]}
\CommentTok{\#\#  [0 0]}
\CommentTok{\#\#  [0 0]}
\CommentTok{\#\#  [0 0]}
\CommentTok{\#\#  [1 1]}
\CommentTok{\#\#  [0 0]}
\CommentTok{\#\#  [0 0]}
\CommentTok{\#\#  [0 0]}
\CommentTok{\#\#  [0 0]}
\CommentTok{\#\#  [1 1]}
\CommentTok{\#\#  [0 0]}
\CommentTok{\#\#  [0 0]}
\CommentTok{\#\#  [1 1]}
\CommentTok{\#\#  [0 0]}
\CommentTok{\#\#  [1 1]}
\CommentTok{\#\#  [1 1]}
\CommentTok{\#\#  [0 0]}
\CommentTok{\#\#  [0 0]}
\CommentTok{\#\#  [0 0]}
\CommentTok{\#\#  [1 1]}
\CommentTok{\#\#  [0 1]}
\CommentTok{\#\#  [0 0]}
\CommentTok{\#\#  [0 0]}
\CommentTok{\#\#  [0 1]}
\CommentTok{\#\#  [0 0]}
\CommentTok{\#\#  [0 0]}
\CommentTok{\#\#  [1 1]}
\CommentTok{\#\#  [0 0]}
\CommentTok{\#\#  [0 1]}
\CommentTok{\#\#  [0 0]}
\CommentTok{\#\#  [1 1]}
\CommentTok{\#\#  [0 0]}
\CommentTok{\#\#  [0 0]}
\CommentTok{\#\#  [0 0]}
\CommentTok{\#\#  [0 0]}
\CommentTok{\#\#  [1 1]}
\CommentTok{\#\#  [0 0]}
\CommentTok{\#\#  [0 0]}
\CommentTok{\#\#  [0 1]}
\CommentTok{\#\#  [0 0]}
\CommentTok{\#\#  [0 0]}
\CommentTok{\#\#  [1 0]}
\CommentTok{\#\#  [0 0]}
\CommentTok{\#\#  [1 1]}
\CommentTok{\#\#  [1 1]}
\CommentTok{\#\#  [1 1]}
\CommentTok{\#\#  [1 0]}
\CommentTok{\#\#  [0 0]}
\CommentTok{\#\#  [0 0]}
\CommentTok{\#\#  [1 1]}
\CommentTok{\#\#  [1 1]}
\CommentTok{\#\#  [0 0]}
\CommentTok{\#\#  [1 1]}
\CommentTok{\#\#  [0 1]}
\CommentTok{\#\#  [0 0]}
\CommentTok{\#\#  [0 0]}
\CommentTok{\#\#  [1 1]}
\CommentTok{\#\#  [0 0]}
\CommentTok{\#\#  [0 0]}
\CommentTok{\#\#  [0 0]}
\CommentTok{\#\#  [0 1]}
\CommentTok{\#\#  [0 0]}
\CommentTok{\#\#  [0 1]}
\CommentTok{\#\#  [1 1]}
\CommentTok{\#\#  [1 1]]}
\end{Highlighting}
\end{Shaded}

R

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{y\_pred }\OtherTok{=} \FunctionTok{predict}\NormalTok{(classifier, }\AttributeTok{newdata =}\NormalTok{ test\_set[}\SpecialCharTok{{-}}\DecValTok{3}\NormalTok{])}
\end{Highlighting}
\end{Shaded}

\hypertarget{making-the-confusion-matrix-2}{%
\subsection{Making the Confusion Matrix}\label{making-the-confusion-matrix-2}}

Python

\begin{Shaded}
\begin{Highlighting}[]
\ImportTok{from}\NormalTok{ sklearn.metrics }\ImportTok{import}\NormalTok{ confusion\_matrix, accuracy\_score}
\NormalTok{cm }\OperatorTok{=}\NormalTok{ confusion\_matrix(y\_test, y\_pred)}
\BuiltInTok{print}\NormalTok{(cm)}
\CommentTok{\#\# [[66  2]}
\CommentTok{\#\#  [ 8 24]]}
\NormalTok{accuracy\_score(y\_test, y\_pred)}
\CommentTok{\#\# 0.9}
\end{Highlighting}
\end{Shaded}

R

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{cm }\OtherTok{=} \FunctionTok{table}\NormalTok{(test\_set[, }\DecValTok{3}\NormalTok{], y\_pred)}
\end{Highlighting}
\end{Shaded}

\hypertarget{visualising-the-training-set-results-3}{%
\subsection{Visualising the Training set results}\label{visualising-the-training-set-results-3}}

Python

\begin{Shaded}
\begin{Highlighting}[]
\ImportTok{from}\NormalTok{ matplotlib.colors }\ImportTok{import}\NormalTok{ ListedColormap}
\NormalTok{X\_set, y\_set }\OperatorTok{=}\NormalTok{ sc.inverse\_transform(X\_train), y\_train}
\NormalTok{X1, X2 }\OperatorTok{=}\NormalTok{ np.meshgrid(np.arange(start }\OperatorTok{=}\NormalTok{ X\_set[:, }\DecValTok{0}\NormalTok{].}\BuiltInTok{min}\NormalTok{() }\OperatorTok{{-}} \DecValTok{10}\NormalTok{, stop }\OperatorTok{=}\NormalTok{ X\_set[:, }\DecValTok{0}\NormalTok{].}\BuiltInTok{max}\NormalTok{() }\OperatorTok{+} \DecValTok{10}\NormalTok{, step }\OperatorTok{=} \FloatTok{0.25}\NormalTok{),}
\NormalTok{                     np.arange(start }\OperatorTok{=}\NormalTok{ X\_set[:, }\DecValTok{1}\NormalTok{].}\BuiltInTok{min}\NormalTok{() }\OperatorTok{{-}} \DecValTok{1000}\NormalTok{, stop }\OperatorTok{=}\NormalTok{ X\_set[:, }\DecValTok{1}\NormalTok{].}\BuiltInTok{max}\NormalTok{() }\OperatorTok{+} \DecValTok{1000}\NormalTok{, step }\OperatorTok{=} \FloatTok{0.25}\NormalTok{))}
\NormalTok{plt.contourf(X1, X2, classifier.predict(sc.transform(np.array([X1.ravel(), X2.ravel()]).T)).reshape(X1.shape),}
\NormalTok{             alpha }\OperatorTok{=} \FloatTok{0.75}\NormalTok{, cmap }\OperatorTok{=}\NormalTok{ ListedColormap((}\StringTok{\textquotesingle{}red\textquotesingle{}}\NormalTok{, }\StringTok{\textquotesingle{}green\textquotesingle{}}\NormalTok{)))}
\NormalTok{plt.xlim(X1.}\BuiltInTok{min}\NormalTok{(), X1.}\BuiltInTok{max}\NormalTok{())}
\NormalTok{plt.ylim(X2.}\BuiltInTok{min}\NormalTok{(), X2.}\BuiltInTok{max}\NormalTok{())}
\ControlFlowTok{for}\NormalTok{ i, j }\KeywordTok{in} \BuiltInTok{enumerate}\NormalTok{(np.unique(y\_set)):}
\NormalTok{    plt.scatter(X\_set[y\_set }\OperatorTok{==}\NormalTok{ j, }\DecValTok{0}\NormalTok{], X\_set[y\_set }\OperatorTok{==}\NormalTok{ j, }\DecValTok{1}\NormalTok{], c }\OperatorTok{=}\NormalTok{ ListedColormap((}\StringTok{\textquotesingle{}red\textquotesingle{}}\NormalTok{, }\StringTok{\textquotesingle{}green\textquotesingle{}}\NormalTok{))(i), label }\OperatorTok{=}\NormalTok{ j)}
\NormalTok{plt.title(}\StringTok{\textquotesingle{}SVM (Training set)\textquotesingle{}}\NormalTok{)}
\NormalTok{plt.xlabel(}\StringTok{\textquotesingle{}Age\textquotesingle{}}\NormalTok{)}
\NormalTok{plt.ylabel(}\StringTok{\textquotesingle{}Estimated Salary\textquotesingle{}}\NormalTok{)}
\NormalTok{plt.legend()}
\NormalTok{plt.show()}
\end{Highlighting}
\end{Shaded}

R

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{library}\NormalTok{(ElemStatLearn)}
\NormalTok{set }\OtherTok{=}\NormalTok{ training\_set}
\NormalTok{X1 }\OtherTok{=} \FunctionTok{seq}\NormalTok{(}\FunctionTok{min}\NormalTok{(set[, }\DecValTok{1}\NormalTok{]) }\SpecialCharTok{{-}} \DecValTok{1}\NormalTok{, }\FunctionTok{max}\NormalTok{(set[, }\DecValTok{1}\NormalTok{]) }\SpecialCharTok{+} \DecValTok{1}\NormalTok{, }\AttributeTok{by =} \FloatTok{0.01}\NormalTok{)}
\NormalTok{X2 }\OtherTok{=} \FunctionTok{seq}\NormalTok{(}\FunctionTok{min}\NormalTok{(set[, }\DecValTok{2}\NormalTok{]) }\SpecialCharTok{{-}} \DecValTok{1}\NormalTok{, }\FunctionTok{max}\NormalTok{(set[, }\DecValTok{2}\NormalTok{]) }\SpecialCharTok{+} \DecValTok{1}\NormalTok{, }\AttributeTok{by =} \FloatTok{0.01}\NormalTok{)}
\NormalTok{grid\_set }\OtherTok{=} \FunctionTok{expand.grid}\NormalTok{(X1, X2)}
\FunctionTok{colnames}\NormalTok{(grid\_set) }\OtherTok{=} \FunctionTok{c}\NormalTok{(}\StringTok{\textquotesingle{}Age\textquotesingle{}}\NormalTok{, }\StringTok{\textquotesingle{}EstimatedSalary\textquotesingle{}}\NormalTok{)}
\NormalTok{y\_grid }\OtherTok{=} \FunctionTok{predict}\NormalTok{(classifier, }\AttributeTok{newdata =}\NormalTok{ grid\_set)}
\FunctionTok{plot}\NormalTok{(set[, }\SpecialCharTok{{-}}\DecValTok{3}\NormalTok{],}
     \AttributeTok{main =} \StringTok{\textquotesingle{}SVM (Training set)\textquotesingle{}}\NormalTok{,}
     \AttributeTok{xlab =} \StringTok{\textquotesingle{}Age\textquotesingle{}}\NormalTok{, }\AttributeTok{ylab =} \StringTok{\textquotesingle{}Estimated Salary\textquotesingle{}}\NormalTok{,}
     \AttributeTok{xlim =} \FunctionTok{range}\NormalTok{(X1), }\AttributeTok{ylim =} \FunctionTok{range}\NormalTok{(X2))}
\FunctionTok{contour}\NormalTok{(X1, X2, }\FunctionTok{matrix}\NormalTok{(}\FunctionTok{as.numeric}\NormalTok{(y\_grid), }\FunctionTok{length}\NormalTok{(X1), }\FunctionTok{length}\NormalTok{(X2)), }\AttributeTok{add =} \ConstantTok{TRUE}\NormalTok{)}
\FunctionTok{points}\NormalTok{(grid\_set, }\AttributeTok{pch =} \StringTok{\textquotesingle{}.\textquotesingle{}}\NormalTok{, }\AttributeTok{col =} \FunctionTok{ifelse}\NormalTok{(y\_grid }\SpecialCharTok{==} \DecValTok{1}\NormalTok{, }\StringTok{\textquotesingle{}springgreen3\textquotesingle{}}\NormalTok{, }\StringTok{\textquotesingle{}tomato\textquotesingle{}}\NormalTok{))}
\FunctionTok{points}\NormalTok{(set, }\AttributeTok{pch =} \DecValTok{21}\NormalTok{, }\AttributeTok{bg =} \FunctionTok{ifelse}\NormalTok{(set[, }\DecValTok{3}\NormalTok{] }\SpecialCharTok{==} \DecValTok{1}\NormalTok{, }\StringTok{\textquotesingle{}green4\textquotesingle{}}\NormalTok{, }\StringTok{\textquotesingle{}red3\textquotesingle{}}\NormalTok{))}
\end{Highlighting}
\end{Shaded}

\includegraphics{_main_files/figure-latex/unnamed-chunk-138-1.pdf}

\hypertarget{visualising-the-test-set-results-3}{%
\subsection{Visualising the Test set results}\label{visualising-the-test-set-results-3}}

Python

\begin{Shaded}
\begin{Highlighting}[]
\ImportTok{from}\NormalTok{ matplotlib.colors }\ImportTok{import}\NormalTok{ ListedColormap}
\NormalTok{X\_set, y\_set }\OperatorTok{=}\NormalTok{ sc.inverse\_transform(X\_test), y\_test}
\NormalTok{X1, X2 }\OperatorTok{=}\NormalTok{ np.meshgrid(np.arange(start }\OperatorTok{=}\NormalTok{ X\_set[:, }\DecValTok{0}\NormalTok{].}\BuiltInTok{min}\NormalTok{() }\OperatorTok{{-}} \DecValTok{10}\NormalTok{, stop }\OperatorTok{=}\NormalTok{ X\_set[:, }\DecValTok{0}\NormalTok{].}\BuiltInTok{max}\NormalTok{() }\OperatorTok{+} \DecValTok{10}\NormalTok{, step }\OperatorTok{=} \FloatTok{0.25}\NormalTok{),}
\NormalTok{                     np.arange(start }\OperatorTok{=}\NormalTok{ X\_set[:, }\DecValTok{1}\NormalTok{].}\BuiltInTok{min}\NormalTok{() }\OperatorTok{{-}} \DecValTok{1000}\NormalTok{, stop }\OperatorTok{=}\NormalTok{ X\_set[:, }\DecValTok{1}\NormalTok{].}\BuiltInTok{max}\NormalTok{() }\OperatorTok{+} \DecValTok{1000}\NormalTok{, step }\OperatorTok{=} \FloatTok{0.25}\NormalTok{))}
\NormalTok{plt.contourf(X1, X2, classifier.predict(sc.transform(np.array([X1.ravel(), X2.ravel()]).T)).reshape(X1.shape),}
\NormalTok{             alpha }\OperatorTok{=} \FloatTok{0.75}\NormalTok{, cmap }\OperatorTok{=}\NormalTok{ ListedColormap((}\StringTok{\textquotesingle{}red\textquotesingle{}}\NormalTok{, }\StringTok{\textquotesingle{}green\textquotesingle{}}\NormalTok{)))}
\NormalTok{plt.xlim(X1.}\BuiltInTok{min}\NormalTok{(), X1.}\BuiltInTok{max}\NormalTok{())}
\NormalTok{plt.ylim(X2.}\BuiltInTok{min}\NormalTok{(), X2.}\BuiltInTok{max}\NormalTok{())}
\ControlFlowTok{for}\NormalTok{ i, j }\KeywordTok{in} \BuiltInTok{enumerate}\NormalTok{(np.unique(y\_set)):}
\NormalTok{    plt.scatter(X\_set[y\_set }\OperatorTok{==}\NormalTok{ j, }\DecValTok{0}\NormalTok{], X\_set[y\_set }\OperatorTok{==}\NormalTok{ j, }\DecValTok{1}\NormalTok{], c }\OperatorTok{=}\NormalTok{ ListedColormap((}\StringTok{\textquotesingle{}red\textquotesingle{}}\NormalTok{, }\StringTok{\textquotesingle{}green\textquotesingle{}}\NormalTok{))(i), label }\OperatorTok{=}\NormalTok{ j)}
\NormalTok{plt.title(}\StringTok{\textquotesingle{}SVM (Test set)\textquotesingle{}}\NormalTok{)}
\NormalTok{plt.xlabel(}\StringTok{\textquotesingle{}Age\textquotesingle{}}\NormalTok{)}
\NormalTok{plt.ylabel(}\StringTok{\textquotesingle{}Estimated Salary\textquotesingle{}}\NormalTok{)}
\NormalTok{plt.legend()}
\NormalTok{plt.show()}
\end{Highlighting}
\end{Shaded}

R

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{library}\NormalTok{(ElemStatLearn)}
\NormalTok{set }\OtherTok{=}\NormalTok{ test\_set}
\NormalTok{X1 }\OtherTok{=} \FunctionTok{seq}\NormalTok{(}\FunctionTok{min}\NormalTok{(set[, }\DecValTok{1}\NormalTok{]) }\SpecialCharTok{{-}} \DecValTok{1}\NormalTok{, }\FunctionTok{max}\NormalTok{(set[, }\DecValTok{1}\NormalTok{]) }\SpecialCharTok{+} \DecValTok{1}\NormalTok{, }\AttributeTok{by =} \FloatTok{0.01}\NormalTok{)}
\NormalTok{X2 }\OtherTok{=} \FunctionTok{seq}\NormalTok{(}\FunctionTok{min}\NormalTok{(set[, }\DecValTok{2}\NormalTok{]) }\SpecialCharTok{{-}} \DecValTok{1}\NormalTok{, }\FunctionTok{max}\NormalTok{(set[, }\DecValTok{2}\NormalTok{]) }\SpecialCharTok{+} \DecValTok{1}\NormalTok{, }\AttributeTok{by =} \FloatTok{0.01}\NormalTok{)}
\NormalTok{grid\_set }\OtherTok{=} \FunctionTok{expand.grid}\NormalTok{(X1, X2)}
\FunctionTok{colnames}\NormalTok{(grid\_set) }\OtherTok{=} \FunctionTok{c}\NormalTok{(}\StringTok{\textquotesingle{}Age\textquotesingle{}}\NormalTok{, }\StringTok{\textquotesingle{}EstimatedSalary\textquotesingle{}}\NormalTok{)}
\NormalTok{y\_grid }\OtherTok{=} \FunctionTok{predict}\NormalTok{(classifier, }\AttributeTok{newdata =}\NormalTok{ grid\_set)}
\FunctionTok{plot}\NormalTok{(set[, }\SpecialCharTok{{-}}\DecValTok{3}\NormalTok{], }\AttributeTok{main =} \StringTok{\textquotesingle{}SVM (Test set)\textquotesingle{}}\NormalTok{,}
     \AttributeTok{xlab =} \StringTok{\textquotesingle{}Age\textquotesingle{}}\NormalTok{, }\AttributeTok{ylab =} \StringTok{\textquotesingle{}Estimated Salary\textquotesingle{}}\NormalTok{,}
     \AttributeTok{xlim =} \FunctionTok{range}\NormalTok{(X1), }\AttributeTok{ylim =} \FunctionTok{range}\NormalTok{(X2))}
\FunctionTok{contour}\NormalTok{(X1, X2, }\FunctionTok{matrix}\NormalTok{(}\FunctionTok{as.numeric}\NormalTok{(y\_grid), }\FunctionTok{length}\NormalTok{(X1), }\FunctionTok{length}\NormalTok{(X2)), }\AttributeTok{add =} \ConstantTok{TRUE}\NormalTok{)}
\FunctionTok{points}\NormalTok{(grid\_set, }\AttributeTok{pch =} \StringTok{\textquotesingle{}.\textquotesingle{}}\NormalTok{, }\AttributeTok{col =} \FunctionTok{ifelse}\NormalTok{(y\_grid }\SpecialCharTok{==} \DecValTok{1}\NormalTok{, }\StringTok{\textquotesingle{}springgreen3\textquotesingle{}}\NormalTok{, }\StringTok{\textquotesingle{}tomato\textquotesingle{}}\NormalTok{))}
\FunctionTok{points}\NormalTok{(set, }\AttributeTok{pch =} \DecValTok{21}\NormalTok{, }\AttributeTok{bg =} \FunctionTok{ifelse}\NormalTok{(set[, }\DecValTok{3}\NormalTok{] }\SpecialCharTok{==} \DecValTok{1}\NormalTok{, }\StringTok{\textquotesingle{}green4\textquotesingle{}}\NormalTok{, }\StringTok{\textquotesingle{}red3\textquotesingle{}}\NormalTok{))}
\end{Highlighting}
\end{Shaded}

\includegraphics{_main_files/figure-latex/unnamed-chunk-140-1.pdf}

\hypertarget{kernel-svm}{%
\section{Kernel SVM}\label{kernel-svm}}

\hypertarget{importing-the-libraries-10}{%
\subsection{Importing the libraries}\label{importing-the-libraries-10}}

Python

\begin{Shaded}
\begin{Highlighting}[]
\ImportTok{import}\NormalTok{ numpy }\ImportTok{as}\NormalTok{ np}
\ImportTok{import}\NormalTok{ matplotlib.pyplot }\ImportTok{as}\NormalTok{ plt}
\ImportTok{import}\NormalTok{ pandas }\ImportTok{as}\NormalTok{ pd}
\end{Highlighting}
\end{Shaded}

\hypertarget{importing-the-dataset-10}{%
\subsection{Importing the dataset}\label{importing-the-dataset-10}}

Python

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{dataset }\OperatorTok{=}\NormalTok{ pd.read\_csv(}\StringTok{\textquotesingle{}Social\_Network\_Ads.csv\textquotesingle{}}\NormalTok{)}
\NormalTok{X }\OperatorTok{=}\NormalTok{ dataset.iloc[:, :}\OperatorTok{{-}}\DecValTok{1}\NormalTok{].values}
\NormalTok{y }\OperatorTok{=}\NormalTok{ dataset.iloc[:, }\OperatorTok{{-}}\DecValTok{1}\NormalTok{].values}
\end{Highlighting}
\end{Shaded}

R

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{dataset }\OtherTok{=} \FunctionTok{read.csv}\NormalTok{(}\StringTok{\textquotesingle{}Social\_Network\_Ads.csv\textquotesingle{}}\NormalTok{)}
\CommentTok{\# dataset = dataset[3:5]}
\end{Highlighting}
\end{Shaded}

\hypertarget{encoding-the-target-feature-as-factor-3}{%
\subsection{Encoding the target feature as factor}\label{encoding-the-target-feature-as-factor-3}}

R

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{dataset}\SpecialCharTok{$}\NormalTok{Purchased }\OtherTok{=} \FunctionTok{factor}\NormalTok{(dataset}\SpecialCharTok{$}\NormalTok{Purchased, }\AttributeTok{levels =} \FunctionTok{c}\NormalTok{(}\DecValTok{0}\NormalTok{, }\DecValTok{1}\NormalTok{))}
\end{Highlighting}
\end{Shaded}

\hypertarget{splitting-the-dataset-into-the-training-set-and-test-set-6}{%
\subsection{Splitting the dataset into the Training set and Test set}\label{splitting-the-dataset-into-the-training-set-and-test-set-6}}

Python

\begin{Shaded}
\begin{Highlighting}[]
\ImportTok{from}\NormalTok{ sklearn.model\_selection }\ImportTok{import}\NormalTok{ train\_test\_split}
\NormalTok{X\_train, X\_test, y\_train, y\_test }\OperatorTok{=}\NormalTok{ train\_test\_split(X, y, test\_size }\OperatorTok{=} \FloatTok{0.25}\NormalTok{, random\_state }\OperatorTok{=} \DecValTok{0}\NormalTok{)}
\BuiltInTok{print}\NormalTok{(X\_train)}
\CommentTok{\#\# [[    44  39000]}
\CommentTok{\#\#  [    32 120000]}
\CommentTok{\#\#  [    38  50000]}
\CommentTok{\#\#  [    32 135000]}
\CommentTok{\#\#  [    52  21000]}
\CommentTok{\#\#  [    53 104000]}
\CommentTok{\#\#  [    39  42000]}
\CommentTok{\#\#  [    38  61000]}
\CommentTok{\#\#  [    36  50000]}
\CommentTok{\#\#  [    36  63000]}
\CommentTok{\#\#  [    35  25000]}
\CommentTok{\#\#  [    35  50000]}
\CommentTok{\#\#  [    42  73000]}
\CommentTok{\#\#  [    47  49000]}
\CommentTok{\#\#  [    59  29000]}
\CommentTok{\#\#  [    49  65000]}
\CommentTok{\#\#  [    45 131000]}
\CommentTok{\#\#  [    31  89000]}
\CommentTok{\#\#  [    46  82000]}
\CommentTok{\#\#  [    47  51000]}
\CommentTok{\#\#  [    26  15000]}
\CommentTok{\#\#  [    60 102000]}
\CommentTok{\#\#  [    38 112000]}
\CommentTok{\#\#  [    40 107000]}
\CommentTok{\#\#  [    42  53000]}
\CommentTok{\#\#  [    35  59000]}
\CommentTok{\#\#  [    48  41000]}
\CommentTok{\#\#  [    48 134000]}
\CommentTok{\#\#  [    38 113000]}
\CommentTok{\#\#  [    29 148000]}
\CommentTok{\#\#  [    26  15000]}
\CommentTok{\#\#  [    60  42000]}
\CommentTok{\#\#  [    24  19000]}
\CommentTok{\#\#  [    42 149000]}
\CommentTok{\#\#  [    46  96000]}
\CommentTok{\#\#  [    28  59000]}
\CommentTok{\#\#  [    39  96000]}
\CommentTok{\#\#  [    28  89000]}
\CommentTok{\#\#  [    41  72000]}
\CommentTok{\#\#  [    45  26000]}
\CommentTok{\#\#  [    33  69000]}
\CommentTok{\#\#  [    20  82000]}
\CommentTok{\#\#  [    31  74000]}
\CommentTok{\#\#  [    42  80000]}
\CommentTok{\#\#  [    35  72000]}
\CommentTok{\#\#  [    33 149000]}
\CommentTok{\#\#  [    40  71000]}
\CommentTok{\#\#  [    51 146000]}
\CommentTok{\#\#  [    46  79000]}
\CommentTok{\#\#  [    35  75000]}
\CommentTok{\#\#  [    38  51000]}
\CommentTok{\#\#  [    36  75000]}
\CommentTok{\#\#  [    37  78000]}
\CommentTok{\#\#  [    38  61000]}
\CommentTok{\#\#  [    60 108000]}
\CommentTok{\#\#  [    20  82000]}
\CommentTok{\#\#  [    57  74000]}
\CommentTok{\#\#  [    42  65000]}
\CommentTok{\#\#  [    26  80000]}
\CommentTok{\#\#  [    46 117000]}
\CommentTok{\#\#  [    35  61000]}
\CommentTok{\#\#  [    21  68000]}
\CommentTok{\#\#  [    28  44000]}
\CommentTok{\#\#  [    41  87000]}
\CommentTok{\#\#  [    37  33000]}
\CommentTok{\#\#  [    27  90000]}
\CommentTok{\#\#  [    39  42000]}
\CommentTok{\#\#  [    28 123000]}
\CommentTok{\#\#  [    31 118000]}
\CommentTok{\#\#  [    25  87000]}
\CommentTok{\#\#  [    35  71000]}
\CommentTok{\#\#  [    37  70000]}
\CommentTok{\#\#  [    35  39000]}
\CommentTok{\#\#  [    47  23000]}
\CommentTok{\#\#  [    35 147000]}
\CommentTok{\#\#  [    48 138000]}
\CommentTok{\#\#  [    26  86000]}
\CommentTok{\#\#  [    25  79000]}
\CommentTok{\#\#  [    52 138000]}
\CommentTok{\#\#  [    51  23000]}
\CommentTok{\#\#  [    35  60000]}
\CommentTok{\#\#  [    33 113000]}
\CommentTok{\#\#  [    30 107000]}
\CommentTok{\#\#  [    48  33000]}
\CommentTok{\#\#  [    41  80000]}
\CommentTok{\#\#  [    48  96000]}
\CommentTok{\#\#  [    31  18000]}
\CommentTok{\#\#  [    31  71000]}
\CommentTok{\#\#  [    43 129000]}
\CommentTok{\#\#  [    59  76000]}
\CommentTok{\#\#  [    18  44000]}
\CommentTok{\#\#  [    36 118000]}
\CommentTok{\#\#  [    42  90000]}
\CommentTok{\#\#  [    47  30000]}
\CommentTok{\#\#  [    26  43000]}
\CommentTok{\#\#  [    40  78000]}
\CommentTok{\#\#  [    46  59000]}
\CommentTok{\#\#  [    59  42000]}
\CommentTok{\#\#  [    46  74000]}
\CommentTok{\#\#  [    35  91000]}
\CommentTok{\#\#  [    28  59000]}
\CommentTok{\#\#  [    40  57000]}
\CommentTok{\#\#  [    59 143000]}
\CommentTok{\#\#  [    57  26000]}
\CommentTok{\#\#  [    52  38000]}
\CommentTok{\#\#  [    47 113000]}
\CommentTok{\#\#  [    53 143000]}
\CommentTok{\#\#  [    35  27000]}
\CommentTok{\#\#  [    58 101000]}
\CommentTok{\#\#  [    45  45000]}
\CommentTok{\#\#  [    23  82000]}
\CommentTok{\#\#  [    46  23000]}
\CommentTok{\#\#  [    42  65000]}
\CommentTok{\#\#  [    28  84000]}
\CommentTok{\#\#  [    38  59000]}
\CommentTok{\#\#  [    26  84000]}
\CommentTok{\#\#  [    29  28000]}
\CommentTok{\#\#  [    37  71000]}
\CommentTok{\#\#  [    22  55000]}
\CommentTok{\#\#  [    48  35000]}
\CommentTok{\#\#  [    49  28000]}
\CommentTok{\#\#  [    38  65000]}
\CommentTok{\#\#  [    27  17000]}
\CommentTok{\#\#  [    46  28000]}
\CommentTok{\#\#  [    48 141000]}
\CommentTok{\#\#  [    26  17000]}
\CommentTok{\#\#  [    35  97000]}
\CommentTok{\#\#  [    39  59000]}
\CommentTok{\#\#  [    24  27000]}
\CommentTok{\#\#  [    32  18000]}
\CommentTok{\#\#  [    46  88000]}
\CommentTok{\#\#  [    35  58000]}
\CommentTok{\#\#  [    56  60000]}
\CommentTok{\#\#  [    47  34000]}
\CommentTok{\#\#  [    40  72000]}
\CommentTok{\#\#  [    32 100000]}
\CommentTok{\#\#  [    19  21000]}
\CommentTok{\#\#  [    25  90000]}
\CommentTok{\#\#  [    35  88000]}
\CommentTok{\#\#  [    28  32000]}
\CommentTok{\#\#  [    50  20000]}
\CommentTok{\#\#  [    40  59000]}
\CommentTok{\#\#  [    50  44000]}
\CommentTok{\#\#  [    35  72000]}
\CommentTok{\#\#  [    40 142000]}
\CommentTok{\#\#  [    46  32000]}
\CommentTok{\#\#  [    39  71000]}
\CommentTok{\#\#  [    20  74000]}
\CommentTok{\#\#  [    29  75000]}
\CommentTok{\#\#  [    31  76000]}
\CommentTok{\#\#  [    47  25000]}
\CommentTok{\#\#  [    40  61000]}
\CommentTok{\#\#  [    34 112000]}
\CommentTok{\#\#  [    38  80000]}
\CommentTok{\#\#  [    42  75000]}
\CommentTok{\#\#  [    47  47000]}
\CommentTok{\#\#  [    39  75000]}
\CommentTok{\#\#  [    19  25000]}
\CommentTok{\#\#  [    37  80000]}
\CommentTok{\#\#  [    36  60000]}
\CommentTok{\#\#  [    41  52000]}
\CommentTok{\#\#  [    36 125000]}
\CommentTok{\#\#  [    48  29000]}
\CommentTok{\#\#  [    36 126000]}
\CommentTok{\#\#  [    51 134000]}
\CommentTok{\#\#  [    27  57000]}
\CommentTok{\#\#  [    38  71000]}
\CommentTok{\#\#  [    39  61000]}
\CommentTok{\#\#  [    22  27000]}
\CommentTok{\#\#  [    33  60000]}
\CommentTok{\#\#  [    48  74000]}
\CommentTok{\#\#  [    58  23000]}
\CommentTok{\#\#  [    53  72000]}
\CommentTok{\#\#  [    32 117000]}
\CommentTok{\#\#  [    54  70000]}
\CommentTok{\#\#  [    30  80000]}
\CommentTok{\#\#  [    58  95000]}
\CommentTok{\#\#  [    26  52000]}
\CommentTok{\#\#  [    45  79000]}
\CommentTok{\#\#  [    24  55000]}
\CommentTok{\#\#  [    40  75000]}
\CommentTok{\#\#  [    33  28000]}
\CommentTok{\#\#  [    44 139000]}
\CommentTok{\#\#  [    22  18000]}
\CommentTok{\#\#  [    33  51000]}
\CommentTok{\#\#  [    43 133000]}
\CommentTok{\#\#  [    24  32000]}
\CommentTok{\#\#  [    46  22000]}
\CommentTok{\#\#  [    35  55000]}
\CommentTok{\#\#  [    54 104000]}
\CommentTok{\#\#  [    48 119000]}
\CommentTok{\#\#  [    35  53000]}
\CommentTok{\#\#  [    37 144000]}
\CommentTok{\#\#  [    23  66000]}
\CommentTok{\#\#  [    37 137000]}
\CommentTok{\#\#  [    31  58000]}
\CommentTok{\#\#  [    33  41000]}
\CommentTok{\#\#  [    45  22000]}
\CommentTok{\#\#  [    30  15000]}
\CommentTok{\#\#  [    19  19000]}
\CommentTok{\#\#  [    49  74000]}
\CommentTok{\#\#  [    39 122000]}
\CommentTok{\#\#  [    35  73000]}
\CommentTok{\#\#  [    39  71000]}
\CommentTok{\#\#  [    24  23000]}
\CommentTok{\#\#  [    41  72000]}
\CommentTok{\#\#  [    29  83000]}
\CommentTok{\#\#  [    54  26000]}
\CommentTok{\#\#  [    35  44000]}
\CommentTok{\#\#  [    37  75000]}
\CommentTok{\#\#  [    29  47000]}
\CommentTok{\#\#  [    31  68000]}
\CommentTok{\#\#  [    42  54000]}
\CommentTok{\#\#  [    30 135000]}
\CommentTok{\#\#  [    52 114000]}
\CommentTok{\#\#  [    50  36000]}
\CommentTok{\#\#  [    56 133000]}
\CommentTok{\#\#  [    29  61000]}
\CommentTok{\#\#  [    30  89000]}
\CommentTok{\#\#  [    26  16000]}
\CommentTok{\#\#  [    33  31000]}
\CommentTok{\#\#  [    41  72000]}
\CommentTok{\#\#  [    36  33000]}
\CommentTok{\#\#  [    55 125000]}
\CommentTok{\#\#  [    48 131000]}
\CommentTok{\#\#  [    41  71000]}
\CommentTok{\#\#  [    30  62000]}
\CommentTok{\#\#  [    37  72000]}
\CommentTok{\#\#  [    41  63000]}
\CommentTok{\#\#  [    58  47000]}
\CommentTok{\#\#  [    30 116000]}
\CommentTok{\#\#  [    20  49000]}
\CommentTok{\#\#  [    37  74000]}
\CommentTok{\#\#  [    41  59000]}
\CommentTok{\#\#  [    49  89000]}
\CommentTok{\#\#  [    28  79000]}
\CommentTok{\#\#  [    53  82000]}
\CommentTok{\#\#  [    40  57000]}
\CommentTok{\#\#  [    60  34000]}
\CommentTok{\#\#  [    35 108000]}
\CommentTok{\#\#  [    21  72000]}
\CommentTok{\#\#  [    38  71000]}
\CommentTok{\#\#  [    39 106000]}
\CommentTok{\#\#  [    37  57000]}
\CommentTok{\#\#  [    26  72000]}
\CommentTok{\#\#  [    35  23000]}
\CommentTok{\#\#  [    54 108000]}
\CommentTok{\#\#  [    30  17000]}
\CommentTok{\#\#  [    39 134000]}
\CommentTok{\#\#  [    29  43000]}
\CommentTok{\#\#  [    33  43000]}
\CommentTok{\#\#  [    35  38000]}
\CommentTok{\#\#  [    41  45000]}
\CommentTok{\#\#  [    41  72000]}
\CommentTok{\#\#  [    39 134000]}
\CommentTok{\#\#  [    27 137000]}
\CommentTok{\#\#  [    21  16000]}
\CommentTok{\#\#  [    26  32000]}
\CommentTok{\#\#  [    31  66000]}
\CommentTok{\#\#  [    39  73000]}
\CommentTok{\#\#  [    41  79000]}
\CommentTok{\#\#  [    47  50000]}
\CommentTok{\#\#  [    41  30000]}
\CommentTok{\#\#  [    37  93000]}
\CommentTok{\#\#  [    60  46000]}
\CommentTok{\#\#  [    25  22000]}
\CommentTok{\#\#  [    28  37000]}
\CommentTok{\#\#  [    38  55000]}
\CommentTok{\#\#  [    36  54000]}
\CommentTok{\#\#  [    20  36000]}
\CommentTok{\#\#  [    56 104000]}
\CommentTok{\#\#  [    40  57000]}
\CommentTok{\#\#  [    42 108000]}
\CommentTok{\#\#  [    20  23000]}
\CommentTok{\#\#  [    40  65000]}
\CommentTok{\#\#  [    47  20000]}
\CommentTok{\#\#  [    18  86000]}
\CommentTok{\#\#  [    35  79000]}
\CommentTok{\#\#  [    57  33000]}
\CommentTok{\#\#  [    34  72000]}
\CommentTok{\#\#  [    49  39000]}
\CommentTok{\#\#  [    27  31000]}
\CommentTok{\#\#  [    19  70000]}
\CommentTok{\#\#  [    39  79000]}
\CommentTok{\#\#  [    26  81000]}
\CommentTok{\#\#  [    25  80000]}
\CommentTok{\#\#  [    28  85000]}
\CommentTok{\#\#  [    55  39000]}
\CommentTok{\#\#  [    50  88000]}
\CommentTok{\#\#  [    49  88000]}
\CommentTok{\#\#  [    52 150000]}
\CommentTok{\#\#  [    35  65000]}
\CommentTok{\#\#  [    42  54000]}
\CommentTok{\#\#  [    34  43000]}
\CommentTok{\#\#  [    37  52000]}
\CommentTok{\#\#  [    48  30000]}
\CommentTok{\#\#  [    29  43000]}
\CommentTok{\#\#  [    36  52000]}
\CommentTok{\#\#  [    27  54000]}
\CommentTok{\#\#  [    26 118000]]}
\BuiltInTok{print}\NormalTok{(y\_train)}
\CommentTok{\#\# [0 1 0 1 1 1 0 0 0 0 0 0 1 1 1 0 1 0 0 1 0 1 0 1 0 0 1 1 1 1 0 1 0 1 0 0 1}
\CommentTok{\#\#  0 0 1 0 0 0 0 0 1 1 1 1 0 0 0 1 0 1 0 1 0 0 1 0 0 0 1 0 0 0 1 1 0 0 1 0 1}
\CommentTok{\#\#  1 1 0 0 1 1 0 0 1 1 0 1 0 0 1 1 0 1 1 1 0 0 0 0 0 1 0 0 1 1 1 1 1 0 1 1 0}
\CommentTok{\#\#  1 0 0 0 0 0 0 0 1 1 0 0 1 0 0 1 0 0 0 1 0 1 1 0 1 0 0 0 0 1 0 0 0 1 1 0 0}
\CommentTok{\#\#  0 0 1 0 1 0 0 0 1 0 0 0 0 1 1 1 0 0 0 0 0 0 1 1 1 1 1 0 1 0 0 0 0 0 1 0 0}
\CommentTok{\#\#  0 0 0 0 1 1 0 1 0 1 0 0 1 0 0 0 1 0 0 0 0 0 1 0 0 0 0 0 1 0 1 1 0 0 0 0 0}
\CommentTok{\#\#  0 1 1 0 0 0 0 1 0 0 0 0 1 0 1 0 1 0 0 0 1 0 0 0 1 0 1 0 0 0 0 0 1 1 0 0 0}
\CommentTok{\#\#  0 0 1 0 1 1 0 0 0 0 0 1 0 1 0 0 1 0 0 1 0 1 0 0 0 0 0 0 1 1 1 1 0 0 0 0 1}
\CommentTok{\#\#  0 0 0 0]}
\BuiltInTok{print}\NormalTok{(X\_test)}
\CommentTok{\#\# [[    30  87000]}
\CommentTok{\#\#  [    38  50000]}
\CommentTok{\#\#  [    35  75000]}
\CommentTok{\#\#  [    30  79000]}
\CommentTok{\#\#  [    35  50000]}
\CommentTok{\#\#  [    27  20000]}
\CommentTok{\#\#  [    31  15000]}
\CommentTok{\#\#  [    36 144000]}
\CommentTok{\#\#  [    18  68000]}
\CommentTok{\#\#  [    47  43000]}
\CommentTok{\#\#  [    30  49000]}
\CommentTok{\#\#  [    28  55000]}
\CommentTok{\#\#  [    37  55000]}
\CommentTok{\#\#  [    39  77000]}
\CommentTok{\#\#  [    20  86000]}
\CommentTok{\#\#  [    32 117000]}
\CommentTok{\#\#  [    37  77000]}
\CommentTok{\#\#  [    19  85000]}
\CommentTok{\#\#  [    55 130000]}
\CommentTok{\#\#  [    35  22000]}
\CommentTok{\#\#  [    35  47000]}
\CommentTok{\#\#  [    47 144000]}
\CommentTok{\#\#  [    41  51000]}
\CommentTok{\#\#  [    47 105000]}
\CommentTok{\#\#  [    23  28000]}
\CommentTok{\#\#  [    49 141000]}
\CommentTok{\#\#  [    28  87000]}
\CommentTok{\#\#  [    29  80000]}
\CommentTok{\#\#  [    37  62000]}
\CommentTok{\#\#  [    32  86000]}
\CommentTok{\#\#  [    21  88000]}
\CommentTok{\#\#  [    37  79000]}
\CommentTok{\#\#  [    57  60000]}
\CommentTok{\#\#  [    37  53000]}
\CommentTok{\#\#  [    24  58000]}
\CommentTok{\#\#  [    18  52000]}
\CommentTok{\#\#  [    22  81000]}
\CommentTok{\#\#  [    34  43000]}
\CommentTok{\#\#  [    31  34000]}
\CommentTok{\#\#  [    49  36000]}
\CommentTok{\#\#  [    27  88000]}
\CommentTok{\#\#  [    41  52000]}
\CommentTok{\#\#  [    27  84000]}
\CommentTok{\#\#  [    35  20000]}
\CommentTok{\#\#  [    43 112000]}
\CommentTok{\#\#  [    27  58000]}
\CommentTok{\#\#  [    37  80000]}
\CommentTok{\#\#  [    52  90000]}
\CommentTok{\#\#  [    26  30000]}
\CommentTok{\#\#  [    49  86000]}
\CommentTok{\#\#  [    57 122000]}
\CommentTok{\#\#  [    34  25000]}
\CommentTok{\#\#  [    35  57000]}
\CommentTok{\#\#  [    34 115000]}
\CommentTok{\#\#  [    59  88000]}
\CommentTok{\#\#  [    45  32000]}
\CommentTok{\#\#  [    29  83000]}
\CommentTok{\#\#  [    26  80000]}
\CommentTok{\#\#  [    49  28000]}
\CommentTok{\#\#  [    23  20000]}
\CommentTok{\#\#  [    32  18000]}
\CommentTok{\#\#  [    60  42000]}
\CommentTok{\#\#  [    19  76000]}
\CommentTok{\#\#  [    36  99000]}
\CommentTok{\#\#  [    19  26000]}
\CommentTok{\#\#  [    60  83000]}
\CommentTok{\#\#  [    24  89000]}
\CommentTok{\#\#  [    27  58000]}
\CommentTok{\#\#  [    40  47000]}
\CommentTok{\#\#  [    42  70000]}
\CommentTok{\#\#  [    32 150000]}
\CommentTok{\#\#  [    35  77000]}
\CommentTok{\#\#  [    22  63000]}
\CommentTok{\#\#  [    45  22000]}
\CommentTok{\#\#  [    27  89000]}
\CommentTok{\#\#  [    18  82000]}
\CommentTok{\#\#  [    42  79000]}
\CommentTok{\#\#  [    40  60000]}
\CommentTok{\#\#  [    53  34000]}
\CommentTok{\#\#  [    47 107000]}
\CommentTok{\#\#  [    58 144000]}
\CommentTok{\#\#  [    59  83000]}
\CommentTok{\#\#  [    24  55000]}
\CommentTok{\#\#  [    26  35000]}
\CommentTok{\#\#  [    58  38000]}
\CommentTok{\#\#  [    42  80000]}
\CommentTok{\#\#  [    40  75000]}
\CommentTok{\#\#  [    59 130000]}
\CommentTok{\#\#  [    46  41000]}
\CommentTok{\#\#  [    41  60000]}
\CommentTok{\#\#  [    42  64000]}
\CommentTok{\#\#  [    37 146000]}
\CommentTok{\#\#  [    23  48000]}
\CommentTok{\#\#  [    25  33000]}
\CommentTok{\#\#  [    24  84000]}
\CommentTok{\#\#  [    27  96000]}
\CommentTok{\#\#  [    23  63000]}
\CommentTok{\#\#  [    48  33000]}
\CommentTok{\#\#  [    48  90000]}
\CommentTok{\#\#  [    42 104000]]}
\BuiltInTok{print}\NormalTok{(y\_test)}
\CommentTok{\#\# [0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 1 0 0 1 0 1 0 1 0 0 0 0 0 1 1 0 0 0 0}
\CommentTok{\#\#  0 0 1 0 0 0 0 1 0 0 1 0 1 1 0 0 0 1 1 0 0 1 0 0 1 0 1 0 1 0 0 0 0 1 0 0 1}
\CommentTok{\#\#  0 0 0 0 1 1 1 0 0 0 1 1 0 1 1 0 0 1 0 0 0 1 0 1 1 1]}
\end{Highlighting}
\end{Shaded}

R

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\# install.packages(\textquotesingle{}caTools\textquotesingle{})}
\FunctionTok{library}\NormalTok{(caTools)}
\FunctionTok{set.seed}\NormalTok{(}\DecValTok{123}\NormalTok{)}
\NormalTok{split }\OtherTok{=} \FunctionTok{sample.split}\NormalTok{(dataset}\SpecialCharTok{$}\NormalTok{Purchased, }\AttributeTok{SplitRatio =} \FloatTok{0.75}\NormalTok{)}
\NormalTok{training\_set }\OtherTok{=} \FunctionTok{subset}\NormalTok{(dataset, split }\SpecialCharTok{==} \ConstantTok{TRUE}\NormalTok{)}
\NormalTok{test\_set }\OtherTok{=} \FunctionTok{subset}\NormalTok{(dataset, split }\SpecialCharTok{==} \ConstantTok{FALSE}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\hypertarget{feature-scaling-5}{%
\subsection{Feature Scaling}\label{feature-scaling-5}}

Python

\begin{Shaded}
\begin{Highlighting}[]
\ImportTok{from}\NormalTok{ sklearn.preprocessing }\ImportTok{import}\NormalTok{ StandardScaler}
\NormalTok{sc }\OperatorTok{=}\NormalTok{ StandardScaler()}
\NormalTok{X\_train }\OperatorTok{=}\NormalTok{ sc.fit\_transform(X\_train)}
\NormalTok{X\_test }\OperatorTok{=}\NormalTok{ sc.transform(X\_test)}
\BuiltInTok{print}\NormalTok{(X\_train)}
\CommentTok{\#\# [[ 0.58 {-}0.89]}
\CommentTok{\#\#  [{-}0.61  1.46]}
\CommentTok{\#\#  [{-}0.01 {-}0.57]}
\CommentTok{\#\#  [{-}0.61  1.9 ]}
\CommentTok{\#\#  [ 1.37 {-}1.41]}
\CommentTok{\#\#  [ 1.47  1.  ]}
\CommentTok{\#\#  [ 0.09 {-}0.8 ]}
\CommentTok{\#\#  [{-}0.01 {-}0.25]}
\CommentTok{\#\#  [{-}0.21 {-}0.57]}
\CommentTok{\#\#  [{-}0.21 {-}0.19]}
\CommentTok{\#\#  [{-}0.31 {-}1.29]}
\CommentTok{\#\#  [{-}0.31 {-}0.57]}
\CommentTok{\#\#  [ 0.38  0.1 ]}
\CommentTok{\#\#  [ 0.88 {-}0.6 ]}
\CommentTok{\#\#  [ 2.07 {-}1.18]}
\CommentTok{\#\#  [ 1.08 {-}0.13]}
\CommentTok{\#\#  [ 0.68  1.78]}
\CommentTok{\#\#  [{-}0.71  0.56]}
\CommentTok{\#\#  [ 0.78  0.36]}
\CommentTok{\#\#  [ 0.88 {-}0.54]}
\CommentTok{\#\#  [{-}1.2  {-}1.58]}
\CommentTok{\#\#  [ 2.17  0.94]}
\CommentTok{\#\#  [{-}0.01  1.23]}
\CommentTok{\#\#  [ 0.19  1.08]}
\CommentTok{\#\#  [ 0.38 {-}0.48]}
\CommentTok{\#\#  [{-}0.31 {-}0.31]}
\CommentTok{\#\#  [ 0.98 {-}0.83]}
\CommentTok{\#\#  [ 0.98  1.87]}
\CommentTok{\#\#  [{-}0.01  1.26]}
\CommentTok{\#\#  [{-}0.9   2.27]}
\CommentTok{\#\#  [{-}1.2  {-}1.58]}
\CommentTok{\#\#  [ 2.17 {-}0.8 ]}
\CommentTok{\#\#  [{-}1.4  {-}1.47]}
\CommentTok{\#\#  [ 0.38  2.3 ]}
\CommentTok{\#\#  [ 0.78  0.77]}
\CommentTok{\#\#  [{-}1.   {-}0.31]}
\CommentTok{\#\#  [ 0.09  0.77]}
\CommentTok{\#\#  [{-}1.    0.56]}
\CommentTok{\#\#  [ 0.28  0.07]}
\CommentTok{\#\#  [ 0.68 {-}1.26]}
\CommentTok{\#\#  [{-}0.51 {-}0.02]}
\CommentTok{\#\#  [{-}1.8   0.36]}
\CommentTok{\#\#  [{-}0.71  0.13]}
\CommentTok{\#\#  [ 0.38  0.3 ]}
\CommentTok{\#\#  [{-}0.31  0.07]}
\CommentTok{\#\#  [{-}0.51  2.3 ]}
\CommentTok{\#\#  [ 0.19  0.04]}
\CommentTok{\#\#  [ 1.27  2.22]}
\CommentTok{\#\#  [ 0.78  0.27]}
\CommentTok{\#\#  [{-}0.31  0.16]}
\CommentTok{\#\#  [{-}0.01 {-}0.54]}
\CommentTok{\#\#  [{-}0.21  0.16]}
\CommentTok{\#\#  [{-}0.11  0.24]}
\CommentTok{\#\#  [{-}0.01 {-}0.25]}
\CommentTok{\#\#  [ 2.17  1.11]}
\CommentTok{\#\#  [{-}1.8   0.36]}
\CommentTok{\#\#  [ 1.87  0.13]}
\CommentTok{\#\#  [ 0.38 {-}0.13]}
\CommentTok{\#\#  [{-}1.2   0.3 ]}
\CommentTok{\#\#  [ 0.78  1.37]}
\CommentTok{\#\#  [{-}0.31 {-}0.25]}
\CommentTok{\#\#  [{-}1.7  {-}0.05]}
\CommentTok{\#\#  [{-}1.   {-}0.74]}
\CommentTok{\#\#  [ 0.28  0.5 ]}
\CommentTok{\#\#  [{-}0.11 {-}1.06]}
\CommentTok{\#\#  [{-}1.1   0.59]}
\CommentTok{\#\#  [ 0.09 {-}0.8 ]}
\CommentTok{\#\#  [{-}1.    1.55]}
\CommentTok{\#\#  [{-}0.71  1.4 ]}
\CommentTok{\#\#  [{-}1.3   0.5 ]}
\CommentTok{\#\#  [{-}0.31  0.04]}
\CommentTok{\#\#  [{-}0.11  0.01]}
\CommentTok{\#\#  [{-}0.31 {-}0.89]}
\CommentTok{\#\#  [ 0.88 {-}1.35]}
\CommentTok{\#\#  [{-}0.31  2.24]}
\CommentTok{\#\#  [ 0.98  1.98]}
\CommentTok{\#\#  [{-}1.2   0.48]}
\CommentTok{\#\#  [{-}1.3   0.27]}
\CommentTok{\#\#  [ 1.37  1.98]}
\CommentTok{\#\#  [ 1.27 {-}1.35]}
\CommentTok{\#\#  [{-}0.31 {-}0.28]}
\CommentTok{\#\#  [{-}0.51  1.26]}
\CommentTok{\#\#  [{-}0.8   1.08]}
\CommentTok{\#\#  [ 0.98 {-}1.06]}
\CommentTok{\#\#  [ 0.28  0.3 ]}
\CommentTok{\#\#  [ 0.98  0.77]}
\CommentTok{\#\#  [{-}0.71 {-}1.5 ]}
\CommentTok{\#\#  [{-}0.71  0.04]}
\CommentTok{\#\#  [ 0.48  1.72]}
\CommentTok{\#\#  [ 2.07  0.19]}
\CommentTok{\#\#  [{-}1.99 {-}0.74]}
\CommentTok{\#\#  [{-}0.21  1.4 ]}
\CommentTok{\#\#  [ 0.38  0.59]}
\CommentTok{\#\#  [ 0.88 {-}1.15]}
\CommentTok{\#\#  [{-}1.2  {-}0.77]}
\CommentTok{\#\#  [ 0.19  0.24]}
\CommentTok{\#\#  [ 0.78 {-}0.31]}
\CommentTok{\#\#  [ 2.07 {-}0.8 ]}
\CommentTok{\#\#  [ 0.78  0.13]}
\CommentTok{\#\#  [{-}0.31  0.62]}
\CommentTok{\#\#  [{-}1.   {-}0.31]}
\CommentTok{\#\#  [ 0.19 {-}0.36]}
\CommentTok{\#\#  [ 2.07  2.13]}
\CommentTok{\#\#  [ 1.87 {-}1.26]}
\CommentTok{\#\#  [ 1.37 {-}0.92]}
\CommentTok{\#\#  [ 0.88  1.26]}
\CommentTok{\#\#  [ 1.47  2.13]}
\CommentTok{\#\#  [{-}0.31 {-}1.23]}
\CommentTok{\#\#  [ 1.97  0.91]}
\CommentTok{\#\#  [ 0.68 {-}0.71]}
\CommentTok{\#\#  [{-}1.5   0.36]}
\CommentTok{\#\#  [ 0.78 {-}1.35]}
\CommentTok{\#\#  [ 0.38 {-}0.13]}
\CommentTok{\#\#  [{-}1.    0.42]}
\CommentTok{\#\#  [{-}0.01 {-}0.31]}
\CommentTok{\#\#  [{-}1.2   0.42]}
\CommentTok{\#\#  [{-}0.9  {-}1.21]}
\CommentTok{\#\#  [{-}0.11  0.04]}
\CommentTok{\#\#  [{-}1.6  {-}0.42]}
\CommentTok{\#\#  [ 0.98 {-}1.  ]}
\CommentTok{\#\#  [ 1.08 {-}1.21]}
\CommentTok{\#\#  [{-}0.01 {-}0.13]}
\CommentTok{\#\#  [{-}1.1  {-}1.52]}
\CommentTok{\#\#  [ 0.78 {-}1.21]}
\CommentTok{\#\#  [ 0.98  2.07]}
\CommentTok{\#\#  [{-}1.2  {-}1.52]}
\CommentTok{\#\#  [{-}0.31  0.79]}
\CommentTok{\#\#  [ 0.09 {-}0.31]}
\CommentTok{\#\#  [{-}1.4  {-}1.23]}
\CommentTok{\#\#  [{-}0.61 {-}1.5 ]}
\CommentTok{\#\#  [ 0.78  0.53]}
\CommentTok{\#\#  [{-}0.31 {-}0.34]}
\CommentTok{\#\#  [ 1.77 {-}0.28]}
\CommentTok{\#\#  [ 0.88 {-}1.03]}
\CommentTok{\#\#  [ 0.19  0.07]}
\CommentTok{\#\#  [{-}0.61  0.88]}
\CommentTok{\#\#  [{-}1.89 {-}1.41]}
\CommentTok{\#\#  [{-}1.3   0.59]}
\CommentTok{\#\#  [{-}0.31  0.53]}
\CommentTok{\#\#  [{-}1.   {-}1.09]}
\CommentTok{\#\#  [ 1.18 {-}1.44]}
\CommentTok{\#\#  [ 0.19 {-}0.31]}
\CommentTok{\#\#  [ 1.18 {-}0.74]}
\CommentTok{\#\#  [{-}0.31  0.07]}
\CommentTok{\#\#  [ 0.19  2.1 ]}
\CommentTok{\#\#  [ 0.78 {-}1.09]}
\CommentTok{\#\#  [ 0.09  0.04]}
\CommentTok{\#\#  [{-}1.8   0.13]}
\CommentTok{\#\#  [{-}0.9   0.16]}
\CommentTok{\#\#  [{-}0.71  0.19]}
\CommentTok{\#\#  [ 0.88 {-}1.29]}
\CommentTok{\#\#  [ 0.19 {-}0.25]}
\CommentTok{\#\#  [{-}0.41  1.23]}
\CommentTok{\#\#  [{-}0.01  0.3 ]}
\CommentTok{\#\#  [ 0.38  0.16]}
\CommentTok{\#\#  [ 0.88 {-}0.65]}
\CommentTok{\#\#  [ 0.09  0.16]}
\CommentTok{\#\#  [{-}1.89 {-}1.29]}
\CommentTok{\#\#  [{-}0.11  0.3 ]}
\CommentTok{\#\#  [{-}0.21 {-}0.28]}
\CommentTok{\#\#  [ 0.28 {-}0.51]}
\CommentTok{\#\#  [{-}0.21  1.61]}
\CommentTok{\#\#  [ 0.98 {-}1.18]}
\CommentTok{\#\#  [{-}0.21  1.64]}
\CommentTok{\#\#  [ 1.27  1.87]}
\CommentTok{\#\#  [{-}1.1  {-}0.36]}
\CommentTok{\#\#  [{-}0.01  0.04]}
\CommentTok{\#\#  [ 0.09 {-}0.25]}
\CommentTok{\#\#  [{-}1.6  {-}1.23]}
\CommentTok{\#\#  [{-}0.51 {-}0.28]}
\CommentTok{\#\#  [ 0.98  0.13]}
\CommentTok{\#\#  [ 1.97 {-}1.35]}
\CommentTok{\#\#  [ 1.47  0.07]}
\CommentTok{\#\#  [{-}0.61  1.37]}
\CommentTok{\#\#  [ 1.57  0.01]}
\CommentTok{\#\#  [{-}0.8   0.3 ]}
\CommentTok{\#\#  [ 1.97  0.74]}
\CommentTok{\#\#  [{-}1.2  {-}0.51]}
\CommentTok{\#\#  [ 0.68  0.27]}
\CommentTok{\#\#  [{-}1.4  {-}0.42]}
\CommentTok{\#\#  [ 0.19  0.16]}
\CommentTok{\#\#  [{-}0.51 {-}1.21]}
\CommentTok{\#\#  [ 0.58  2.01]}
\CommentTok{\#\#  [{-}1.6  {-}1.5 ]}
\CommentTok{\#\#  [{-}0.51 {-}0.54]}
\CommentTok{\#\#  [ 0.48  1.84]}
\CommentTok{\#\#  [{-}1.4  {-}1.09]}
\CommentTok{\#\#  [ 0.78 {-}1.38]}
\CommentTok{\#\#  [{-}0.31 {-}0.42]}
\CommentTok{\#\#  [ 1.57  1.  ]}
\CommentTok{\#\#  [ 0.98  1.43]}
\CommentTok{\#\#  [{-}0.31 {-}0.48]}
\CommentTok{\#\#  [{-}0.11  2.16]}
\CommentTok{\#\#  [{-}1.5  {-}0.1 ]}
\CommentTok{\#\#  [{-}0.11  1.95]}
\CommentTok{\#\#  [{-}0.71 {-}0.34]}
\CommentTok{\#\#  [{-}0.51 {-}0.83]}
\CommentTok{\#\#  [ 0.68 {-}1.38]}
\CommentTok{\#\#  [{-}0.8  {-}1.58]}
\CommentTok{\#\#  [{-}1.89 {-}1.47]}
\CommentTok{\#\#  [ 1.08  0.13]}
\CommentTok{\#\#  [ 0.09  1.52]}
\CommentTok{\#\#  [{-}0.31  0.1 ]}
\CommentTok{\#\#  [ 0.09  0.04]}
\CommentTok{\#\#  [{-}1.4  {-}1.35]}
\CommentTok{\#\#  [ 0.28  0.07]}
\CommentTok{\#\#  [{-}0.9   0.39]}
\CommentTok{\#\#  [ 1.57 {-}1.26]}
\CommentTok{\#\#  [{-}0.31 {-}0.74]}
\CommentTok{\#\#  [{-}0.11  0.16]}
\CommentTok{\#\#  [{-}0.9  {-}0.65]}
\CommentTok{\#\#  [{-}0.71 {-}0.05]}
\CommentTok{\#\#  [ 0.38 {-}0.45]}
\CommentTok{\#\#  [{-}0.8   1.9 ]}
\CommentTok{\#\#  [ 1.37  1.29]}
\CommentTok{\#\#  [ 1.18 {-}0.97]}
\CommentTok{\#\#  [ 1.77  1.84]}
\CommentTok{\#\#  [{-}0.9  {-}0.25]}
\CommentTok{\#\#  [{-}0.8   0.56]}
\CommentTok{\#\#  [{-}1.2  {-}1.55]}
\CommentTok{\#\#  [{-}0.51 {-}1.12]}
\CommentTok{\#\#  [ 0.28  0.07]}
\CommentTok{\#\#  [{-}0.21 {-}1.06]}
\CommentTok{\#\#  [ 1.67  1.61]}
\CommentTok{\#\#  [ 0.98  1.78]}
\CommentTok{\#\#  [ 0.28  0.04]}
\CommentTok{\#\#  [{-}0.8  {-}0.22]}
\CommentTok{\#\#  [{-}0.11  0.07]}
\CommentTok{\#\#  [ 0.28 {-}0.19]}
\CommentTok{\#\#  [ 1.97 {-}0.65]}
\CommentTok{\#\#  [{-}0.8   1.35]}
\CommentTok{\#\#  [{-}1.8  {-}0.6 ]}
\CommentTok{\#\#  [{-}0.11  0.13]}
\CommentTok{\#\#  [ 0.28 {-}0.31]}
\CommentTok{\#\#  [ 1.08  0.56]}
\CommentTok{\#\#  [{-}1.    0.27]}
\CommentTok{\#\#  [ 1.47  0.36]}
\CommentTok{\#\#  [ 0.19 {-}0.36]}
\CommentTok{\#\#  [ 2.17 {-}1.03]}
\CommentTok{\#\#  [{-}0.31  1.11]}
\CommentTok{\#\#  [{-}1.7   0.07]}
\CommentTok{\#\#  [{-}0.01  0.04]}
\CommentTok{\#\#  [ 0.09  1.06]}
\CommentTok{\#\#  [{-}0.11 {-}0.36]}
\CommentTok{\#\#  [{-}1.2   0.07]}
\CommentTok{\#\#  [{-}0.31 {-}1.35]}
\CommentTok{\#\#  [ 1.57  1.11]}
\CommentTok{\#\#  [{-}0.8  {-}1.52]}
\CommentTok{\#\#  [ 0.09  1.87]}
\CommentTok{\#\#  [{-}0.9  {-}0.77]}
\CommentTok{\#\#  [{-}0.51 {-}0.77]}
\CommentTok{\#\#  [{-}0.31 {-}0.92]}
\CommentTok{\#\#  [ 0.28 {-}0.71]}
\CommentTok{\#\#  [ 0.28  0.07]}
\CommentTok{\#\#  [ 0.09  1.87]}
\CommentTok{\#\#  [{-}1.1   1.95]}
\CommentTok{\#\#  [{-}1.7  {-}1.55]}
\CommentTok{\#\#  [{-}1.2  {-}1.09]}
\CommentTok{\#\#  [{-}0.71 {-}0.1 ]}
\CommentTok{\#\#  [ 0.09  0.1 ]}
\CommentTok{\#\#  [ 0.28  0.27]}
\CommentTok{\#\#  [ 0.88 {-}0.57]}
\CommentTok{\#\#  [ 0.28 {-}1.15]}
\CommentTok{\#\#  [{-}0.11  0.68]}
\CommentTok{\#\#  [ 2.17 {-}0.68]}
\CommentTok{\#\#  [{-}1.3  {-}1.38]}
\CommentTok{\#\#  [{-}1.   {-}0.94]}
\CommentTok{\#\#  [{-}0.01 {-}0.42]}
\CommentTok{\#\#  [{-}0.21 {-}0.45]}
\CommentTok{\#\#  [{-}1.8  {-}0.97]}
\CommentTok{\#\#  [ 1.77  1.  ]}
\CommentTok{\#\#  [ 0.19 {-}0.36]}
\CommentTok{\#\#  [ 0.38  1.11]}
\CommentTok{\#\#  [{-}1.8  {-}1.35]}
\CommentTok{\#\#  [ 0.19 {-}0.13]}
\CommentTok{\#\#  [ 0.88 {-}1.44]}
\CommentTok{\#\#  [{-}1.99  0.48]}
\CommentTok{\#\#  [{-}0.31  0.27]}
\CommentTok{\#\#  [ 1.87 {-}1.06]}
\CommentTok{\#\#  [{-}0.41  0.07]}
\CommentTok{\#\#  [ 1.08 {-}0.89]}
\CommentTok{\#\#  [{-}1.1  {-}1.12]}
\CommentTok{\#\#  [{-}1.89  0.01]}
\CommentTok{\#\#  [ 0.09  0.27]}
\CommentTok{\#\#  [{-}1.2   0.33]}
\CommentTok{\#\#  [{-}1.3   0.3 ]}
\CommentTok{\#\#  [{-}1.    0.45]}
\CommentTok{\#\#  [ 1.67 {-}0.89]}
\CommentTok{\#\#  [ 1.18  0.53]}
\CommentTok{\#\#  [ 1.08  0.53]}
\CommentTok{\#\#  [ 1.37  2.33]}
\CommentTok{\#\#  [{-}0.31 {-}0.13]}
\CommentTok{\#\#  [ 0.38 {-}0.45]}
\CommentTok{\#\#  [{-}0.41 {-}0.77]}
\CommentTok{\#\#  [{-}0.11 {-}0.51]}
\CommentTok{\#\#  [ 0.98 {-}1.15]}
\CommentTok{\#\#  [{-}0.9  {-}0.77]}
\CommentTok{\#\#  [{-}0.21 {-}0.51]}
\CommentTok{\#\#  [{-}1.1  {-}0.45]}
\CommentTok{\#\#  [{-}1.2   1.4 ]]}
\BuiltInTok{print}\NormalTok{(X\_test)}
\CommentTok{\#\# [[{-}0.8   0.5 ]}
\CommentTok{\#\#  [{-}0.01 {-}0.57]}
\CommentTok{\#\#  [{-}0.31  0.16]}
\CommentTok{\#\#  [{-}0.8   0.27]}
\CommentTok{\#\#  [{-}0.31 {-}0.57]}
\CommentTok{\#\#  [{-}1.1  {-}1.44]}
\CommentTok{\#\#  [{-}0.71 {-}1.58]}
\CommentTok{\#\#  [{-}0.21  2.16]}
\CommentTok{\#\#  [{-}1.99 {-}0.05]}
\CommentTok{\#\#  [ 0.88 {-}0.77]}
\CommentTok{\#\#  [{-}0.8  {-}0.6 ]}
\CommentTok{\#\#  [{-}1.   {-}0.42]}
\CommentTok{\#\#  [{-}0.11 {-}0.42]}
\CommentTok{\#\#  [ 0.09  0.22]}
\CommentTok{\#\#  [{-}1.8   0.48]}
\CommentTok{\#\#  [{-}0.61  1.37]}
\CommentTok{\#\#  [{-}0.11  0.22]}
\CommentTok{\#\#  [{-}1.89  0.45]}
\CommentTok{\#\#  [ 1.67  1.75]}
\CommentTok{\#\#  [{-}0.31 {-}1.38]}
\CommentTok{\#\#  [{-}0.31 {-}0.65]}
\CommentTok{\#\#  [ 0.88  2.16]}
\CommentTok{\#\#  [ 0.28 {-}0.54]}
\CommentTok{\#\#  [ 0.88  1.03]}
\CommentTok{\#\#  [{-}1.5  {-}1.21]}
\CommentTok{\#\#  [ 1.08  2.07]}
\CommentTok{\#\#  [{-}1.    0.5 ]}
\CommentTok{\#\#  [{-}0.9   0.3 ]}
\CommentTok{\#\#  [{-}0.11 {-}0.22]}
\CommentTok{\#\#  [{-}0.61  0.48]}
\CommentTok{\#\#  [{-}1.7   0.53]}
\CommentTok{\#\#  [{-}0.11  0.27]}
\CommentTok{\#\#  [ 1.87 {-}0.28]}
\CommentTok{\#\#  [{-}0.11 {-}0.48]}
\CommentTok{\#\#  [{-}1.4  {-}0.34]}
\CommentTok{\#\#  [{-}1.99 {-}0.51]}
\CommentTok{\#\#  [{-}1.6   0.33]}
\CommentTok{\#\#  [{-}0.41 {-}0.77]}
\CommentTok{\#\#  [{-}0.71 {-}1.03]}
\CommentTok{\#\#  [ 1.08 {-}0.97]}
\CommentTok{\#\#  [{-}1.1   0.53]}
\CommentTok{\#\#  [ 0.28 {-}0.51]}
\CommentTok{\#\#  [{-}1.1   0.42]}
\CommentTok{\#\#  [{-}0.31 {-}1.44]}
\CommentTok{\#\#  [ 0.48  1.23]}
\CommentTok{\#\#  [{-}1.1  {-}0.34]}
\CommentTok{\#\#  [{-}0.11  0.3 ]}
\CommentTok{\#\#  [ 1.37  0.59]}
\CommentTok{\#\#  [{-}1.2  {-}1.15]}
\CommentTok{\#\#  [ 1.08  0.48]}
\CommentTok{\#\#  [ 1.87  1.52]}
\CommentTok{\#\#  [{-}0.41 {-}1.29]}
\CommentTok{\#\#  [{-}0.31 {-}0.36]}
\CommentTok{\#\#  [{-}0.41  1.32]}
\CommentTok{\#\#  [ 2.07  0.53]}
\CommentTok{\#\#  [ 0.68 {-}1.09]}
\CommentTok{\#\#  [{-}0.9   0.39]}
\CommentTok{\#\#  [{-}1.2   0.3 ]}
\CommentTok{\#\#  [ 1.08 {-}1.21]}
\CommentTok{\#\#  [{-}1.5  {-}1.44]}
\CommentTok{\#\#  [{-}0.61 {-}1.5 ]}
\CommentTok{\#\#  [ 2.17 {-}0.8 ]}
\CommentTok{\#\#  [{-}1.89  0.19]}
\CommentTok{\#\#  [{-}0.21  0.85]}
\CommentTok{\#\#  [{-}1.89 {-}1.26]}
\CommentTok{\#\#  [ 2.17  0.39]}
\CommentTok{\#\#  [{-}1.4   0.56]}
\CommentTok{\#\#  [{-}1.1  {-}0.34]}
\CommentTok{\#\#  [ 0.19 {-}0.65]}
\CommentTok{\#\#  [ 0.38  0.01]}
\CommentTok{\#\#  [{-}0.61  2.33]}
\CommentTok{\#\#  [{-}0.31  0.22]}
\CommentTok{\#\#  [{-}1.6  {-}0.19]}
\CommentTok{\#\#  [ 0.68 {-}1.38]}
\CommentTok{\#\#  [{-}1.1   0.56]}
\CommentTok{\#\#  [{-}1.99  0.36]}
\CommentTok{\#\#  [ 0.38  0.27]}
\CommentTok{\#\#  [ 0.19 {-}0.28]}
\CommentTok{\#\#  [ 1.47 {-}1.03]}
\CommentTok{\#\#  [ 0.88  1.08]}
\CommentTok{\#\#  [ 1.97  2.16]}
\CommentTok{\#\#  [ 2.07  0.39]}
\CommentTok{\#\#  [{-}1.4  {-}0.42]}
\CommentTok{\#\#  [{-}1.2  {-}1.  ]}
\CommentTok{\#\#  [ 1.97 {-}0.92]}
\CommentTok{\#\#  [ 0.38  0.3 ]}
\CommentTok{\#\#  [ 0.19  0.16]}
\CommentTok{\#\#  [ 2.07  1.75]}
\CommentTok{\#\#  [ 0.78 {-}0.83]}
\CommentTok{\#\#  [ 0.28 {-}0.28]}
\CommentTok{\#\#  [ 0.38 {-}0.16]}
\CommentTok{\#\#  [{-}0.11  2.22]}
\CommentTok{\#\#  [{-}1.5  {-}0.63]}
\CommentTok{\#\#  [{-}1.3  {-}1.06]}
\CommentTok{\#\#  [{-}1.4   0.42]}
\CommentTok{\#\#  [{-}1.1   0.77]}
\CommentTok{\#\#  [{-}1.5  {-}0.19]}
\CommentTok{\#\#  [ 0.98 {-}1.06]}
\CommentTok{\#\#  [ 0.98  0.59]}
\CommentTok{\#\#  [ 0.38  1.  ]]}
\end{Highlighting}
\end{Shaded}

R

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{training\_set[}\SpecialCharTok{{-}}\DecValTok{3}\NormalTok{] }\OtherTok{=} \FunctionTok{scale}\NormalTok{(training\_set[}\SpecialCharTok{{-}}\DecValTok{3}\NormalTok{])}
\NormalTok{test\_set[}\SpecialCharTok{{-}}\DecValTok{3}\NormalTok{] }\OtherTok{=} \FunctionTok{scale}\NormalTok{(test\_set[}\SpecialCharTok{{-}}\DecValTok{3}\NormalTok{])}
\end{Highlighting}
\end{Shaded}

\hypertarget{training-the-kernel-svm-model-on-the-training-set}{%
\subsection{Training the Kernel SVM model on the Training set}\label{training-the-kernel-svm-model-on-the-training-set}}

Python

\begin{Shaded}
\begin{Highlighting}[]
\ImportTok{from}\NormalTok{ sklearn.svm }\ImportTok{import}\NormalTok{ SVC}
\NormalTok{classifier }\OperatorTok{=}\NormalTok{ SVC(kernel }\OperatorTok{=} \StringTok{\textquotesingle{}rbf\textquotesingle{}}\NormalTok{, random\_state }\OperatorTok{=} \DecValTok{0}\NormalTok{)}
\NormalTok{classifier.fit(X\_train, y\_train)}
\CommentTok{\#\# SVC(random\_state=0)}
\end{Highlighting}
\end{Shaded}

R

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\# install.packages(\textquotesingle{}e1071\textquotesingle{})}
\FunctionTok{library}\NormalTok{(e1071)}
\NormalTok{classifier }\OtherTok{=} \FunctionTok{svm}\NormalTok{(}\AttributeTok{formula =}\NormalTok{ Purchased }\SpecialCharTok{\textasciitilde{}}\NormalTok{ .,}
                 \AttributeTok{data =}\NormalTok{ training\_set,}
                 \AttributeTok{type =} \StringTok{\textquotesingle{}C{-}classification\textquotesingle{}}\NormalTok{,}
                 \AttributeTok{kernel =} \StringTok{\textquotesingle{}radial\textquotesingle{}}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\hypertarget{predicting-a-new-result-6}{%
\subsection{Predicting a new result}\label{predicting-a-new-result-6}}

Python

\begin{Shaded}
\begin{Highlighting}[]
\BuiltInTok{print}\NormalTok{(classifier.predict(sc.transform([[}\DecValTok{30}\NormalTok{,}\DecValTok{87000}\NormalTok{]])))}
\CommentTok{\#\# [0]}
\end{Highlighting}
\end{Shaded}

\hypertarget{predicting-the-test-set-results-5}{%
\subsection{Predicting the Test set results}\label{predicting-the-test-set-results-5}}

Python

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{y\_pred }\OperatorTok{=}\NormalTok{ classifier.predict(X\_test)}
\BuiltInTok{print}\NormalTok{(np.concatenate((y\_pred.reshape(}\BuiltInTok{len}\NormalTok{(y\_pred),}\DecValTok{1}\NormalTok{), y\_test.reshape(}\BuiltInTok{len}\NormalTok{(y\_test),}\DecValTok{1}\NormalTok{)),}\DecValTok{1}\NormalTok{))}
\CommentTok{\#\# [[0 0]}
\CommentTok{\#\#  [0 0]}
\CommentTok{\#\#  [0 0]}
\CommentTok{\#\#  [0 0]}
\CommentTok{\#\#  [0 0]}
\CommentTok{\#\#  [0 0]}
\CommentTok{\#\#  [0 0]}
\CommentTok{\#\#  [1 1]}
\CommentTok{\#\#  [0 0]}
\CommentTok{\#\#  [1 0]}
\CommentTok{\#\#  [0 0]}
\CommentTok{\#\#  [0 0]}
\CommentTok{\#\#  [0 0]}
\CommentTok{\#\#  [0 0]}
\CommentTok{\#\#  [0 0]}
\CommentTok{\#\#  [1 0]}
\CommentTok{\#\#  [0 0]}
\CommentTok{\#\#  [0 0]}
\CommentTok{\#\#  [1 1]}
\CommentTok{\#\#  [0 0]}
\CommentTok{\#\#  [0 0]}
\CommentTok{\#\#  [1 1]}
\CommentTok{\#\#  [0 0]}
\CommentTok{\#\#  [1 1]}
\CommentTok{\#\#  [0 0]}
\CommentTok{\#\#  [1 1]}
\CommentTok{\#\#  [0 0]}
\CommentTok{\#\#  [0 0]}
\CommentTok{\#\#  [0 0]}
\CommentTok{\#\#  [0 0]}
\CommentTok{\#\#  [0 0]}
\CommentTok{\#\#  [0 1]}
\CommentTok{\#\#  [1 1]}
\CommentTok{\#\#  [0 0]}
\CommentTok{\#\#  [0 0]}
\CommentTok{\#\#  [0 0]}
\CommentTok{\#\#  [0 0]}
\CommentTok{\#\#  [0 0]}
\CommentTok{\#\#  [0 0]}
\CommentTok{\#\#  [1 1]}
\CommentTok{\#\#  [0 0]}
\CommentTok{\#\#  [0 0]}
\CommentTok{\#\#  [0 0]}
\CommentTok{\#\#  [0 0]}
\CommentTok{\#\#  [1 1]}
\CommentTok{\#\#  [0 0]}
\CommentTok{\#\#  [0 0]}
\CommentTok{\#\#  [1 1]}
\CommentTok{\#\#  [0 0]}
\CommentTok{\#\#  [1 1]}
\CommentTok{\#\#  [1 1]}
\CommentTok{\#\#  [0 0]}
\CommentTok{\#\#  [0 0]}
\CommentTok{\#\#  [1 0]}
\CommentTok{\#\#  [1 1]}
\CommentTok{\#\#  [1 1]}
\CommentTok{\#\#  [0 0]}
\CommentTok{\#\#  [0 0]}
\CommentTok{\#\#  [1 1]}
\CommentTok{\#\#  [0 0]}
\CommentTok{\#\#  [0 0]}
\CommentTok{\#\#  [1 1]}
\CommentTok{\#\#  [0 0]}
\CommentTok{\#\#  [1 1]}
\CommentTok{\#\#  [0 0]}
\CommentTok{\#\#  [1 1]}
\CommentTok{\#\#  [0 0]}
\CommentTok{\#\#  [0 0]}
\CommentTok{\#\#  [0 0]}
\CommentTok{\#\#  [0 0]}
\CommentTok{\#\#  [1 1]}
\CommentTok{\#\#  [0 0]}
\CommentTok{\#\#  [0 0]}
\CommentTok{\#\#  [1 1]}
\CommentTok{\#\#  [0 0]}
\CommentTok{\#\#  [0 0]}
\CommentTok{\#\#  [0 0]}
\CommentTok{\#\#  [0 0]}
\CommentTok{\#\#  [1 1]}
\CommentTok{\#\#  [1 1]}
\CommentTok{\#\#  [1 1]}
\CommentTok{\#\#  [1 0]}
\CommentTok{\#\#  [0 0]}
\CommentTok{\#\#  [0 0]}
\CommentTok{\#\#  [1 1]}
\CommentTok{\#\#  [0 1]}
\CommentTok{\#\#  [0 0]}
\CommentTok{\#\#  [1 1]}
\CommentTok{\#\#  [1 1]}
\CommentTok{\#\#  [0 0]}
\CommentTok{\#\#  [0 0]}
\CommentTok{\#\#  [1 1]}
\CommentTok{\#\#  [0 0]}
\CommentTok{\#\#  [0 0]}
\CommentTok{\#\#  [0 0]}
\CommentTok{\#\#  [0 1]}
\CommentTok{\#\#  [0 0]}
\CommentTok{\#\#  [1 1]}
\CommentTok{\#\#  [1 1]}
\CommentTok{\#\#  [1 1]]}
\end{Highlighting}
\end{Shaded}

R

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{y\_pred }\OtherTok{=} \FunctionTok{predict}\NormalTok{(classifier, }\AttributeTok{newdata =}\NormalTok{ test\_set[}\SpecialCharTok{{-}}\DecValTok{3}\NormalTok{])}
\end{Highlighting}
\end{Shaded}

\hypertarget{making-the-confusion-matrix-3}{%
\subsection{Making the Confusion Matrix}\label{making-the-confusion-matrix-3}}

Python

\begin{Shaded}
\begin{Highlighting}[]
\ImportTok{from}\NormalTok{ sklearn.metrics }\ImportTok{import}\NormalTok{ confusion\_matrix, accuracy\_score}
\NormalTok{cm }\OperatorTok{=}\NormalTok{ confusion\_matrix(y\_test, y\_pred)}
\BuiltInTok{print}\NormalTok{(cm)}
\CommentTok{\#\# [[64  4]}
\CommentTok{\#\#  [ 3 29]]}
\NormalTok{accuracy\_score(y\_test, y\_pred)}
\CommentTok{\#\# 0.93}
\end{Highlighting}
\end{Shaded}

R

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{cm }\OtherTok{=} \FunctionTok{table}\NormalTok{(test\_set[, }\DecValTok{3}\NormalTok{], y\_pred)}
\end{Highlighting}
\end{Shaded}

\hypertarget{visualising-the-training-set-results-4}{%
\subsection{Visualising the Training set results}\label{visualising-the-training-set-results-4}}

Python

\begin{Shaded}
\begin{Highlighting}[]
\ImportTok{from}\NormalTok{ matplotlib.colors }\ImportTok{import}\NormalTok{ ListedColormap}
\NormalTok{X\_set, y\_set }\OperatorTok{=}\NormalTok{ sc.inverse\_transform(X\_train), y\_train}
\NormalTok{X1, X2 }\OperatorTok{=}\NormalTok{ np.meshgrid(np.arange(start }\OperatorTok{=}\NormalTok{ X\_set[:, }\DecValTok{0}\NormalTok{].}\BuiltInTok{min}\NormalTok{() }\OperatorTok{{-}} \DecValTok{10}\NormalTok{, stop }\OperatorTok{=}\NormalTok{ X\_set[:, }\DecValTok{0}\NormalTok{].}\BuiltInTok{max}\NormalTok{() }\OperatorTok{+} \DecValTok{10}\NormalTok{, step }\OperatorTok{=} \FloatTok{0.25}\NormalTok{),}
\NormalTok{                     np.arange(start }\OperatorTok{=}\NormalTok{ X\_set[:, }\DecValTok{1}\NormalTok{].}\BuiltInTok{min}\NormalTok{() }\OperatorTok{{-}} \DecValTok{1000}\NormalTok{, stop }\OperatorTok{=}\NormalTok{ X\_set[:, }\DecValTok{1}\NormalTok{].}\BuiltInTok{max}\NormalTok{() }\OperatorTok{+} \DecValTok{1000}\NormalTok{, step }\OperatorTok{=} \FloatTok{0.25}\NormalTok{))}
\NormalTok{plt.contourf(X1, X2, classifier.predict(sc.transform(np.array([X1.ravel(), X2.ravel()]).T)).reshape(X1.shape),}
\NormalTok{             alpha }\OperatorTok{=} \FloatTok{0.75}\NormalTok{, cmap }\OperatorTok{=}\NormalTok{ ListedColormap((}\StringTok{\textquotesingle{}red\textquotesingle{}}\NormalTok{, }\StringTok{\textquotesingle{}green\textquotesingle{}}\NormalTok{)))}
\NormalTok{plt.xlim(X1.}\BuiltInTok{min}\NormalTok{(), X1.}\BuiltInTok{max}\NormalTok{())}
\NormalTok{plt.ylim(X2.}\BuiltInTok{min}\NormalTok{(), X2.}\BuiltInTok{max}\NormalTok{())}
\ControlFlowTok{for}\NormalTok{ i, j }\KeywordTok{in} \BuiltInTok{enumerate}\NormalTok{(np.unique(y\_set)):}
\NormalTok{    plt.scatter(X\_set[y\_set }\OperatorTok{==}\NormalTok{ j, }\DecValTok{0}\NormalTok{], X\_set[y\_set }\OperatorTok{==}\NormalTok{ j, }\DecValTok{1}\NormalTok{], c }\OperatorTok{=}\NormalTok{ ListedColormap((}\StringTok{\textquotesingle{}red\textquotesingle{}}\NormalTok{, }\StringTok{\textquotesingle{}green\textquotesingle{}}\NormalTok{))(i), label }\OperatorTok{=}\NormalTok{ j)}
\NormalTok{plt.title(}\StringTok{\textquotesingle{}Kernel SVM (Training set)\textquotesingle{}}\NormalTok{)}
\NormalTok{plt.xlabel(}\StringTok{\textquotesingle{}Age\textquotesingle{}}\NormalTok{)}
\NormalTok{plt.ylabel(}\StringTok{\textquotesingle{}Estimated Salary\textquotesingle{}}\NormalTok{)}
\NormalTok{plt.legend()}
\NormalTok{plt.show()}
\end{Highlighting}
\end{Shaded}

R

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{library}\NormalTok{(ElemStatLearn)}
\NormalTok{set }\OtherTok{=}\NormalTok{ training\_set}
\NormalTok{X1 }\OtherTok{=} \FunctionTok{seq}\NormalTok{(}\FunctionTok{min}\NormalTok{(set[, }\DecValTok{1}\NormalTok{]) }\SpecialCharTok{{-}} \DecValTok{1}\NormalTok{, }\FunctionTok{max}\NormalTok{(set[, }\DecValTok{1}\NormalTok{]) }\SpecialCharTok{+} \DecValTok{1}\NormalTok{, }\AttributeTok{by =} \FloatTok{0.01}\NormalTok{)}
\NormalTok{X2 }\OtherTok{=} \FunctionTok{seq}\NormalTok{(}\FunctionTok{min}\NormalTok{(set[, }\DecValTok{2}\NormalTok{]) }\SpecialCharTok{{-}} \DecValTok{1}\NormalTok{, }\FunctionTok{max}\NormalTok{(set[, }\DecValTok{2}\NormalTok{]) }\SpecialCharTok{+} \DecValTok{1}\NormalTok{, }\AttributeTok{by =} \FloatTok{0.01}\NormalTok{)}
\NormalTok{grid\_set }\OtherTok{=} \FunctionTok{expand.grid}\NormalTok{(X1, X2)}
\FunctionTok{colnames}\NormalTok{(grid\_set) }\OtherTok{=} \FunctionTok{c}\NormalTok{(}\StringTok{\textquotesingle{}Age\textquotesingle{}}\NormalTok{, }\StringTok{\textquotesingle{}EstimatedSalary\textquotesingle{}}\NormalTok{)}
\NormalTok{y\_grid }\OtherTok{=} \FunctionTok{predict}\NormalTok{(classifier, }\AttributeTok{newdata =}\NormalTok{ grid\_set)}
\FunctionTok{plot}\NormalTok{(set[, }\SpecialCharTok{{-}}\DecValTok{3}\NormalTok{],}
     \AttributeTok{main =} \StringTok{\textquotesingle{}Kernel SVM (Training set)\textquotesingle{}}\NormalTok{,}
     \AttributeTok{xlab =} \StringTok{\textquotesingle{}Age\textquotesingle{}}\NormalTok{, }\AttributeTok{ylab =} \StringTok{\textquotesingle{}Estimated Salary\textquotesingle{}}\NormalTok{,}
     \AttributeTok{xlim =} \FunctionTok{range}\NormalTok{(X1), }\AttributeTok{ylim =} \FunctionTok{range}\NormalTok{(X2))}
\FunctionTok{contour}\NormalTok{(X1, X2, }\FunctionTok{matrix}\NormalTok{(}\FunctionTok{as.numeric}\NormalTok{(y\_grid), }\FunctionTok{length}\NormalTok{(X1), }\FunctionTok{length}\NormalTok{(X2)), }\AttributeTok{add =} \ConstantTok{TRUE}\NormalTok{)}
\FunctionTok{points}\NormalTok{(grid\_set, }\AttributeTok{pch =} \StringTok{\textquotesingle{}.\textquotesingle{}}\NormalTok{, }\AttributeTok{col =} \FunctionTok{ifelse}\NormalTok{(y\_grid }\SpecialCharTok{==} \DecValTok{1}\NormalTok{, }\StringTok{\textquotesingle{}springgreen3\textquotesingle{}}\NormalTok{, }\StringTok{\textquotesingle{}tomato\textquotesingle{}}\NormalTok{))}
\FunctionTok{points}\NormalTok{(set, }\AttributeTok{pch =} \DecValTok{21}\NormalTok{, }\AttributeTok{bg =} \FunctionTok{ifelse}\NormalTok{(set[, }\DecValTok{3}\NormalTok{] }\SpecialCharTok{==} \DecValTok{1}\NormalTok{, }\StringTok{\textquotesingle{}green4\textquotesingle{}}\NormalTok{, }\StringTok{\textquotesingle{}red3\textquotesingle{}}\NormalTok{))}
\end{Highlighting}
\end{Shaded}

\includegraphics{_main_files/figure-latex/unnamed-chunk-157-1.pdf}

\hypertarget{visualising-the-test-set-results-4}{%
\subsection{Visualising the Test set results}\label{visualising-the-test-set-results-4}}

Python

\begin{Shaded}
\begin{Highlighting}[]
\ImportTok{from}\NormalTok{ matplotlib.colors }\ImportTok{import}\NormalTok{ ListedColormap}
\NormalTok{X\_set, y\_set }\OperatorTok{=}\NormalTok{ sc.inverse\_transform(X\_test), y\_test}
\NormalTok{X1, X2 }\OperatorTok{=}\NormalTok{ np.meshgrid(np.arange(start }\OperatorTok{=}\NormalTok{ X\_set[:, }\DecValTok{0}\NormalTok{].}\BuiltInTok{min}\NormalTok{() }\OperatorTok{{-}} \DecValTok{10}\NormalTok{, stop }\OperatorTok{=}\NormalTok{ X\_set[:, }\DecValTok{0}\NormalTok{].}\BuiltInTok{max}\NormalTok{() }\OperatorTok{+} \DecValTok{10}\NormalTok{, step }\OperatorTok{=} \FloatTok{0.25}\NormalTok{),}
\NormalTok{                     np.arange(start }\OperatorTok{=}\NormalTok{ X\_set[:, }\DecValTok{1}\NormalTok{].}\BuiltInTok{min}\NormalTok{() }\OperatorTok{{-}} \DecValTok{1000}\NormalTok{, stop }\OperatorTok{=}\NormalTok{ X\_set[:, }\DecValTok{1}\NormalTok{].}\BuiltInTok{max}\NormalTok{() }\OperatorTok{+} \DecValTok{1000}\NormalTok{, step }\OperatorTok{=} \FloatTok{0.25}\NormalTok{))}
\NormalTok{plt.contourf(X1, X2, classifier.predict(sc.transform(np.array([X1.ravel(), X2.ravel()]).T)).reshape(X1.shape),}
\NormalTok{             alpha }\OperatorTok{=} \FloatTok{0.75}\NormalTok{, cmap }\OperatorTok{=}\NormalTok{ ListedColormap((}\StringTok{\textquotesingle{}red\textquotesingle{}}\NormalTok{, }\StringTok{\textquotesingle{}green\textquotesingle{}}\NormalTok{)))}
\NormalTok{plt.xlim(X1.}\BuiltInTok{min}\NormalTok{(), X1.}\BuiltInTok{max}\NormalTok{())}
\NormalTok{plt.ylim(X2.}\BuiltInTok{min}\NormalTok{(), X2.}\BuiltInTok{max}\NormalTok{())}
\ControlFlowTok{for}\NormalTok{ i, j }\KeywordTok{in} \BuiltInTok{enumerate}\NormalTok{(np.unique(y\_set)):}
\NormalTok{    plt.scatter(X\_set[y\_set }\OperatorTok{==}\NormalTok{ j, }\DecValTok{0}\NormalTok{], X\_set[y\_set }\OperatorTok{==}\NormalTok{ j, }\DecValTok{1}\NormalTok{], c }\OperatorTok{=}\NormalTok{ ListedColormap((}\StringTok{\textquotesingle{}red\textquotesingle{}}\NormalTok{, }\StringTok{\textquotesingle{}green\textquotesingle{}}\NormalTok{))(i), label }\OperatorTok{=}\NormalTok{ j)}
\NormalTok{plt.title(}\StringTok{\textquotesingle{}Kernel SVM (Test set)\textquotesingle{}}\NormalTok{)}
\NormalTok{plt.xlabel(}\StringTok{\textquotesingle{}Age\textquotesingle{}}\NormalTok{)}
\NormalTok{plt.ylabel(}\StringTok{\textquotesingle{}Estimated Salary\textquotesingle{}}\NormalTok{)}
\NormalTok{plt.legend()}
\NormalTok{plt.show()}
\end{Highlighting}
\end{Shaded}

R

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{library}\NormalTok{(ElemStatLearn)}
\NormalTok{set }\OtherTok{=}\NormalTok{ test\_set}
\NormalTok{X1 }\OtherTok{=} \FunctionTok{seq}\NormalTok{(}\FunctionTok{min}\NormalTok{(set[, }\DecValTok{1}\NormalTok{]) }\SpecialCharTok{{-}} \DecValTok{1}\NormalTok{, }\FunctionTok{max}\NormalTok{(set[, }\DecValTok{1}\NormalTok{]) }\SpecialCharTok{+} \DecValTok{1}\NormalTok{, }\AttributeTok{by =} \FloatTok{0.01}\NormalTok{)}
\NormalTok{X2 }\OtherTok{=} \FunctionTok{seq}\NormalTok{(}\FunctionTok{min}\NormalTok{(set[, }\DecValTok{2}\NormalTok{]) }\SpecialCharTok{{-}} \DecValTok{1}\NormalTok{, }\FunctionTok{max}\NormalTok{(set[, }\DecValTok{2}\NormalTok{]) }\SpecialCharTok{+} \DecValTok{1}\NormalTok{, }\AttributeTok{by =} \FloatTok{0.01}\NormalTok{)}
\NormalTok{grid\_set }\OtherTok{=} \FunctionTok{expand.grid}\NormalTok{(X1, X2)}
\FunctionTok{colnames}\NormalTok{(grid\_set) }\OtherTok{=} \FunctionTok{c}\NormalTok{(}\StringTok{\textquotesingle{}Age\textquotesingle{}}\NormalTok{, }\StringTok{\textquotesingle{}EstimatedSalary\textquotesingle{}}\NormalTok{)}
\NormalTok{y\_grid }\OtherTok{=} \FunctionTok{predict}\NormalTok{(classifier, }\AttributeTok{newdata =}\NormalTok{ grid\_set)}
\FunctionTok{plot}\NormalTok{(set[, }\SpecialCharTok{{-}}\DecValTok{3}\NormalTok{], }\AttributeTok{main =} \StringTok{\textquotesingle{}Kernel SVM (Test set)\textquotesingle{}}\NormalTok{,}
     \AttributeTok{xlab =} \StringTok{\textquotesingle{}Age\textquotesingle{}}\NormalTok{, }\AttributeTok{ylab =} \StringTok{\textquotesingle{}Estimated Salary\textquotesingle{}}\NormalTok{,}
     \AttributeTok{xlim =} \FunctionTok{range}\NormalTok{(X1), }\AttributeTok{ylim =} \FunctionTok{range}\NormalTok{(X2))}
\FunctionTok{contour}\NormalTok{(X1, X2, }\FunctionTok{matrix}\NormalTok{(}\FunctionTok{as.numeric}\NormalTok{(y\_grid), }\FunctionTok{length}\NormalTok{(X1), }\FunctionTok{length}\NormalTok{(X2)), }\AttributeTok{add =} \ConstantTok{TRUE}\NormalTok{)}
\FunctionTok{points}\NormalTok{(grid\_set, }\AttributeTok{pch =} \StringTok{\textquotesingle{}.\textquotesingle{}}\NormalTok{, }\AttributeTok{col =} \FunctionTok{ifelse}\NormalTok{(y\_grid }\SpecialCharTok{==} \DecValTok{1}\NormalTok{, }\StringTok{\textquotesingle{}springgreen3\textquotesingle{}}\NormalTok{, }\StringTok{\textquotesingle{}tomato\textquotesingle{}}\NormalTok{))}
\FunctionTok{points}\NormalTok{(set, }\AttributeTok{pch =} \DecValTok{21}\NormalTok{, }\AttributeTok{bg =} \FunctionTok{ifelse}\NormalTok{(set[, }\DecValTok{3}\NormalTok{] }\SpecialCharTok{==} \DecValTok{1}\NormalTok{, }\StringTok{\textquotesingle{}green4\textquotesingle{}}\NormalTok{, }\StringTok{\textquotesingle{}red3\textquotesingle{}}\NormalTok{))}
\end{Highlighting}
\end{Shaded}

\includegraphics{_main_files/figure-latex/unnamed-chunk-159-1.pdf}

\hypertarget{naive-bayes}{%
\section{Naive Bayes}\label{naive-bayes}}

\hypertarget{importing-the-libraries-11}{%
\subsection{Importing the libraries}\label{importing-the-libraries-11}}

Python

\begin{Shaded}
\begin{Highlighting}[]
\ImportTok{import}\NormalTok{ numpy }\ImportTok{as}\NormalTok{ np}
\ImportTok{import}\NormalTok{ matplotlib.pyplot }\ImportTok{as}\NormalTok{ plt}
\ImportTok{import}\NormalTok{ pandas }\ImportTok{as}\NormalTok{ pd}
\end{Highlighting}
\end{Shaded}

\hypertarget{importing-the-dataset-11}{%
\subsection{Importing the dataset}\label{importing-the-dataset-11}}

Python

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{dataset }\OperatorTok{=}\NormalTok{ pd.read\_csv(}\StringTok{\textquotesingle{}Social\_Network\_Ads.csv\textquotesingle{}}\NormalTok{)}
\NormalTok{X }\OperatorTok{=}\NormalTok{ dataset.iloc[:, :}\OperatorTok{{-}}\DecValTok{1}\NormalTok{].values}
\NormalTok{y }\OperatorTok{=}\NormalTok{ dataset.iloc[:, }\OperatorTok{{-}}\DecValTok{1}\NormalTok{].values}
\end{Highlighting}
\end{Shaded}

R

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{dataset }\OtherTok{=} \FunctionTok{read.csv}\NormalTok{(}\StringTok{\textquotesingle{}Social\_Network\_Ads.csv\textquotesingle{}}\NormalTok{)}
\CommentTok{\# dataset = dataset[3:5]}
\end{Highlighting}
\end{Shaded}

\hypertarget{encoding-the-target-feature-as-factor-4}{%
\subsection{Encoding the target feature as factor}\label{encoding-the-target-feature-as-factor-4}}

R

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{dataset}\SpecialCharTok{$}\NormalTok{Purchased }\OtherTok{=} \FunctionTok{factor}\NormalTok{(dataset}\SpecialCharTok{$}\NormalTok{Purchased, }\AttributeTok{levels =} \FunctionTok{c}\NormalTok{(}\DecValTok{0}\NormalTok{, }\DecValTok{1}\NormalTok{))}
\end{Highlighting}
\end{Shaded}

\hypertarget{splitting-the-dataset-into-the-training-set-and-test-set-7}{%
\subsection{Splitting the dataset into the Training set and Test set}\label{splitting-the-dataset-into-the-training-set-and-test-set-7}}

Python

\begin{Shaded}
\begin{Highlighting}[]
\ImportTok{from}\NormalTok{ sklearn.model\_selection }\ImportTok{import}\NormalTok{ train\_test\_split}
\NormalTok{X\_train, X\_test, y\_train, y\_test }\OperatorTok{=}\NormalTok{ train\_test\_split(X, y, test\_size }\OperatorTok{=} \FloatTok{0.25}\NormalTok{, random\_state }\OperatorTok{=} \DecValTok{0}\NormalTok{)}
\BuiltInTok{print}\NormalTok{(X\_train)}
\CommentTok{\#\# [[    44  39000]}
\CommentTok{\#\#  [    32 120000]}
\CommentTok{\#\#  [    38  50000]}
\CommentTok{\#\#  [    32 135000]}
\CommentTok{\#\#  [    52  21000]}
\CommentTok{\#\#  [    53 104000]}
\CommentTok{\#\#  [    39  42000]}
\CommentTok{\#\#  [    38  61000]}
\CommentTok{\#\#  [    36  50000]}
\CommentTok{\#\#  [    36  63000]}
\CommentTok{\#\#  [    35  25000]}
\CommentTok{\#\#  [    35  50000]}
\CommentTok{\#\#  [    42  73000]}
\CommentTok{\#\#  [    47  49000]}
\CommentTok{\#\#  [    59  29000]}
\CommentTok{\#\#  [    49  65000]}
\CommentTok{\#\#  [    45 131000]}
\CommentTok{\#\#  [    31  89000]}
\CommentTok{\#\#  [    46  82000]}
\CommentTok{\#\#  [    47  51000]}
\CommentTok{\#\#  [    26  15000]}
\CommentTok{\#\#  [    60 102000]}
\CommentTok{\#\#  [    38 112000]}
\CommentTok{\#\#  [    40 107000]}
\CommentTok{\#\#  [    42  53000]}
\CommentTok{\#\#  [    35  59000]}
\CommentTok{\#\#  [    48  41000]}
\CommentTok{\#\#  [    48 134000]}
\CommentTok{\#\#  [    38 113000]}
\CommentTok{\#\#  [    29 148000]}
\CommentTok{\#\#  [    26  15000]}
\CommentTok{\#\#  [    60  42000]}
\CommentTok{\#\#  [    24  19000]}
\CommentTok{\#\#  [    42 149000]}
\CommentTok{\#\#  [    46  96000]}
\CommentTok{\#\#  [    28  59000]}
\CommentTok{\#\#  [    39  96000]}
\CommentTok{\#\#  [    28  89000]}
\CommentTok{\#\#  [    41  72000]}
\CommentTok{\#\#  [    45  26000]}
\CommentTok{\#\#  [    33  69000]}
\CommentTok{\#\#  [    20  82000]}
\CommentTok{\#\#  [    31  74000]}
\CommentTok{\#\#  [    42  80000]}
\CommentTok{\#\#  [    35  72000]}
\CommentTok{\#\#  [    33 149000]}
\CommentTok{\#\#  [    40  71000]}
\CommentTok{\#\#  [    51 146000]}
\CommentTok{\#\#  [    46  79000]}
\CommentTok{\#\#  [    35  75000]}
\CommentTok{\#\#  [    38  51000]}
\CommentTok{\#\#  [    36  75000]}
\CommentTok{\#\#  [    37  78000]}
\CommentTok{\#\#  [    38  61000]}
\CommentTok{\#\#  [    60 108000]}
\CommentTok{\#\#  [    20  82000]}
\CommentTok{\#\#  [    57  74000]}
\CommentTok{\#\#  [    42  65000]}
\CommentTok{\#\#  [    26  80000]}
\CommentTok{\#\#  [    46 117000]}
\CommentTok{\#\#  [    35  61000]}
\CommentTok{\#\#  [    21  68000]}
\CommentTok{\#\#  [    28  44000]}
\CommentTok{\#\#  [    41  87000]}
\CommentTok{\#\#  [    37  33000]}
\CommentTok{\#\#  [    27  90000]}
\CommentTok{\#\#  [    39  42000]}
\CommentTok{\#\#  [    28 123000]}
\CommentTok{\#\#  [    31 118000]}
\CommentTok{\#\#  [    25  87000]}
\CommentTok{\#\#  [    35  71000]}
\CommentTok{\#\#  [    37  70000]}
\CommentTok{\#\#  [    35  39000]}
\CommentTok{\#\#  [    47  23000]}
\CommentTok{\#\#  [    35 147000]}
\CommentTok{\#\#  [    48 138000]}
\CommentTok{\#\#  [    26  86000]}
\CommentTok{\#\#  [    25  79000]}
\CommentTok{\#\#  [    52 138000]}
\CommentTok{\#\#  [    51  23000]}
\CommentTok{\#\#  [    35  60000]}
\CommentTok{\#\#  [    33 113000]}
\CommentTok{\#\#  [    30 107000]}
\CommentTok{\#\#  [    48  33000]}
\CommentTok{\#\#  [    41  80000]}
\CommentTok{\#\#  [    48  96000]}
\CommentTok{\#\#  [    31  18000]}
\CommentTok{\#\#  [    31  71000]}
\CommentTok{\#\#  [    43 129000]}
\CommentTok{\#\#  [    59  76000]}
\CommentTok{\#\#  [    18  44000]}
\CommentTok{\#\#  [    36 118000]}
\CommentTok{\#\#  [    42  90000]}
\CommentTok{\#\#  [    47  30000]}
\CommentTok{\#\#  [    26  43000]}
\CommentTok{\#\#  [    40  78000]}
\CommentTok{\#\#  [    46  59000]}
\CommentTok{\#\#  [    59  42000]}
\CommentTok{\#\#  [    46  74000]}
\CommentTok{\#\#  [    35  91000]}
\CommentTok{\#\#  [    28  59000]}
\CommentTok{\#\#  [    40  57000]}
\CommentTok{\#\#  [    59 143000]}
\CommentTok{\#\#  [    57  26000]}
\CommentTok{\#\#  [    52  38000]}
\CommentTok{\#\#  [    47 113000]}
\CommentTok{\#\#  [    53 143000]}
\CommentTok{\#\#  [    35  27000]}
\CommentTok{\#\#  [    58 101000]}
\CommentTok{\#\#  [    45  45000]}
\CommentTok{\#\#  [    23  82000]}
\CommentTok{\#\#  [    46  23000]}
\CommentTok{\#\#  [    42  65000]}
\CommentTok{\#\#  [    28  84000]}
\CommentTok{\#\#  [    38  59000]}
\CommentTok{\#\#  [    26  84000]}
\CommentTok{\#\#  [    29  28000]}
\CommentTok{\#\#  [    37  71000]}
\CommentTok{\#\#  [    22  55000]}
\CommentTok{\#\#  [    48  35000]}
\CommentTok{\#\#  [    49  28000]}
\CommentTok{\#\#  [    38  65000]}
\CommentTok{\#\#  [    27  17000]}
\CommentTok{\#\#  [    46  28000]}
\CommentTok{\#\#  [    48 141000]}
\CommentTok{\#\#  [    26  17000]}
\CommentTok{\#\#  [    35  97000]}
\CommentTok{\#\#  [    39  59000]}
\CommentTok{\#\#  [    24  27000]}
\CommentTok{\#\#  [    32  18000]}
\CommentTok{\#\#  [    46  88000]}
\CommentTok{\#\#  [    35  58000]}
\CommentTok{\#\#  [    56  60000]}
\CommentTok{\#\#  [    47  34000]}
\CommentTok{\#\#  [    40  72000]}
\CommentTok{\#\#  [    32 100000]}
\CommentTok{\#\#  [    19  21000]}
\CommentTok{\#\#  [    25  90000]}
\CommentTok{\#\#  [    35  88000]}
\CommentTok{\#\#  [    28  32000]}
\CommentTok{\#\#  [    50  20000]}
\CommentTok{\#\#  [    40  59000]}
\CommentTok{\#\#  [    50  44000]}
\CommentTok{\#\#  [    35  72000]}
\CommentTok{\#\#  [    40 142000]}
\CommentTok{\#\#  [    46  32000]}
\CommentTok{\#\#  [    39  71000]}
\CommentTok{\#\#  [    20  74000]}
\CommentTok{\#\#  [    29  75000]}
\CommentTok{\#\#  [    31  76000]}
\CommentTok{\#\#  [    47  25000]}
\CommentTok{\#\#  [    40  61000]}
\CommentTok{\#\#  [    34 112000]}
\CommentTok{\#\#  [    38  80000]}
\CommentTok{\#\#  [    42  75000]}
\CommentTok{\#\#  [    47  47000]}
\CommentTok{\#\#  [    39  75000]}
\CommentTok{\#\#  [    19  25000]}
\CommentTok{\#\#  [    37  80000]}
\CommentTok{\#\#  [    36  60000]}
\CommentTok{\#\#  [    41  52000]}
\CommentTok{\#\#  [    36 125000]}
\CommentTok{\#\#  [    48  29000]}
\CommentTok{\#\#  [    36 126000]}
\CommentTok{\#\#  [    51 134000]}
\CommentTok{\#\#  [    27  57000]}
\CommentTok{\#\#  [    38  71000]}
\CommentTok{\#\#  [    39  61000]}
\CommentTok{\#\#  [    22  27000]}
\CommentTok{\#\#  [    33  60000]}
\CommentTok{\#\#  [    48  74000]}
\CommentTok{\#\#  [    58  23000]}
\CommentTok{\#\#  [    53  72000]}
\CommentTok{\#\#  [    32 117000]}
\CommentTok{\#\#  [    54  70000]}
\CommentTok{\#\#  [    30  80000]}
\CommentTok{\#\#  [    58  95000]}
\CommentTok{\#\#  [    26  52000]}
\CommentTok{\#\#  [    45  79000]}
\CommentTok{\#\#  [    24  55000]}
\CommentTok{\#\#  [    40  75000]}
\CommentTok{\#\#  [    33  28000]}
\CommentTok{\#\#  [    44 139000]}
\CommentTok{\#\#  [    22  18000]}
\CommentTok{\#\#  [    33  51000]}
\CommentTok{\#\#  [    43 133000]}
\CommentTok{\#\#  [    24  32000]}
\CommentTok{\#\#  [    46  22000]}
\CommentTok{\#\#  [    35  55000]}
\CommentTok{\#\#  [    54 104000]}
\CommentTok{\#\#  [    48 119000]}
\CommentTok{\#\#  [    35  53000]}
\CommentTok{\#\#  [    37 144000]}
\CommentTok{\#\#  [    23  66000]}
\CommentTok{\#\#  [    37 137000]}
\CommentTok{\#\#  [    31  58000]}
\CommentTok{\#\#  [    33  41000]}
\CommentTok{\#\#  [    45  22000]}
\CommentTok{\#\#  [    30  15000]}
\CommentTok{\#\#  [    19  19000]}
\CommentTok{\#\#  [    49  74000]}
\CommentTok{\#\#  [    39 122000]}
\CommentTok{\#\#  [    35  73000]}
\CommentTok{\#\#  [    39  71000]}
\CommentTok{\#\#  [    24  23000]}
\CommentTok{\#\#  [    41  72000]}
\CommentTok{\#\#  [    29  83000]}
\CommentTok{\#\#  [    54  26000]}
\CommentTok{\#\#  [    35  44000]}
\CommentTok{\#\#  [    37  75000]}
\CommentTok{\#\#  [    29  47000]}
\CommentTok{\#\#  [    31  68000]}
\CommentTok{\#\#  [    42  54000]}
\CommentTok{\#\#  [    30 135000]}
\CommentTok{\#\#  [    52 114000]}
\CommentTok{\#\#  [    50  36000]}
\CommentTok{\#\#  [    56 133000]}
\CommentTok{\#\#  [    29  61000]}
\CommentTok{\#\#  [    30  89000]}
\CommentTok{\#\#  [    26  16000]}
\CommentTok{\#\#  [    33  31000]}
\CommentTok{\#\#  [    41  72000]}
\CommentTok{\#\#  [    36  33000]}
\CommentTok{\#\#  [    55 125000]}
\CommentTok{\#\#  [    48 131000]}
\CommentTok{\#\#  [    41  71000]}
\CommentTok{\#\#  [    30  62000]}
\CommentTok{\#\#  [    37  72000]}
\CommentTok{\#\#  [    41  63000]}
\CommentTok{\#\#  [    58  47000]}
\CommentTok{\#\#  [    30 116000]}
\CommentTok{\#\#  [    20  49000]}
\CommentTok{\#\#  [    37  74000]}
\CommentTok{\#\#  [    41  59000]}
\CommentTok{\#\#  [    49  89000]}
\CommentTok{\#\#  [    28  79000]}
\CommentTok{\#\#  [    53  82000]}
\CommentTok{\#\#  [    40  57000]}
\CommentTok{\#\#  [    60  34000]}
\CommentTok{\#\#  [    35 108000]}
\CommentTok{\#\#  [    21  72000]}
\CommentTok{\#\#  [    38  71000]}
\CommentTok{\#\#  [    39 106000]}
\CommentTok{\#\#  [    37  57000]}
\CommentTok{\#\#  [    26  72000]}
\CommentTok{\#\#  [    35  23000]}
\CommentTok{\#\#  [    54 108000]}
\CommentTok{\#\#  [    30  17000]}
\CommentTok{\#\#  [    39 134000]}
\CommentTok{\#\#  [    29  43000]}
\CommentTok{\#\#  [    33  43000]}
\CommentTok{\#\#  [    35  38000]}
\CommentTok{\#\#  [    41  45000]}
\CommentTok{\#\#  [    41  72000]}
\CommentTok{\#\#  [    39 134000]}
\CommentTok{\#\#  [    27 137000]}
\CommentTok{\#\#  [    21  16000]}
\CommentTok{\#\#  [    26  32000]}
\CommentTok{\#\#  [    31  66000]}
\CommentTok{\#\#  [    39  73000]}
\CommentTok{\#\#  [    41  79000]}
\CommentTok{\#\#  [    47  50000]}
\CommentTok{\#\#  [    41  30000]}
\CommentTok{\#\#  [    37  93000]}
\CommentTok{\#\#  [    60  46000]}
\CommentTok{\#\#  [    25  22000]}
\CommentTok{\#\#  [    28  37000]}
\CommentTok{\#\#  [    38  55000]}
\CommentTok{\#\#  [    36  54000]}
\CommentTok{\#\#  [    20  36000]}
\CommentTok{\#\#  [    56 104000]}
\CommentTok{\#\#  [    40  57000]}
\CommentTok{\#\#  [    42 108000]}
\CommentTok{\#\#  [    20  23000]}
\CommentTok{\#\#  [    40  65000]}
\CommentTok{\#\#  [    47  20000]}
\CommentTok{\#\#  [    18  86000]}
\CommentTok{\#\#  [    35  79000]}
\CommentTok{\#\#  [    57  33000]}
\CommentTok{\#\#  [    34  72000]}
\CommentTok{\#\#  [    49  39000]}
\CommentTok{\#\#  [    27  31000]}
\CommentTok{\#\#  [    19  70000]}
\CommentTok{\#\#  [    39  79000]}
\CommentTok{\#\#  [    26  81000]}
\CommentTok{\#\#  [    25  80000]}
\CommentTok{\#\#  [    28  85000]}
\CommentTok{\#\#  [    55  39000]}
\CommentTok{\#\#  [    50  88000]}
\CommentTok{\#\#  [    49  88000]}
\CommentTok{\#\#  [    52 150000]}
\CommentTok{\#\#  [    35  65000]}
\CommentTok{\#\#  [    42  54000]}
\CommentTok{\#\#  [    34  43000]}
\CommentTok{\#\#  [    37  52000]}
\CommentTok{\#\#  [    48  30000]}
\CommentTok{\#\#  [    29  43000]}
\CommentTok{\#\#  [    36  52000]}
\CommentTok{\#\#  [    27  54000]}
\CommentTok{\#\#  [    26 118000]]}
\BuiltInTok{print}\NormalTok{(y\_train)}
\CommentTok{\#\# [0 1 0 1 1 1 0 0 0 0 0 0 1 1 1 0 1 0 0 1 0 1 0 1 0 0 1 1 1 1 0 1 0 1 0 0 1}
\CommentTok{\#\#  0 0 1 0 0 0 0 0 1 1 1 1 0 0 0 1 0 1 0 1 0 0 1 0 0 0 1 0 0 0 1 1 0 0 1 0 1}
\CommentTok{\#\#  1 1 0 0 1 1 0 0 1 1 0 1 0 0 1 1 0 1 1 1 0 0 0 0 0 1 0 0 1 1 1 1 1 0 1 1 0}
\CommentTok{\#\#  1 0 0 0 0 0 0 0 1 1 0 0 1 0 0 1 0 0 0 1 0 1 1 0 1 0 0 0 0 1 0 0 0 1 1 0 0}
\CommentTok{\#\#  0 0 1 0 1 0 0 0 1 0 0 0 0 1 1 1 0 0 0 0 0 0 1 1 1 1 1 0 1 0 0 0 0 0 1 0 0}
\CommentTok{\#\#  0 0 0 0 1 1 0 1 0 1 0 0 1 0 0 0 1 0 0 0 0 0 1 0 0 0 0 0 1 0 1 1 0 0 0 0 0}
\CommentTok{\#\#  0 1 1 0 0 0 0 1 0 0 0 0 1 0 1 0 1 0 0 0 1 0 0 0 1 0 1 0 0 0 0 0 1 1 0 0 0}
\CommentTok{\#\#  0 0 1 0 1 1 0 0 0 0 0 1 0 1 0 0 1 0 0 1 0 1 0 0 0 0 0 0 1 1 1 1 0 0 0 0 1}
\CommentTok{\#\#  0 0 0 0]}
\BuiltInTok{print}\NormalTok{(X\_test)}
\CommentTok{\#\# [[    30  87000]}
\CommentTok{\#\#  [    38  50000]}
\CommentTok{\#\#  [    35  75000]}
\CommentTok{\#\#  [    30  79000]}
\CommentTok{\#\#  [    35  50000]}
\CommentTok{\#\#  [    27  20000]}
\CommentTok{\#\#  [    31  15000]}
\CommentTok{\#\#  [    36 144000]}
\CommentTok{\#\#  [    18  68000]}
\CommentTok{\#\#  [    47  43000]}
\CommentTok{\#\#  [    30  49000]}
\CommentTok{\#\#  [    28  55000]}
\CommentTok{\#\#  [    37  55000]}
\CommentTok{\#\#  [    39  77000]}
\CommentTok{\#\#  [    20  86000]}
\CommentTok{\#\#  [    32 117000]}
\CommentTok{\#\#  [    37  77000]}
\CommentTok{\#\#  [    19  85000]}
\CommentTok{\#\#  [    55 130000]}
\CommentTok{\#\#  [    35  22000]}
\CommentTok{\#\#  [    35  47000]}
\CommentTok{\#\#  [    47 144000]}
\CommentTok{\#\#  [    41  51000]}
\CommentTok{\#\#  [    47 105000]}
\CommentTok{\#\#  [    23  28000]}
\CommentTok{\#\#  [    49 141000]}
\CommentTok{\#\#  [    28  87000]}
\CommentTok{\#\#  [    29  80000]}
\CommentTok{\#\#  [    37  62000]}
\CommentTok{\#\#  [    32  86000]}
\CommentTok{\#\#  [    21  88000]}
\CommentTok{\#\#  [    37  79000]}
\CommentTok{\#\#  [    57  60000]}
\CommentTok{\#\#  [    37  53000]}
\CommentTok{\#\#  [    24  58000]}
\CommentTok{\#\#  [    18  52000]}
\CommentTok{\#\#  [    22  81000]}
\CommentTok{\#\#  [    34  43000]}
\CommentTok{\#\#  [    31  34000]}
\CommentTok{\#\#  [    49  36000]}
\CommentTok{\#\#  [    27  88000]}
\CommentTok{\#\#  [    41  52000]}
\CommentTok{\#\#  [    27  84000]}
\CommentTok{\#\#  [    35  20000]}
\CommentTok{\#\#  [    43 112000]}
\CommentTok{\#\#  [    27  58000]}
\CommentTok{\#\#  [    37  80000]}
\CommentTok{\#\#  [    52  90000]}
\CommentTok{\#\#  [    26  30000]}
\CommentTok{\#\#  [    49  86000]}
\CommentTok{\#\#  [    57 122000]}
\CommentTok{\#\#  [    34  25000]}
\CommentTok{\#\#  [    35  57000]}
\CommentTok{\#\#  [    34 115000]}
\CommentTok{\#\#  [    59  88000]}
\CommentTok{\#\#  [    45  32000]}
\CommentTok{\#\#  [    29  83000]}
\CommentTok{\#\#  [    26  80000]}
\CommentTok{\#\#  [    49  28000]}
\CommentTok{\#\#  [    23  20000]}
\CommentTok{\#\#  [    32  18000]}
\CommentTok{\#\#  [    60  42000]}
\CommentTok{\#\#  [    19  76000]}
\CommentTok{\#\#  [    36  99000]}
\CommentTok{\#\#  [    19  26000]}
\CommentTok{\#\#  [    60  83000]}
\CommentTok{\#\#  [    24  89000]}
\CommentTok{\#\#  [    27  58000]}
\CommentTok{\#\#  [    40  47000]}
\CommentTok{\#\#  [    42  70000]}
\CommentTok{\#\#  [    32 150000]}
\CommentTok{\#\#  [    35  77000]}
\CommentTok{\#\#  [    22  63000]}
\CommentTok{\#\#  [    45  22000]}
\CommentTok{\#\#  [    27  89000]}
\CommentTok{\#\#  [    18  82000]}
\CommentTok{\#\#  [    42  79000]}
\CommentTok{\#\#  [    40  60000]}
\CommentTok{\#\#  [    53  34000]}
\CommentTok{\#\#  [    47 107000]}
\CommentTok{\#\#  [    58 144000]}
\CommentTok{\#\#  [    59  83000]}
\CommentTok{\#\#  [    24  55000]}
\CommentTok{\#\#  [    26  35000]}
\CommentTok{\#\#  [    58  38000]}
\CommentTok{\#\#  [    42  80000]}
\CommentTok{\#\#  [    40  75000]}
\CommentTok{\#\#  [    59 130000]}
\CommentTok{\#\#  [    46  41000]}
\CommentTok{\#\#  [    41  60000]}
\CommentTok{\#\#  [    42  64000]}
\CommentTok{\#\#  [    37 146000]}
\CommentTok{\#\#  [    23  48000]}
\CommentTok{\#\#  [    25  33000]}
\CommentTok{\#\#  [    24  84000]}
\CommentTok{\#\#  [    27  96000]}
\CommentTok{\#\#  [    23  63000]}
\CommentTok{\#\#  [    48  33000]}
\CommentTok{\#\#  [    48  90000]}
\CommentTok{\#\#  [    42 104000]]}
\BuiltInTok{print}\NormalTok{(y\_test)}
\CommentTok{\#\# [0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 1 0 0 1 0 1 0 1 0 0 0 0 0 1 1 0 0 0 0}
\CommentTok{\#\#  0 0 1 0 0 0 0 1 0 0 1 0 1 1 0 0 0 1 1 0 0 1 0 0 1 0 1 0 1 0 0 0 0 1 0 0 1}
\CommentTok{\#\#  0 0 0 0 1 1 1 0 0 0 1 1 0 1 1 0 0 1 0 0 0 1 0 1 1 1]}
\end{Highlighting}
\end{Shaded}

R

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\# install.packages(\textquotesingle{}caTools\textquotesingle{})}
\FunctionTok{library}\NormalTok{(caTools)}
\FunctionTok{set.seed}\NormalTok{(}\DecValTok{123}\NormalTok{)}
\NormalTok{split }\OtherTok{=} \FunctionTok{sample.split}\NormalTok{(dataset}\SpecialCharTok{$}\NormalTok{Purchased, }\AttributeTok{SplitRatio =} \FloatTok{0.75}\NormalTok{)}
\NormalTok{training\_set }\OtherTok{=} \FunctionTok{subset}\NormalTok{(dataset, split }\SpecialCharTok{==} \ConstantTok{TRUE}\NormalTok{)}
\NormalTok{test\_set }\OtherTok{=} \FunctionTok{subset}\NormalTok{(dataset, split }\SpecialCharTok{==} \ConstantTok{FALSE}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\hypertarget{feature-scaling-6}{%
\subsection{Feature Scaling}\label{feature-scaling-6}}

Python

\begin{Shaded}
\begin{Highlighting}[]
\ImportTok{from}\NormalTok{ sklearn.preprocessing }\ImportTok{import}\NormalTok{ StandardScaler}
\NormalTok{sc }\OperatorTok{=}\NormalTok{ StandardScaler()}
\NormalTok{X\_train }\OperatorTok{=}\NormalTok{ sc.fit\_transform(X\_train)}
\NormalTok{X\_test }\OperatorTok{=}\NormalTok{ sc.transform(X\_test)}
\BuiltInTok{print}\NormalTok{(X\_train)}
\CommentTok{\#\# [[ 0.58 {-}0.89]}
\CommentTok{\#\#  [{-}0.61  1.46]}
\CommentTok{\#\#  [{-}0.01 {-}0.57]}
\CommentTok{\#\#  [{-}0.61  1.9 ]}
\CommentTok{\#\#  [ 1.37 {-}1.41]}
\CommentTok{\#\#  [ 1.47  1.  ]}
\CommentTok{\#\#  [ 0.09 {-}0.8 ]}
\CommentTok{\#\#  [{-}0.01 {-}0.25]}
\CommentTok{\#\#  [{-}0.21 {-}0.57]}
\CommentTok{\#\#  [{-}0.21 {-}0.19]}
\CommentTok{\#\#  [{-}0.31 {-}1.29]}
\CommentTok{\#\#  [{-}0.31 {-}0.57]}
\CommentTok{\#\#  [ 0.38  0.1 ]}
\CommentTok{\#\#  [ 0.88 {-}0.6 ]}
\CommentTok{\#\#  [ 2.07 {-}1.18]}
\CommentTok{\#\#  [ 1.08 {-}0.13]}
\CommentTok{\#\#  [ 0.68  1.78]}
\CommentTok{\#\#  [{-}0.71  0.56]}
\CommentTok{\#\#  [ 0.78  0.36]}
\CommentTok{\#\#  [ 0.88 {-}0.54]}
\CommentTok{\#\#  [{-}1.2  {-}1.58]}
\CommentTok{\#\#  [ 2.17  0.94]}
\CommentTok{\#\#  [{-}0.01  1.23]}
\CommentTok{\#\#  [ 0.19  1.08]}
\CommentTok{\#\#  [ 0.38 {-}0.48]}
\CommentTok{\#\#  [{-}0.31 {-}0.31]}
\CommentTok{\#\#  [ 0.98 {-}0.83]}
\CommentTok{\#\#  [ 0.98  1.87]}
\CommentTok{\#\#  [{-}0.01  1.26]}
\CommentTok{\#\#  [{-}0.9   2.27]}
\CommentTok{\#\#  [{-}1.2  {-}1.58]}
\CommentTok{\#\#  [ 2.17 {-}0.8 ]}
\CommentTok{\#\#  [{-}1.4  {-}1.47]}
\CommentTok{\#\#  [ 0.38  2.3 ]}
\CommentTok{\#\#  [ 0.78  0.77]}
\CommentTok{\#\#  [{-}1.   {-}0.31]}
\CommentTok{\#\#  [ 0.09  0.77]}
\CommentTok{\#\#  [{-}1.    0.56]}
\CommentTok{\#\#  [ 0.28  0.07]}
\CommentTok{\#\#  [ 0.68 {-}1.26]}
\CommentTok{\#\#  [{-}0.51 {-}0.02]}
\CommentTok{\#\#  [{-}1.8   0.36]}
\CommentTok{\#\#  [{-}0.71  0.13]}
\CommentTok{\#\#  [ 0.38  0.3 ]}
\CommentTok{\#\#  [{-}0.31  0.07]}
\CommentTok{\#\#  [{-}0.51  2.3 ]}
\CommentTok{\#\#  [ 0.19  0.04]}
\CommentTok{\#\#  [ 1.27  2.22]}
\CommentTok{\#\#  [ 0.78  0.27]}
\CommentTok{\#\#  [{-}0.31  0.16]}
\CommentTok{\#\#  [{-}0.01 {-}0.54]}
\CommentTok{\#\#  [{-}0.21  0.16]}
\CommentTok{\#\#  [{-}0.11  0.24]}
\CommentTok{\#\#  [{-}0.01 {-}0.25]}
\CommentTok{\#\#  [ 2.17  1.11]}
\CommentTok{\#\#  [{-}1.8   0.36]}
\CommentTok{\#\#  [ 1.87  0.13]}
\CommentTok{\#\#  [ 0.38 {-}0.13]}
\CommentTok{\#\#  [{-}1.2   0.3 ]}
\CommentTok{\#\#  [ 0.78  1.37]}
\CommentTok{\#\#  [{-}0.31 {-}0.25]}
\CommentTok{\#\#  [{-}1.7  {-}0.05]}
\CommentTok{\#\#  [{-}1.   {-}0.74]}
\CommentTok{\#\#  [ 0.28  0.5 ]}
\CommentTok{\#\#  [{-}0.11 {-}1.06]}
\CommentTok{\#\#  [{-}1.1   0.59]}
\CommentTok{\#\#  [ 0.09 {-}0.8 ]}
\CommentTok{\#\#  [{-}1.    1.55]}
\CommentTok{\#\#  [{-}0.71  1.4 ]}
\CommentTok{\#\#  [{-}1.3   0.5 ]}
\CommentTok{\#\#  [{-}0.31  0.04]}
\CommentTok{\#\#  [{-}0.11  0.01]}
\CommentTok{\#\#  [{-}0.31 {-}0.89]}
\CommentTok{\#\#  [ 0.88 {-}1.35]}
\CommentTok{\#\#  [{-}0.31  2.24]}
\CommentTok{\#\#  [ 0.98  1.98]}
\CommentTok{\#\#  [{-}1.2   0.48]}
\CommentTok{\#\#  [{-}1.3   0.27]}
\CommentTok{\#\#  [ 1.37  1.98]}
\CommentTok{\#\#  [ 1.27 {-}1.35]}
\CommentTok{\#\#  [{-}0.31 {-}0.28]}
\CommentTok{\#\#  [{-}0.51  1.26]}
\CommentTok{\#\#  [{-}0.8   1.08]}
\CommentTok{\#\#  [ 0.98 {-}1.06]}
\CommentTok{\#\#  [ 0.28  0.3 ]}
\CommentTok{\#\#  [ 0.98  0.77]}
\CommentTok{\#\#  [{-}0.71 {-}1.5 ]}
\CommentTok{\#\#  [{-}0.71  0.04]}
\CommentTok{\#\#  [ 0.48  1.72]}
\CommentTok{\#\#  [ 2.07  0.19]}
\CommentTok{\#\#  [{-}1.99 {-}0.74]}
\CommentTok{\#\#  [{-}0.21  1.4 ]}
\CommentTok{\#\#  [ 0.38  0.59]}
\CommentTok{\#\#  [ 0.88 {-}1.15]}
\CommentTok{\#\#  [{-}1.2  {-}0.77]}
\CommentTok{\#\#  [ 0.19  0.24]}
\CommentTok{\#\#  [ 0.78 {-}0.31]}
\CommentTok{\#\#  [ 2.07 {-}0.8 ]}
\CommentTok{\#\#  [ 0.78  0.13]}
\CommentTok{\#\#  [{-}0.31  0.62]}
\CommentTok{\#\#  [{-}1.   {-}0.31]}
\CommentTok{\#\#  [ 0.19 {-}0.36]}
\CommentTok{\#\#  [ 2.07  2.13]}
\CommentTok{\#\#  [ 1.87 {-}1.26]}
\CommentTok{\#\#  [ 1.37 {-}0.92]}
\CommentTok{\#\#  [ 0.88  1.26]}
\CommentTok{\#\#  [ 1.47  2.13]}
\CommentTok{\#\#  [{-}0.31 {-}1.23]}
\CommentTok{\#\#  [ 1.97  0.91]}
\CommentTok{\#\#  [ 0.68 {-}0.71]}
\CommentTok{\#\#  [{-}1.5   0.36]}
\CommentTok{\#\#  [ 0.78 {-}1.35]}
\CommentTok{\#\#  [ 0.38 {-}0.13]}
\CommentTok{\#\#  [{-}1.    0.42]}
\CommentTok{\#\#  [{-}0.01 {-}0.31]}
\CommentTok{\#\#  [{-}1.2   0.42]}
\CommentTok{\#\#  [{-}0.9  {-}1.21]}
\CommentTok{\#\#  [{-}0.11  0.04]}
\CommentTok{\#\#  [{-}1.6  {-}0.42]}
\CommentTok{\#\#  [ 0.98 {-}1.  ]}
\CommentTok{\#\#  [ 1.08 {-}1.21]}
\CommentTok{\#\#  [{-}0.01 {-}0.13]}
\CommentTok{\#\#  [{-}1.1  {-}1.52]}
\CommentTok{\#\#  [ 0.78 {-}1.21]}
\CommentTok{\#\#  [ 0.98  2.07]}
\CommentTok{\#\#  [{-}1.2  {-}1.52]}
\CommentTok{\#\#  [{-}0.31  0.79]}
\CommentTok{\#\#  [ 0.09 {-}0.31]}
\CommentTok{\#\#  [{-}1.4  {-}1.23]}
\CommentTok{\#\#  [{-}0.61 {-}1.5 ]}
\CommentTok{\#\#  [ 0.78  0.53]}
\CommentTok{\#\#  [{-}0.31 {-}0.34]}
\CommentTok{\#\#  [ 1.77 {-}0.28]}
\CommentTok{\#\#  [ 0.88 {-}1.03]}
\CommentTok{\#\#  [ 0.19  0.07]}
\CommentTok{\#\#  [{-}0.61  0.88]}
\CommentTok{\#\#  [{-}1.89 {-}1.41]}
\CommentTok{\#\#  [{-}1.3   0.59]}
\CommentTok{\#\#  [{-}0.31  0.53]}
\CommentTok{\#\#  [{-}1.   {-}1.09]}
\CommentTok{\#\#  [ 1.18 {-}1.44]}
\CommentTok{\#\#  [ 0.19 {-}0.31]}
\CommentTok{\#\#  [ 1.18 {-}0.74]}
\CommentTok{\#\#  [{-}0.31  0.07]}
\CommentTok{\#\#  [ 0.19  2.1 ]}
\CommentTok{\#\#  [ 0.78 {-}1.09]}
\CommentTok{\#\#  [ 0.09  0.04]}
\CommentTok{\#\#  [{-}1.8   0.13]}
\CommentTok{\#\#  [{-}0.9   0.16]}
\CommentTok{\#\#  [{-}0.71  0.19]}
\CommentTok{\#\#  [ 0.88 {-}1.29]}
\CommentTok{\#\#  [ 0.19 {-}0.25]}
\CommentTok{\#\#  [{-}0.41  1.23]}
\CommentTok{\#\#  [{-}0.01  0.3 ]}
\CommentTok{\#\#  [ 0.38  0.16]}
\CommentTok{\#\#  [ 0.88 {-}0.65]}
\CommentTok{\#\#  [ 0.09  0.16]}
\CommentTok{\#\#  [{-}1.89 {-}1.29]}
\CommentTok{\#\#  [{-}0.11  0.3 ]}
\CommentTok{\#\#  [{-}0.21 {-}0.28]}
\CommentTok{\#\#  [ 0.28 {-}0.51]}
\CommentTok{\#\#  [{-}0.21  1.61]}
\CommentTok{\#\#  [ 0.98 {-}1.18]}
\CommentTok{\#\#  [{-}0.21  1.64]}
\CommentTok{\#\#  [ 1.27  1.87]}
\CommentTok{\#\#  [{-}1.1  {-}0.36]}
\CommentTok{\#\#  [{-}0.01  0.04]}
\CommentTok{\#\#  [ 0.09 {-}0.25]}
\CommentTok{\#\#  [{-}1.6  {-}1.23]}
\CommentTok{\#\#  [{-}0.51 {-}0.28]}
\CommentTok{\#\#  [ 0.98  0.13]}
\CommentTok{\#\#  [ 1.97 {-}1.35]}
\CommentTok{\#\#  [ 1.47  0.07]}
\CommentTok{\#\#  [{-}0.61  1.37]}
\CommentTok{\#\#  [ 1.57  0.01]}
\CommentTok{\#\#  [{-}0.8   0.3 ]}
\CommentTok{\#\#  [ 1.97  0.74]}
\CommentTok{\#\#  [{-}1.2  {-}0.51]}
\CommentTok{\#\#  [ 0.68  0.27]}
\CommentTok{\#\#  [{-}1.4  {-}0.42]}
\CommentTok{\#\#  [ 0.19  0.16]}
\CommentTok{\#\#  [{-}0.51 {-}1.21]}
\CommentTok{\#\#  [ 0.58  2.01]}
\CommentTok{\#\#  [{-}1.6  {-}1.5 ]}
\CommentTok{\#\#  [{-}0.51 {-}0.54]}
\CommentTok{\#\#  [ 0.48  1.84]}
\CommentTok{\#\#  [{-}1.4  {-}1.09]}
\CommentTok{\#\#  [ 0.78 {-}1.38]}
\CommentTok{\#\#  [{-}0.31 {-}0.42]}
\CommentTok{\#\#  [ 1.57  1.  ]}
\CommentTok{\#\#  [ 0.98  1.43]}
\CommentTok{\#\#  [{-}0.31 {-}0.48]}
\CommentTok{\#\#  [{-}0.11  2.16]}
\CommentTok{\#\#  [{-}1.5  {-}0.1 ]}
\CommentTok{\#\#  [{-}0.11  1.95]}
\CommentTok{\#\#  [{-}0.71 {-}0.34]}
\CommentTok{\#\#  [{-}0.51 {-}0.83]}
\CommentTok{\#\#  [ 0.68 {-}1.38]}
\CommentTok{\#\#  [{-}0.8  {-}1.58]}
\CommentTok{\#\#  [{-}1.89 {-}1.47]}
\CommentTok{\#\#  [ 1.08  0.13]}
\CommentTok{\#\#  [ 0.09  1.52]}
\CommentTok{\#\#  [{-}0.31  0.1 ]}
\CommentTok{\#\#  [ 0.09  0.04]}
\CommentTok{\#\#  [{-}1.4  {-}1.35]}
\CommentTok{\#\#  [ 0.28  0.07]}
\CommentTok{\#\#  [{-}0.9   0.39]}
\CommentTok{\#\#  [ 1.57 {-}1.26]}
\CommentTok{\#\#  [{-}0.31 {-}0.74]}
\CommentTok{\#\#  [{-}0.11  0.16]}
\CommentTok{\#\#  [{-}0.9  {-}0.65]}
\CommentTok{\#\#  [{-}0.71 {-}0.05]}
\CommentTok{\#\#  [ 0.38 {-}0.45]}
\CommentTok{\#\#  [{-}0.8   1.9 ]}
\CommentTok{\#\#  [ 1.37  1.29]}
\CommentTok{\#\#  [ 1.18 {-}0.97]}
\CommentTok{\#\#  [ 1.77  1.84]}
\CommentTok{\#\#  [{-}0.9  {-}0.25]}
\CommentTok{\#\#  [{-}0.8   0.56]}
\CommentTok{\#\#  [{-}1.2  {-}1.55]}
\CommentTok{\#\#  [{-}0.51 {-}1.12]}
\CommentTok{\#\#  [ 0.28  0.07]}
\CommentTok{\#\#  [{-}0.21 {-}1.06]}
\CommentTok{\#\#  [ 1.67  1.61]}
\CommentTok{\#\#  [ 0.98  1.78]}
\CommentTok{\#\#  [ 0.28  0.04]}
\CommentTok{\#\#  [{-}0.8  {-}0.22]}
\CommentTok{\#\#  [{-}0.11  0.07]}
\CommentTok{\#\#  [ 0.28 {-}0.19]}
\CommentTok{\#\#  [ 1.97 {-}0.65]}
\CommentTok{\#\#  [{-}0.8   1.35]}
\CommentTok{\#\#  [{-}1.8  {-}0.6 ]}
\CommentTok{\#\#  [{-}0.11  0.13]}
\CommentTok{\#\#  [ 0.28 {-}0.31]}
\CommentTok{\#\#  [ 1.08  0.56]}
\CommentTok{\#\#  [{-}1.    0.27]}
\CommentTok{\#\#  [ 1.47  0.36]}
\CommentTok{\#\#  [ 0.19 {-}0.36]}
\CommentTok{\#\#  [ 2.17 {-}1.03]}
\CommentTok{\#\#  [{-}0.31  1.11]}
\CommentTok{\#\#  [{-}1.7   0.07]}
\CommentTok{\#\#  [{-}0.01  0.04]}
\CommentTok{\#\#  [ 0.09  1.06]}
\CommentTok{\#\#  [{-}0.11 {-}0.36]}
\CommentTok{\#\#  [{-}1.2   0.07]}
\CommentTok{\#\#  [{-}0.31 {-}1.35]}
\CommentTok{\#\#  [ 1.57  1.11]}
\CommentTok{\#\#  [{-}0.8  {-}1.52]}
\CommentTok{\#\#  [ 0.09  1.87]}
\CommentTok{\#\#  [{-}0.9  {-}0.77]}
\CommentTok{\#\#  [{-}0.51 {-}0.77]}
\CommentTok{\#\#  [{-}0.31 {-}0.92]}
\CommentTok{\#\#  [ 0.28 {-}0.71]}
\CommentTok{\#\#  [ 0.28  0.07]}
\CommentTok{\#\#  [ 0.09  1.87]}
\CommentTok{\#\#  [{-}1.1   1.95]}
\CommentTok{\#\#  [{-}1.7  {-}1.55]}
\CommentTok{\#\#  [{-}1.2  {-}1.09]}
\CommentTok{\#\#  [{-}0.71 {-}0.1 ]}
\CommentTok{\#\#  [ 0.09  0.1 ]}
\CommentTok{\#\#  [ 0.28  0.27]}
\CommentTok{\#\#  [ 0.88 {-}0.57]}
\CommentTok{\#\#  [ 0.28 {-}1.15]}
\CommentTok{\#\#  [{-}0.11  0.68]}
\CommentTok{\#\#  [ 2.17 {-}0.68]}
\CommentTok{\#\#  [{-}1.3  {-}1.38]}
\CommentTok{\#\#  [{-}1.   {-}0.94]}
\CommentTok{\#\#  [{-}0.01 {-}0.42]}
\CommentTok{\#\#  [{-}0.21 {-}0.45]}
\CommentTok{\#\#  [{-}1.8  {-}0.97]}
\CommentTok{\#\#  [ 1.77  1.  ]}
\CommentTok{\#\#  [ 0.19 {-}0.36]}
\CommentTok{\#\#  [ 0.38  1.11]}
\CommentTok{\#\#  [{-}1.8  {-}1.35]}
\CommentTok{\#\#  [ 0.19 {-}0.13]}
\CommentTok{\#\#  [ 0.88 {-}1.44]}
\CommentTok{\#\#  [{-}1.99  0.48]}
\CommentTok{\#\#  [{-}0.31  0.27]}
\CommentTok{\#\#  [ 1.87 {-}1.06]}
\CommentTok{\#\#  [{-}0.41  0.07]}
\CommentTok{\#\#  [ 1.08 {-}0.89]}
\CommentTok{\#\#  [{-}1.1  {-}1.12]}
\CommentTok{\#\#  [{-}1.89  0.01]}
\CommentTok{\#\#  [ 0.09  0.27]}
\CommentTok{\#\#  [{-}1.2   0.33]}
\CommentTok{\#\#  [{-}1.3   0.3 ]}
\CommentTok{\#\#  [{-}1.    0.45]}
\CommentTok{\#\#  [ 1.67 {-}0.89]}
\CommentTok{\#\#  [ 1.18  0.53]}
\CommentTok{\#\#  [ 1.08  0.53]}
\CommentTok{\#\#  [ 1.37  2.33]}
\CommentTok{\#\#  [{-}0.31 {-}0.13]}
\CommentTok{\#\#  [ 0.38 {-}0.45]}
\CommentTok{\#\#  [{-}0.41 {-}0.77]}
\CommentTok{\#\#  [{-}0.11 {-}0.51]}
\CommentTok{\#\#  [ 0.98 {-}1.15]}
\CommentTok{\#\#  [{-}0.9  {-}0.77]}
\CommentTok{\#\#  [{-}0.21 {-}0.51]}
\CommentTok{\#\#  [{-}1.1  {-}0.45]}
\CommentTok{\#\#  [{-}1.2   1.4 ]]}
\BuiltInTok{print}\NormalTok{(X\_test)}
\CommentTok{\#\# [[{-}0.8   0.5 ]}
\CommentTok{\#\#  [{-}0.01 {-}0.57]}
\CommentTok{\#\#  [{-}0.31  0.16]}
\CommentTok{\#\#  [{-}0.8   0.27]}
\CommentTok{\#\#  [{-}0.31 {-}0.57]}
\CommentTok{\#\#  [{-}1.1  {-}1.44]}
\CommentTok{\#\#  [{-}0.71 {-}1.58]}
\CommentTok{\#\#  [{-}0.21  2.16]}
\CommentTok{\#\#  [{-}1.99 {-}0.05]}
\CommentTok{\#\#  [ 0.88 {-}0.77]}
\CommentTok{\#\#  [{-}0.8  {-}0.6 ]}
\CommentTok{\#\#  [{-}1.   {-}0.42]}
\CommentTok{\#\#  [{-}0.11 {-}0.42]}
\CommentTok{\#\#  [ 0.09  0.22]}
\CommentTok{\#\#  [{-}1.8   0.48]}
\CommentTok{\#\#  [{-}0.61  1.37]}
\CommentTok{\#\#  [{-}0.11  0.22]}
\CommentTok{\#\#  [{-}1.89  0.45]}
\CommentTok{\#\#  [ 1.67  1.75]}
\CommentTok{\#\#  [{-}0.31 {-}1.38]}
\CommentTok{\#\#  [{-}0.31 {-}0.65]}
\CommentTok{\#\#  [ 0.88  2.16]}
\CommentTok{\#\#  [ 0.28 {-}0.54]}
\CommentTok{\#\#  [ 0.88  1.03]}
\CommentTok{\#\#  [{-}1.5  {-}1.21]}
\CommentTok{\#\#  [ 1.08  2.07]}
\CommentTok{\#\#  [{-}1.    0.5 ]}
\CommentTok{\#\#  [{-}0.9   0.3 ]}
\CommentTok{\#\#  [{-}0.11 {-}0.22]}
\CommentTok{\#\#  [{-}0.61  0.48]}
\CommentTok{\#\#  [{-}1.7   0.53]}
\CommentTok{\#\#  [{-}0.11  0.27]}
\CommentTok{\#\#  [ 1.87 {-}0.28]}
\CommentTok{\#\#  [{-}0.11 {-}0.48]}
\CommentTok{\#\#  [{-}1.4  {-}0.34]}
\CommentTok{\#\#  [{-}1.99 {-}0.51]}
\CommentTok{\#\#  [{-}1.6   0.33]}
\CommentTok{\#\#  [{-}0.41 {-}0.77]}
\CommentTok{\#\#  [{-}0.71 {-}1.03]}
\CommentTok{\#\#  [ 1.08 {-}0.97]}
\CommentTok{\#\#  [{-}1.1   0.53]}
\CommentTok{\#\#  [ 0.28 {-}0.51]}
\CommentTok{\#\#  [{-}1.1   0.42]}
\CommentTok{\#\#  [{-}0.31 {-}1.44]}
\CommentTok{\#\#  [ 0.48  1.23]}
\CommentTok{\#\#  [{-}1.1  {-}0.34]}
\CommentTok{\#\#  [{-}0.11  0.3 ]}
\CommentTok{\#\#  [ 1.37  0.59]}
\CommentTok{\#\#  [{-}1.2  {-}1.15]}
\CommentTok{\#\#  [ 1.08  0.48]}
\CommentTok{\#\#  [ 1.87  1.52]}
\CommentTok{\#\#  [{-}0.41 {-}1.29]}
\CommentTok{\#\#  [{-}0.31 {-}0.36]}
\CommentTok{\#\#  [{-}0.41  1.32]}
\CommentTok{\#\#  [ 2.07  0.53]}
\CommentTok{\#\#  [ 0.68 {-}1.09]}
\CommentTok{\#\#  [{-}0.9   0.39]}
\CommentTok{\#\#  [{-}1.2   0.3 ]}
\CommentTok{\#\#  [ 1.08 {-}1.21]}
\CommentTok{\#\#  [{-}1.5  {-}1.44]}
\CommentTok{\#\#  [{-}0.61 {-}1.5 ]}
\CommentTok{\#\#  [ 2.17 {-}0.8 ]}
\CommentTok{\#\#  [{-}1.89  0.19]}
\CommentTok{\#\#  [{-}0.21  0.85]}
\CommentTok{\#\#  [{-}1.89 {-}1.26]}
\CommentTok{\#\#  [ 2.17  0.39]}
\CommentTok{\#\#  [{-}1.4   0.56]}
\CommentTok{\#\#  [{-}1.1  {-}0.34]}
\CommentTok{\#\#  [ 0.19 {-}0.65]}
\CommentTok{\#\#  [ 0.38  0.01]}
\CommentTok{\#\#  [{-}0.61  2.33]}
\CommentTok{\#\#  [{-}0.31  0.22]}
\CommentTok{\#\#  [{-}1.6  {-}0.19]}
\CommentTok{\#\#  [ 0.68 {-}1.38]}
\CommentTok{\#\#  [{-}1.1   0.56]}
\CommentTok{\#\#  [{-}1.99  0.36]}
\CommentTok{\#\#  [ 0.38  0.27]}
\CommentTok{\#\#  [ 0.19 {-}0.28]}
\CommentTok{\#\#  [ 1.47 {-}1.03]}
\CommentTok{\#\#  [ 0.88  1.08]}
\CommentTok{\#\#  [ 1.97  2.16]}
\CommentTok{\#\#  [ 2.07  0.39]}
\CommentTok{\#\#  [{-}1.4  {-}0.42]}
\CommentTok{\#\#  [{-}1.2  {-}1.  ]}
\CommentTok{\#\#  [ 1.97 {-}0.92]}
\CommentTok{\#\#  [ 0.38  0.3 ]}
\CommentTok{\#\#  [ 0.19  0.16]}
\CommentTok{\#\#  [ 2.07  1.75]}
\CommentTok{\#\#  [ 0.78 {-}0.83]}
\CommentTok{\#\#  [ 0.28 {-}0.28]}
\CommentTok{\#\#  [ 0.38 {-}0.16]}
\CommentTok{\#\#  [{-}0.11  2.22]}
\CommentTok{\#\#  [{-}1.5  {-}0.63]}
\CommentTok{\#\#  [{-}1.3  {-}1.06]}
\CommentTok{\#\#  [{-}1.4   0.42]}
\CommentTok{\#\#  [{-}1.1   0.77]}
\CommentTok{\#\#  [{-}1.5  {-}0.19]}
\CommentTok{\#\#  [ 0.98 {-}1.06]}
\CommentTok{\#\#  [ 0.98  0.59]}
\CommentTok{\#\#  [ 0.38  1.  ]]}
\end{Highlighting}
\end{Shaded}

R

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{training\_set[}\SpecialCharTok{{-}}\DecValTok{3}\NormalTok{] }\OtherTok{=} \FunctionTok{scale}\NormalTok{(training\_set[}\SpecialCharTok{{-}}\DecValTok{3}\NormalTok{])}
\NormalTok{test\_set[}\SpecialCharTok{{-}}\DecValTok{3}\NormalTok{] }\OtherTok{=} \FunctionTok{scale}\NormalTok{(test\_set[}\SpecialCharTok{{-}}\DecValTok{3}\NormalTok{])}
\end{Highlighting}
\end{Shaded}

\hypertarget{training-the-naive-bayes-model-on-the-training-set}{%
\subsection{Training the Naive Bayes model on the Training set}\label{training-the-naive-bayes-model-on-the-training-set}}

Python

\begin{Shaded}
\begin{Highlighting}[]
\ImportTok{from}\NormalTok{ sklearn.naive\_bayes }\ImportTok{import}\NormalTok{ GaussianNB}
\NormalTok{classifier }\OperatorTok{=}\NormalTok{ GaussianNB()}
\NormalTok{classifier.fit(X\_train, y\_train)}
\CommentTok{\#\# GaussianNB()}
\end{Highlighting}
\end{Shaded}

R

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\# install.packages(\textquotesingle{}e1071\textquotesingle{})}
\FunctionTok{library}\NormalTok{(e1071)}
\NormalTok{classifier }\OtherTok{=} \FunctionTok{naiveBayes}\NormalTok{(}\AttributeTok{x =}\NormalTok{ training\_set[}\SpecialCharTok{{-}}\DecValTok{3}\NormalTok{],}
                        \AttributeTok{y =}\NormalTok{ training\_set}\SpecialCharTok{$}\NormalTok{Purchased)}
\end{Highlighting}
\end{Shaded}

\hypertarget{predicting-a-new-result-7}{%
\subsection{Predicting a new result}\label{predicting-a-new-result-7}}

Python

\begin{Shaded}
\begin{Highlighting}[]
\BuiltInTok{print}\NormalTok{(classifier.predict(sc.transform([[}\DecValTok{30}\NormalTok{,}\DecValTok{87000}\NormalTok{]])))}
\CommentTok{\#\# [0]}
\end{Highlighting}
\end{Shaded}

\hypertarget{predicting-the-test-set-results-6}{%
\subsection{Predicting the Test set results}\label{predicting-the-test-set-results-6}}

Python

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{y\_pred }\OperatorTok{=}\NormalTok{ classifier.predict(X\_test)}
\BuiltInTok{print}\NormalTok{(np.concatenate((y\_pred.reshape(}\BuiltInTok{len}\NormalTok{(y\_pred),}\DecValTok{1}\NormalTok{), y\_test.reshape(}\BuiltInTok{len}\NormalTok{(y\_test),}\DecValTok{1}\NormalTok{)),}\DecValTok{1}\NormalTok{))}
\CommentTok{\#\# [[0 0]}
\CommentTok{\#\#  [0 0]}
\CommentTok{\#\#  [0 0]}
\CommentTok{\#\#  [0 0]}
\CommentTok{\#\#  [0 0]}
\CommentTok{\#\#  [0 0]}
\CommentTok{\#\#  [0 0]}
\CommentTok{\#\#  [1 1]}
\CommentTok{\#\#  [0 0]}
\CommentTok{\#\#  [1 0]}
\CommentTok{\#\#  [0 0]}
\CommentTok{\#\#  [0 0]}
\CommentTok{\#\#  [0 0]}
\CommentTok{\#\#  [0 0]}
\CommentTok{\#\#  [0 0]}
\CommentTok{\#\#  [0 0]}
\CommentTok{\#\#  [0 0]}
\CommentTok{\#\#  [0 0]}
\CommentTok{\#\#  [1 1]}
\CommentTok{\#\#  [0 0]}
\CommentTok{\#\#  [0 0]}
\CommentTok{\#\#  [1 1]}
\CommentTok{\#\#  [0 0]}
\CommentTok{\#\#  [1 1]}
\CommentTok{\#\#  [0 0]}
\CommentTok{\#\#  [1 1]}
\CommentTok{\#\#  [0 0]}
\CommentTok{\#\#  [0 0]}
\CommentTok{\#\#  [0 0]}
\CommentTok{\#\#  [0 0]}
\CommentTok{\#\#  [0 0]}
\CommentTok{\#\#  [0 1]}
\CommentTok{\#\#  [1 1]}
\CommentTok{\#\#  [0 0]}
\CommentTok{\#\#  [0 0]}
\CommentTok{\#\#  [0 0]}
\CommentTok{\#\#  [0 0]}
\CommentTok{\#\#  [0 0]}
\CommentTok{\#\#  [0 0]}
\CommentTok{\#\#  [1 1]}
\CommentTok{\#\#  [0 0]}
\CommentTok{\#\#  [0 0]}
\CommentTok{\#\#  [0 0]}
\CommentTok{\#\#  [0 0]}
\CommentTok{\#\#  [1 1]}
\CommentTok{\#\#  [0 0]}
\CommentTok{\#\#  [0 0]}
\CommentTok{\#\#  [1 1]}
\CommentTok{\#\#  [0 0]}
\CommentTok{\#\#  [1 1]}
\CommentTok{\#\#  [1 1]}
\CommentTok{\#\#  [0 0]}
\CommentTok{\#\#  [0 0]}
\CommentTok{\#\#  [1 0]}
\CommentTok{\#\#  [1 1]}
\CommentTok{\#\#  [0 1]}
\CommentTok{\#\#  [0 0]}
\CommentTok{\#\#  [0 0]}
\CommentTok{\#\#  [1 1]}
\CommentTok{\#\#  [0 0]}
\CommentTok{\#\#  [0 0]}
\CommentTok{\#\#  [1 1]}
\CommentTok{\#\#  [0 0]}
\CommentTok{\#\#  [0 1]}
\CommentTok{\#\#  [0 0]}
\CommentTok{\#\#  [1 1]}
\CommentTok{\#\#  [0 0]}
\CommentTok{\#\#  [0 0]}
\CommentTok{\#\#  [0 0]}
\CommentTok{\#\#  [0 0]}
\CommentTok{\#\#  [1 1]}
\CommentTok{\#\#  [0 0]}
\CommentTok{\#\#  [0 0]}
\CommentTok{\#\#  [0 1]}
\CommentTok{\#\#  [0 0]}
\CommentTok{\#\#  [0 0]}
\CommentTok{\#\#  [0 0]}
\CommentTok{\#\#  [0 0]}
\CommentTok{\#\#  [1 1]}
\CommentTok{\#\#  [1 1]}
\CommentTok{\#\#  [1 1]}
\CommentTok{\#\#  [1 0]}
\CommentTok{\#\#  [0 0]}
\CommentTok{\#\#  [0 0]}
\CommentTok{\#\#  [1 1]}
\CommentTok{\#\#  [0 1]}
\CommentTok{\#\#  [0 0]}
\CommentTok{\#\#  [1 1]}
\CommentTok{\#\#  [0 1]}
\CommentTok{\#\#  [0 0]}
\CommentTok{\#\#  [0 0]}
\CommentTok{\#\#  [1 1]}
\CommentTok{\#\#  [0 0]}
\CommentTok{\#\#  [0 0]}
\CommentTok{\#\#  [0 0]}
\CommentTok{\#\#  [0 1]}
\CommentTok{\#\#  [0 0]}
\CommentTok{\#\#  [1 1]}
\CommentTok{\#\#  [1 1]}
\CommentTok{\#\#  [1 1]]}
\end{Highlighting}
\end{Shaded}

R

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{y\_pred }\OtherTok{=} \FunctionTok{predict}\NormalTok{(classifier, }\AttributeTok{newdata =}\NormalTok{ test\_set[}\SpecialCharTok{{-}}\DecValTok{3}\NormalTok{])}
\end{Highlighting}
\end{Shaded}

\hypertarget{making-the-confusion-matrix-4}{%
\subsection{Making the Confusion Matrix}\label{making-the-confusion-matrix-4}}

Python

\begin{Shaded}
\begin{Highlighting}[]
\ImportTok{from}\NormalTok{ sklearn.metrics }\ImportTok{import}\NormalTok{ confusion\_matrix, accuracy\_score}
\NormalTok{cm }\OperatorTok{=}\NormalTok{ confusion\_matrix(y\_test, y\_pred)}
\BuiltInTok{print}\NormalTok{(cm)}
\CommentTok{\#\# [[65  3]}
\CommentTok{\#\#  [ 7 25]]}
\NormalTok{accuracy\_score(y\_test, y\_pred)}
\CommentTok{\#\# 0.9}
\end{Highlighting}
\end{Shaded}

R

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{cm }\OtherTok{=} \FunctionTok{table}\NormalTok{(test\_set[, }\DecValTok{3}\NormalTok{], y\_pred)}
\end{Highlighting}
\end{Shaded}

\hypertarget{visualising-the-training-set-results-5}{%
\subsection{Visualising the Training set results}\label{visualising-the-training-set-results-5}}

Python

\begin{Shaded}
\begin{Highlighting}[]
\ImportTok{from}\NormalTok{ matplotlib.colors }\ImportTok{import}\NormalTok{ ListedColormap}
\NormalTok{X\_set, y\_set }\OperatorTok{=}\NormalTok{ sc.inverse\_transform(X\_train), y\_train}
\NormalTok{X1, X2 }\OperatorTok{=}\NormalTok{ np.meshgrid(np.arange(start }\OperatorTok{=}\NormalTok{ X\_set[:, }\DecValTok{0}\NormalTok{].}\BuiltInTok{min}\NormalTok{() }\OperatorTok{{-}} \DecValTok{10}\NormalTok{, stop }\OperatorTok{=}\NormalTok{ X\_set[:, }\DecValTok{0}\NormalTok{].}\BuiltInTok{max}\NormalTok{() }\OperatorTok{+} \DecValTok{10}\NormalTok{, step }\OperatorTok{=} \FloatTok{0.25}\NormalTok{),}
\NormalTok{                     np.arange(start }\OperatorTok{=}\NormalTok{ X\_set[:, }\DecValTok{1}\NormalTok{].}\BuiltInTok{min}\NormalTok{() }\OperatorTok{{-}} \DecValTok{1000}\NormalTok{, stop }\OperatorTok{=}\NormalTok{ X\_set[:, }\DecValTok{1}\NormalTok{].}\BuiltInTok{max}\NormalTok{() }\OperatorTok{+} \DecValTok{1000}\NormalTok{, step }\OperatorTok{=} \FloatTok{0.25}\NormalTok{))}
\NormalTok{plt.contourf(X1, X2, classifier.predict(sc.transform(np.array([X1.ravel(), X2.ravel()]).T)).reshape(X1.shape),}
\NormalTok{             alpha }\OperatorTok{=} \FloatTok{0.75}\NormalTok{, cmap }\OperatorTok{=}\NormalTok{ ListedColormap((}\StringTok{\textquotesingle{}red\textquotesingle{}}\NormalTok{, }\StringTok{\textquotesingle{}green\textquotesingle{}}\NormalTok{)))}
\NormalTok{plt.xlim(X1.}\BuiltInTok{min}\NormalTok{(), X1.}\BuiltInTok{max}\NormalTok{())}
\NormalTok{plt.ylim(X2.}\BuiltInTok{min}\NormalTok{(), X2.}\BuiltInTok{max}\NormalTok{())}
\ControlFlowTok{for}\NormalTok{ i, j }\KeywordTok{in} \BuiltInTok{enumerate}\NormalTok{(np.unique(y\_set)):}
\NormalTok{    plt.scatter(X\_set[y\_set }\OperatorTok{==}\NormalTok{ j, }\DecValTok{0}\NormalTok{], X\_set[y\_set }\OperatorTok{==}\NormalTok{ j, }\DecValTok{1}\NormalTok{], c }\OperatorTok{=}\NormalTok{ ListedColormap((}\StringTok{\textquotesingle{}red\textquotesingle{}}\NormalTok{, }\StringTok{\textquotesingle{}green\textquotesingle{}}\NormalTok{))(i), label }\OperatorTok{=}\NormalTok{ j)}
\NormalTok{plt.title(}\StringTok{\textquotesingle{}Naive Bayes (Training set)\textquotesingle{}}\NormalTok{)}
\NormalTok{plt.xlabel(}\StringTok{\textquotesingle{}Age\textquotesingle{}}\NormalTok{)}
\NormalTok{plt.ylabel(}\StringTok{\textquotesingle{}Estimated Salary\textquotesingle{}}\NormalTok{)}
\NormalTok{plt.legend()}
\NormalTok{plt.show()}
\end{Highlighting}
\end{Shaded}

R

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{library}\NormalTok{(ElemStatLearn)}
\NormalTok{set }\OtherTok{=}\NormalTok{ training\_set}
\NormalTok{X1 }\OtherTok{=} \FunctionTok{seq}\NormalTok{(}\FunctionTok{min}\NormalTok{(set[, }\DecValTok{1}\NormalTok{]) }\SpecialCharTok{{-}} \DecValTok{1}\NormalTok{, }\FunctionTok{max}\NormalTok{(set[, }\DecValTok{1}\NormalTok{]) }\SpecialCharTok{+} \DecValTok{1}\NormalTok{, }\AttributeTok{by =} \FloatTok{0.01}\NormalTok{)}
\NormalTok{X2 }\OtherTok{=} \FunctionTok{seq}\NormalTok{(}\FunctionTok{min}\NormalTok{(set[, }\DecValTok{2}\NormalTok{]) }\SpecialCharTok{{-}} \DecValTok{1}\NormalTok{, }\FunctionTok{max}\NormalTok{(set[, }\DecValTok{2}\NormalTok{]) }\SpecialCharTok{+} \DecValTok{1}\NormalTok{, }\AttributeTok{by =} \FloatTok{0.01}\NormalTok{)}
\NormalTok{grid\_set }\OtherTok{=} \FunctionTok{expand.grid}\NormalTok{(X1, X2)}
\FunctionTok{colnames}\NormalTok{(grid\_set) }\OtherTok{=} \FunctionTok{c}\NormalTok{(}\StringTok{\textquotesingle{}Age\textquotesingle{}}\NormalTok{, }\StringTok{\textquotesingle{}EstimatedSalary\textquotesingle{}}\NormalTok{)}
\NormalTok{y\_grid }\OtherTok{=} \FunctionTok{predict}\NormalTok{(classifier, }\AttributeTok{newdata =}\NormalTok{ grid\_set)}
\FunctionTok{plot}\NormalTok{(set[, }\SpecialCharTok{{-}}\DecValTok{3}\NormalTok{],}
     \AttributeTok{main =} \StringTok{\textquotesingle{}Naive Bayes (Training set)\textquotesingle{}}\NormalTok{,}
     \AttributeTok{xlab =} \StringTok{\textquotesingle{}Age\textquotesingle{}}\NormalTok{, }\AttributeTok{ylab =} \StringTok{\textquotesingle{}Estimated Salary\textquotesingle{}}\NormalTok{,}
     \AttributeTok{xlim =} \FunctionTok{range}\NormalTok{(X1), }\AttributeTok{ylim =} \FunctionTok{range}\NormalTok{(X2))}
\FunctionTok{contour}\NormalTok{(X1, X2, }\FunctionTok{matrix}\NormalTok{(}\FunctionTok{as.numeric}\NormalTok{(y\_grid), }\FunctionTok{length}\NormalTok{(X1), }\FunctionTok{length}\NormalTok{(X2)), }\AttributeTok{add =} \ConstantTok{TRUE}\NormalTok{)}
\FunctionTok{points}\NormalTok{(grid\_set, }\AttributeTok{pch =} \StringTok{\textquotesingle{}.\textquotesingle{}}\NormalTok{, }\AttributeTok{col =} \FunctionTok{ifelse}\NormalTok{(y\_grid }\SpecialCharTok{==} \DecValTok{1}\NormalTok{, }\StringTok{\textquotesingle{}springgreen3\textquotesingle{}}\NormalTok{, }\StringTok{\textquotesingle{}tomato\textquotesingle{}}\NormalTok{))}
\FunctionTok{points}\NormalTok{(set, }\AttributeTok{pch =} \DecValTok{21}\NormalTok{, }\AttributeTok{bg =} \FunctionTok{ifelse}\NormalTok{(set[, }\DecValTok{3}\NormalTok{] }\SpecialCharTok{==} \DecValTok{1}\NormalTok{, }\StringTok{\textquotesingle{}green4\textquotesingle{}}\NormalTok{, }\StringTok{\textquotesingle{}red3\textquotesingle{}}\NormalTok{))}
\end{Highlighting}
\end{Shaded}

\includegraphics{_main_files/figure-latex/unnamed-chunk-176-1.pdf}

\hypertarget{visualising-the-test-set-results-5}{%
\subsection{Visualising the Test set results}\label{visualising-the-test-set-results-5}}

Python

\begin{Shaded}
\begin{Highlighting}[]
\ImportTok{from}\NormalTok{ matplotlib.colors }\ImportTok{import}\NormalTok{ ListedColormap}
\NormalTok{X\_set, y\_set }\OperatorTok{=}\NormalTok{ sc.inverse\_transform(X\_test), y\_test}
\NormalTok{X1, X2 }\OperatorTok{=}\NormalTok{ np.meshgrid(np.arange(start }\OperatorTok{=}\NormalTok{ X\_set[:, }\DecValTok{0}\NormalTok{].}\BuiltInTok{min}\NormalTok{() }\OperatorTok{{-}} \DecValTok{10}\NormalTok{, stop }\OperatorTok{=}\NormalTok{ X\_set[:, }\DecValTok{0}\NormalTok{].}\BuiltInTok{max}\NormalTok{() }\OperatorTok{+} \DecValTok{10}\NormalTok{, step }\OperatorTok{=} \FloatTok{0.25}\NormalTok{),}
\NormalTok{                     np.arange(start }\OperatorTok{=}\NormalTok{ X\_set[:, }\DecValTok{1}\NormalTok{].}\BuiltInTok{min}\NormalTok{() }\OperatorTok{{-}} \DecValTok{1000}\NormalTok{, stop }\OperatorTok{=}\NormalTok{ X\_set[:, }\DecValTok{1}\NormalTok{].}\BuiltInTok{max}\NormalTok{() }\OperatorTok{+} \DecValTok{1000}\NormalTok{, step }\OperatorTok{=} \FloatTok{0.25}\NormalTok{))}
\NormalTok{plt.contourf(X1, X2, classifier.predict(sc.transform(np.array([X1.ravel(), X2.ravel()]).T)).reshape(X1.shape),}
\NormalTok{             alpha }\OperatorTok{=} \FloatTok{0.75}\NormalTok{, cmap }\OperatorTok{=}\NormalTok{ ListedColormap((}\StringTok{\textquotesingle{}red\textquotesingle{}}\NormalTok{, }\StringTok{\textquotesingle{}green\textquotesingle{}}\NormalTok{)))}
\NormalTok{plt.xlim(X1.}\BuiltInTok{min}\NormalTok{(), X1.}\BuiltInTok{max}\NormalTok{())}
\NormalTok{plt.ylim(X2.}\BuiltInTok{min}\NormalTok{(), X2.}\BuiltInTok{max}\NormalTok{())}
\ControlFlowTok{for}\NormalTok{ i, j }\KeywordTok{in} \BuiltInTok{enumerate}\NormalTok{(np.unique(y\_set)):}
\NormalTok{    plt.scatter(X\_set[y\_set }\OperatorTok{==}\NormalTok{ j, }\DecValTok{0}\NormalTok{], X\_set[y\_set }\OperatorTok{==}\NormalTok{ j, }\DecValTok{1}\NormalTok{], c }\OperatorTok{=}\NormalTok{ ListedColormap((}\StringTok{\textquotesingle{}red\textquotesingle{}}\NormalTok{, }\StringTok{\textquotesingle{}green\textquotesingle{}}\NormalTok{))(i), label }\OperatorTok{=}\NormalTok{ j)}
\NormalTok{plt.title(}\StringTok{\textquotesingle{}Naive Bayes (Test set)\textquotesingle{}}\NormalTok{)}
\NormalTok{plt.xlabel(}\StringTok{\textquotesingle{}Age\textquotesingle{}}\NormalTok{)}
\NormalTok{plt.ylabel(}\StringTok{\textquotesingle{}Estimated Salary\textquotesingle{}}\NormalTok{)}
\NormalTok{plt.legend()}
\NormalTok{plt.show()}
\end{Highlighting}
\end{Shaded}

R

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{library}\NormalTok{(ElemStatLearn)}
\NormalTok{set }\OtherTok{=}\NormalTok{ test\_set}
\NormalTok{X1 }\OtherTok{=} \FunctionTok{seq}\NormalTok{(}\FunctionTok{min}\NormalTok{(set[, }\DecValTok{1}\NormalTok{]) }\SpecialCharTok{{-}} \DecValTok{1}\NormalTok{, }\FunctionTok{max}\NormalTok{(set[, }\DecValTok{1}\NormalTok{]) }\SpecialCharTok{+} \DecValTok{1}\NormalTok{, }\AttributeTok{by =} \FloatTok{0.01}\NormalTok{)}
\NormalTok{X2 }\OtherTok{=} \FunctionTok{seq}\NormalTok{(}\FunctionTok{min}\NormalTok{(set[, }\DecValTok{2}\NormalTok{]) }\SpecialCharTok{{-}} \DecValTok{1}\NormalTok{, }\FunctionTok{max}\NormalTok{(set[, }\DecValTok{2}\NormalTok{]) }\SpecialCharTok{+} \DecValTok{1}\NormalTok{, }\AttributeTok{by =} \FloatTok{0.01}\NormalTok{)}
\NormalTok{grid\_set }\OtherTok{=} \FunctionTok{expand.grid}\NormalTok{(X1, X2)}
\FunctionTok{colnames}\NormalTok{(grid\_set) }\OtherTok{=} \FunctionTok{c}\NormalTok{(}\StringTok{\textquotesingle{}Age\textquotesingle{}}\NormalTok{, }\StringTok{\textquotesingle{}EstimatedSalary\textquotesingle{}}\NormalTok{)}
\NormalTok{y\_grid }\OtherTok{=} \FunctionTok{predict}\NormalTok{(classifier, }\AttributeTok{newdata =}\NormalTok{ grid\_set)}
\FunctionTok{plot}\NormalTok{(set[, }\SpecialCharTok{{-}}\DecValTok{3}\NormalTok{], }\AttributeTok{main =} \StringTok{\textquotesingle{}Naive Bayes (Test set)\textquotesingle{}}\NormalTok{,}
     \AttributeTok{xlab =} \StringTok{\textquotesingle{}Age\textquotesingle{}}\NormalTok{, }\AttributeTok{ylab =} \StringTok{\textquotesingle{}Estimated Salary\textquotesingle{}}\NormalTok{,}
     \AttributeTok{xlim =} \FunctionTok{range}\NormalTok{(X1), }\AttributeTok{ylim =} \FunctionTok{range}\NormalTok{(X2))}
\FunctionTok{contour}\NormalTok{(X1, X2, }\FunctionTok{matrix}\NormalTok{(}\FunctionTok{as.numeric}\NormalTok{(y\_grid), }\FunctionTok{length}\NormalTok{(X1), }\FunctionTok{length}\NormalTok{(X2)), }\AttributeTok{add =} \ConstantTok{TRUE}\NormalTok{)}
\FunctionTok{points}\NormalTok{(grid\_set, }\AttributeTok{pch =} \StringTok{\textquotesingle{}.\textquotesingle{}}\NormalTok{, }\AttributeTok{col =} \FunctionTok{ifelse}\NormalTok{(y\_grid }\SpecialCharTok{==} \DecValTok{1}\NormalTok{, }\StringTok{\textquotesingle{}springgreen3\textquotesingle{}}\NormalTok{, }\StringTok{\textquotesingle{}tomato\textquotesingle{}}\NormalTok{))}
\FunctionTok{points}\NormalTok{(set, }\AttributeTok{pch =} \DecValTok{21}\NormalTok{, }\AttributeTok{bg =} \FunctionTok{ifelse}\NormalTok{(set[, }\DecValTok{3}\NormalTok{] }\SpecialCharTok{==} \DecValTok{1}\NormalTok{, }\StringTok{\textquotesingle{}green4\textquotesingle{}}\NormalTok{, }\StringTok{\textquotesingle{}red3\textquotesingle{}}\NormalTok{))}
\end{Highlighting}
\end{Shaded}

\includegraphics{_main_files/figure-latex/unnamed-chunk-178-1.pdf}

\hypertarget{decision-tree-classification}{%
\section{Decision Tree Classification}\label{decision-tree-classification}}

\hypertarget{importing-the-libraries-12}{%
\subsection{Importing the libraries}\label{importing-the-libraries-12}}

Python

\begin{Shaded}
\begin{Highlighting}[]
\ImportTok{import}\NormalTok{ numpy }\ImportTok{as}\NormalTok{ np}
\ImportTok{import}\NormalTok{ matplotlib.pyplot }\ImportTok{as}\NormalTok{ plt}
\ImportTok{import}\NormalTok{ pandas }\ImportTok{as}\NormalTok{ pd}
\end{Highlighting}
\end{Shaded}

\hypertarget{importing-the-dataset-12}{%
\subsection{Importing the dataset}\label{importing-the-dataset-12}}

Python

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{dataset }\OperatorTok{=}\NormalTok{ pd.read\_csv(}\StringTok{\textquotesingle{}Social\_Network\_Ads.csv\textquotesingle{}}\NormalTok{)}
\NormalTok{X }\OperatorTok{=}\NormalTok{ dataset.iloc[:, :}\OperatorTok{{-}}\DecValTok{1}\NormalTok{].values}
\NormalTok{y }\OperatorTok{=}\NormalTok{ dataset.iloc[:, }\OperatorTok{{-}}\DecValTok{1}\NormalTok{].values}
\end{Highlighting}
\end{Shaded}

R

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{dataset }\OtherTok{=} \FunctionTok{read.csv}\NormalTok{(}\StringTok{\textquotesingle{}Social\_Network\_Ads.csv\textquotesingle{}}\NormalTok{)}
\CommentTok{\# dataset = dataset[3:5]}
\end{Highlighting}
\end{Shaded}

\hypertarget{encoding-the-target-feature-as-factor-5}{%
\subsection{Encoding the target feature as factor}\label{encoding-the-target-feature-as-factor-5}}

R

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{dataset}\SpecialCharTok{$}\NormalTok{Purchased }\OtherTok{=} \FunctionTok{factor}\NormalTok{(dataset}\SpecialCharTok{$}\NormalTok{Purchased, }\AttributeTok{levels =} \FunctionTok{c}\NormalTok{(}\DecValTok{0}\NormalTok{, }\DecValTok{1}\NormalTok{))}
\end{Highlighting}
\end{Shaded}

\hypertarget{splitting-the-dataset-into-the-training-set-and-test-set-8}{%
\subsection{Splitting the dataset into the Training set and Test set}\label{splitting-the-dataset-into-the-training-set-and-test-set-8}}

Python

\begin{Shaded}
\begin{Highlighting}[]
\ImportTok{from}\NormalTok{ sklearn.model\_selection }\ImportTok{import}\NormalTok{ train\_test\_split}
\NormalTok{X\_train, X\_test, y\_train, y\_test }\OperatorTok{=}\NormalTok{ train\_test\_split(X, y, test\_size }\OperatorTok{=} \FloatTok{0.25}\NormalTok{, random\_state }\OperatorTok{=} \DecValTok{0}\NormalTok{)}
\BuiltInTok{print}\NormalTok{(X\_train)}
\CommentTok{\#\# [[    44  39000]}
\CommentTok{\#\#  [    32 120000]}
\CommentTok{\#\#  [    38  50000]}
\CommentTok{\#\#  [    32 135000]}
\CommentTok{\#\#  [    52  21000]}
\CommentTok{\#\#  [    53 104000]}
\CommentTok{\#\#  [    39  42000]}
\CommentTok{\#\#  [    38  61000]}
\CommentTok{\#\#  [    36  50000]}
\CommentTok{\#\#  [    36  63000]}
\CommentTok{\#\#  [    35  25000]}
\CommentTok{\#\#  [    35  50000]}
\CommentTok{\#\#  [    42  73000]}
\CommentTok{\#\#  [    47  49000]}
\CommentTok{\#\#  [    59  29000]}
\CommentTok{\#\#  [    49  65000]}
\CommentTok{\#\#  [    45 131000]}
\CommentTok{\#\#  [    31  89000]}
\CommentTok{\#\#  [    46  82000]}
\CommentTok{\#\#  [    47  51000]}
\CommentTok{\#\#  [    26  15000]}
\CommentTok{\#\#  [    60 102000]}
\CommentTok{\#\#  [    38 112000]}
\CommentTok{\#\#  [    40 107000]}
\CommentTok{\#\#  [    42  53000]}
\CommentTok{\#\#  [    35  59000]}
\CommentTok{\#\#  [    48  41000]}
\CommentTok{\#\#  [    48 134000]}
\CommentTok{\#\#  [    38 113000]}
\CommentTok{\#\#  [    29 148000]}
\CommentTok{\#\#  [    26  15000]}
\CommentTok{\#\#  [    60  42000]}
\CommentTok{\#\#  [    24  19000]}
\CommentTok{\#\#  [    42 149000]}
\CommentTok{\#\#  [    46  96000]}
\CommentTok{\#\#  [    28  59000]}
\CommentTok{\#\#  [    39  96000]}
\CommentTok{\#\#  [    28  89000]}
\CommentTok{\#\#  [    41  72000]}
\CommentTok{\#\#  [    45  26000]}
\CommentTok{\#\#  [    33  69000]}
\CommentTok{\#\#  [    20  82000]}
\CommentTok{\#\#  [    31  74000]}
\CommentTok{\#\#  [    42  80000]}
\CommentTok{\#\#  [    35  72000]}
\CommentTok{\#\#  [    33 149000]}
\CommentTok{\#\#  [    40  71000]}
\CommentTok{\#\#  [    51 146000]}
\CommentTok{\#\#  [    46  79000]}
\CommentTok{\#\#  [    35  75000]}
\CommentTok{\#\#  [    38  51000]}
\CommentTok{\#\#  [    36  75000]}
\CommentTok{\#\#  [    37  78000]}
\CommentTok{\#\#  [    38  61000]}
\CommentTok{\#\#  [    60 108000]}
\CommentTok{\#\#  [    20  82000]}
\CommentTok{\#\#  [    57  74000]}
\CommentTok{\#\#  [    42  65000]}
\CommentTok{\#\#  [    26  80000]}
\CommentTok{\#\#  [    46 117000]}
\CommentTok{\#\#  [    35  61000]}
\CommentTok{\#\#  [    21  68000]}
\CommentTok{\#\#  [    28  44000]}
\CommentTok{\#\#  [    41  87000]}
\CommentTok{\#\#  [    37  33000]}
\CommentTok{\#\#  [    27  90000]}
\CommentTok{\#\#  [    39  42000]}
\CommentTok{\#\#  [    28 123000]}
\CommentTok{\#\#  [    31 118000]}
\CommentTok{\#\#  [    25  87000]}
\CommentTok{\#\#  [    35  71000]}
\CommentTok{\#\#  [    37  70000]}
\CommentTok{\#\#  [    35  39000]}
\CommentTok{\#\#  [    47  23000]}
\CommentTok{\#\#  [    35 147000]}
\CommentTok{\#\#  [    48 138000]}
\CommentTok{\#\#  [    26  86000]}
\CommentTok{\#\#  [    25  79000]}
\CommentTok{\#\#  [    52 138000]}
\CommentTok{\#\#  [    51  23000]}
\CommentTok{\#\#  [    35  60000]}
\CommentTok{\#\#  [    33 113000]}
\CommentTok{\#\#  [    30 107000]}
\CommentTok{\#\#  [    48  33000]}
\CommentTok{\#\#  [    41  80000]}
\CommentTok{\#\#  [    48  96000]}
\CommentTok{\#\#  [    31  18000]}
\CommentTok{\#\#  [    31  71000]}
\CommentTok{\#\#  [    43 129000]}
\CommentTok{\#\#  [    59  76000]}
\CommentTok{\#\#  [    18  44000]}
\CommentTok{\#\#  [    36 118000]}
\CommentTok{\#\#  [    42  90000]}
\CommentTok{\#\#  [    47  30000]}
\CommentTok{\#\#  [    26  43000]}
\CommentTok{\#\#  [    40  78000]}
\CommentTok{\#\#  [    46  59000]}
\CommentTok{\#\#  [    59  42000]}
\CommentTok{\#\#  [    46  74000]}
\CommentTok{\#\#  [    35  91000]}
\CommentTok{\#\#  [    28  59000]}
\CommentTok{\#\#  [    40  57000]}
\CommentTok{\#\#  [    59 143000]}
\CommentTok{\#\#  [    57  26000]}
\CommentTok{\#\#  [    52  38000]}
\CommentTok{\#\#  [    47 113000]}
\CommentTok{\#\#  [    53 143000]}
\CommentTok{\#\#  [    35  27000]}
\CommentTok{\#\#  [    58 101000]}
\CommentTok{\#\#  [    45  45000]}
\CommentTok{\#\#  [    23  82000]}
\CommentTok{\#\#  [    46  23000]}
\CommentTok{\#\#  [    42  65000]}
\CommentTok{\#\#  [    28  84000]}
\CommentTok{\#\#  [    38  59000]}
\CommentTok{\#\#  [    26  84000]}
\CommentTok{\#\#  [    29  28000]}
\CommentTok{\#\#  [    37  71000]}
\CommentTok{\#\#  [    22  55000]}
\CommentTok{\#\#  [    48  35000]}
\CommentTok{\#\#  [    49  28000]}
\CommentTok{\#\#  [    38  65000]}
\CommentTok{\#\#  [    27  17000]}
\CommentTok{\#\#  [    46  28000]}
\CommentTok{\#\#  [    48 141000]}
\CommentTok{\#\#  [    26  17000]}
\CommentTok{\#\#  [    35  97000]}
\CommentTok{\#\#  [    39  59000]}
\CommentTok{\#\#  [    24  27000]}
\CommentTok{\#\#  [    32  18000]}
\CommentTok{\#\#  [    46  88000]}
\CommentTok{\#\#  [    35  58000]}
\CommentTok{\#\#  [    56  60000]}
\CommentTok{\#\#  [    47  34000]}
\CommentTok{\#\#  [    40  72000]}
\CommentTok{\#\#  [    32 100000]}
\CommentTok{\#\#  [    19  21000]}
\CommentTok{\#\#  [    25  90000]}
\CommentTok{\#\#  [    35  88000]}
\CommentTok{\#\#  [    28  32000]}
\CommentTok{\#\#  [    50  20000]}
\CommentTok{\#\#  [    40  59000]}
\CommentTok{\#\#  [    50  44000]}
\CommentTok{\#\#  [    35  72000]}
\CommentTok{\#\#  [    40 142000]}
\CommentTok{\#\#  [    46  32000]}
\CommentTok{\#\#  [    39  71000]}
\CommentTok{\#\#  [    20  74000]}
\CommentTok{\#\#  [    29  75000]}
\CommentTok{\#\#  [    31  76000]}
\CommentTok{\#\#  [    47  25000]}
\CommentTok{\#\#  [    40  61000]}
\CommentTok{\#\#  [    34 112000]}
\CommentTok{\#\#  [    38  80000]}
\CommentTok{\#\#  [    42  75000]}
\CommentTok{\#\#  [    47  47000]}
\CommentTok{\#\#  [    39  75000]}
\CommentTok{\#\#  [    19  25000]}
\CommentTok{\#\#  [    37  80000]}
\CommentTok{\#\#  [    36  60000]}
\CommentTok{\#\#  [    41  52000]}
\CommentTok{\#\#  [    36 125000]}
\CommentTok{\#\#  [    48  29000]}
\CommentTok{\#\#  [    36 126000]}
\CommentTok{\#\#  [    51 134000]}
\CommentTok{\#\#  [    27  57000]}
\CommentTok{\#\#  [    38  71000]}
\CommentTok{\#\#  [    39  61000]}
\CommentTok{\#\#  [    22  27000]}
\CommentTok{\#\#  [    33  60000]}
\CommentTok{\#\#  [    48  74000]}
\CommentTok{\#\#  [    58  23000]}
\CommentTok{\#\#  [    53  72000]}
\CommentTok{\#\#  [    32 117000]}
\CommentTok{\#\#  [    54  70000]}
\CommentTok{\#\#  [    30  80000]}
\CommentTok{\#\#  [    58  95000]}
\CommentTok{\#\#  [    26  52000]}
\CommentTok{\#\#  [    45  79000]}
\CommentTok{\#\#  [    24  55000]}
\CommentTok{\#\#  [    40  75000]}
\CommentTok{\#\#  [    33  28000]}
\CommentTok{\#\#  [    44 139000]}
\CommentTok{\#\#  [    22  18000]}
\CommentTok{\#\#  [    33  51000]}
\CommentTok{\#\#  [    43 133000]}
\CommentTok{\#\#  [    24  32000]}
\CommentTok{\#\#  [    46  22000]}
\CommentTok{\#\#  [    35  55000]}
\CommentTok{\#\#  [    54 104000]}
\CommentTok{\#\#  [    48 119000]}
\CommentTok{\#\#  [    35  53000]}
\CommentTok{\#\#  [    37 144000]}
\CommentTok{\#\#  [    23  66000]}
\CommentTok{\#\#  [    37 137000]}
\CommentTok{\#\#  [    31  58000]}
\CommentTok{\#\#  [    33  41000]}
\CommentTok{\#\#  [    45  22000]}
\CommentTok{\#\#  [    30  15000]}
\CommentTok{\#\#  [    19  19000]}
\CommentTok{\#\#  [    49  74000]}
\CommentTok{\#\#  [    39 122000]}
\CommentTok{\#\#  [    35  73000]}
\CommentTok{\#\#  [    39  71000]}
\CommentTok{\#\#  [    24  23000]}
\CommentTok{\#\#  [    41  72000]}
\CommentTok{\#\#  [    29  83000]}
\CommentTok{\#\#  [    54  26000]}
\CommentTok{\#\#  [    35  44000]}
\CommentTok{\#\#  [    37  75000]}
\CommentTok{\#\#  [    29  47000]}
\CommentTok{\#\#  [    31  68000]}
\CommentTok{\#\#  [    42  54000]}
\CommentTok{\#\#  [    30 135000]}
\CommentTok{\#\#  [    52 114000]}
\CommentTok{\#\#  [    50  36000]}
\CommentTok{\#\#  [    56 133000]}
\CommentTok{\#\#  [    29  61000]}
\CommentTok{\#\#  [    30  89000]}
\CommentTok{\#\#  [    26  16000]}
\CommentTok{\#\#  [    33  31000]}
\CommentTok{\#\#  [    41  72000]}
\CommentTok{\#\#  [    36  33000]}
\CommentTok{\#\#  [    55 125000]}
\CommentTok{\#\#  [    48 131000]}
\CommentTok{\#\#  [    41  71000]}
\CommentTok{\#\#  [    30  62000]}
\CommentTok{\#\#  [    37  72000]}
\CommentTok{\#\#  [    41  63000]}
\CommentTok{\#\#  [    58  47000]}
\CommentTok{\#\#  [    30 116000]}
\CommentTok{\#\#  [    20  49000]}
\CommentTok{\#\#  [    37  74000]}
\CommentTok{\#\#  [    41  59000]}
\CommentTok{\#\#  [    49  89000]}
\CommentTok{\#\#  [    28  79000]}
\CommentTok{\#\#  [    53  82000]}
\CommentTok{\#\#  [    40  57000]}
\CommentTok{\#\#  [    60  34000]}
\CommentTok{\#\#  [    35 108000]}
\CommentTok{\#\#  [    21  72000]}
\CommentTok{\#\#  [    38  71000]}
\CommentTok{\#\#  [    39 106000]}
\CommentTok{\#\#  [    37  57000]}
\CommentTok{\#\#  [    26  72000]}
\CommentTok{\#\#  [    35  23000]}
\CommentTok{\#\#  [    54 108000]}
\CommentTok{\#\#  [    30  17000]}
\CommentTok{\#\#  [    39 134000]}
\CommentTok{\#\#  [    29  43000]}
\CommentTok{\#\#  [    33  43000]}
\CommentTok{\#\#  [    35  38000]}
\CommentTok{\#\#  [    41  45000]}
\CommentTok{\#\#  [    41  72000]}
\CommentTok{\#\#  [    39 134000]}
\CommentTok{\#\#  [    27 137000]}
\CommentTok{\#\#  [    21  16000]}
\CommentTok{\#\#  [    26  32000]}
\CommentTok{\#\#  [    31  66000]}
\CommentTok{\#\#  [    39  73000]}
\CommentTok{\#\#  [    41  79000]}
\CommentTok{\#\#  [    47  50000]}
\CommentTok{\#\#  [    41  30000]}
\CommentTok{\#\#  [    37  93000]}
\CommentTok{\#\#  [    60  46000]}
\CommentTok{\#\#  [    25  22000]}
\CommentTok{\#\#  [    28  37000]}
\CommentTok{\#\#  [    38  55000]}
\CommentTok{\#\#  [    36  54000]}
\CommentTok{\#\#  [    20  36000]}
\CommentTok{\#\#  [    56 104000]}
\CommentTok{\#\#  [    40  57000]}
\CommentTok{\#\#  [    42 108000]}
\CommentTok{\#\#  [    20  23000]}
\CommentTok{\#\#  [    40  65000]}
\CommentTok{\#\#  [    47  20000]}
\CommentTok{\#\#  [    18  86000]}
\CommentTok{\#\#  [    35  79000]}
\CommentTok{\#\#  [    57  33000]}
\CommentTok{\#\#  [    34  72000]}
\CommentTok{\#\#  [    49  39000]}
\CommentTok{\#\#  [    27  31000]}
\CommentTok{\#\#  [    19  70000]}
\CommentTok{\#\#  [    39  79000]}
\CommentTok{\#\#  [    26  81000]}
\CommentTok{\#\#  [    25  80000]}
\CommentTok{\#\#  [    28  85000]}
\CommentTok{\#\#  [    55  39000]}
\CommentTok{\#\#  [    50  88000]}
\CommentTok{\#\#  [    49  88000]}
\CommentTok{\#\#  [    52 150000]}
\CommentTok{\#\#  [    35  65000]}
\CommentTok{\#\#  [    42  54000]}
\CommentTok{\#\#  [    34  43000]}
\CommentTok{\#\#  [    37  52000]}
\CommentTok{\#\#  [    48  30000]}
\CommentTok{\#\#  [    29  43000]}
\CommentTok{\#\#  [    36  52000]}
\CommentTok{\#\#  [    27  54000]}
\CommentTok{\#\#  [    26 118000]]}
\BuiltInTok{print}\NormalTok{(y\_train)}
\CommentTok{\#\# [0 1 0 1 1 1 0 0 0 0 0 0 1 1 1 0 1 0 0 1 0 1 0 1 0 0 1 1 1 1 0 1 0 1 0 0 1}
\CommentTok{\#\#  0 0 1 0 0 0 0 0 1 1 1 1 0 0 0 1 0 1 0 1 0 0 1 0 0 0 1 0 0 0 1 1 0 0 1 0 1}
\CommentTok{\#\#  1 1 0 0 1 1 0 0 1 1 0 1 0 0 1 1 0 1 1 1 0 0 0 0 0 1 0 0 1 1 1 1 1 0 1 1 0}
\CommentTok{\#\#  1 0 0 0 0 0 0 0 1 1 0 0 1 0 0 1 0 0 0 1 0 1 1 0 1 0 0 0 0 1 0 0 0 1 1 0 0}
\CommentTok{\#\#  0 0 1 0 1 0 0 0 1 0 0 0 0 1 1 1 0 0 0 0 0 0 1 1 1 1 1 0 1 0 0 0 0 0 1 0 0}
\CommentTok{\#\#  0 0 0 0 1 1 0 1 0 1 0 0 1 0 0 0 1 0 0 0 0 0 1 0 0 0 0 0 1 0 1 1 0 0 0 0 0}
\CommentTok{\#\#  0 1 1 0 0 0 0 1 0 0 0 0 1 0 1 0 1 0 0 0 1 0 0 0 1 0 1 0 0 0 0 0 1 1 0 0 0}
\CommentTok{\#\#  0 0 1 0 1 1 0 0 0 0 0 1 0 1 0 0 1 0 0 1 0 1 0 0 0 0 0 0 1 1 1 1 0 0 0 0 1}
\CommentTok{\#\#  0 0 0 0]}
\BuiltInTok{print}\NormalTok{(X\_test)}
\CommentTok{\#\# [[    30  87000]}
\CommentTok{\#\#  [    38  50000]}
\CommentTok{\#\#  [    35  75000]}
\CommentTok{\#\#  [    30  79000]}
\CommentTok{\#\#  [    35  50000]}
\CommentTok{\#\#  [    27  20000]}
\CommentTok{\#\#  [    31  15000]}
\CommentTok{\#\#  [    36 144000]}
\CommentTok{\#\#  [    18  68000]}
\CommentTok{\#\#  [    47  43000]}
\CommentTok{\#\#  [    30  49000]}
\CommentTok{\#\#  [    28  55000]}
\CommentTok{\#\#  [    37  55000]}
\CommentTok{\#\#  [    39  77000]}
\CommentTok{\#\#  [    20  86000]}
\CommentTok{\#\#  [    32 117000]}
\CommentTok{\#\#  [    37  77000]}
\CommentTok{\#\#  [    19  85000]}
\CommentTok{\#\#  [    55 130000]}
\CommentTok{\#\#  [    35  22000]}
\CommentTok{\#\#  [    35  47000]}
\CommentTok{\#\#  [    47 144000]}
\CommentTok{\#\#  [    41  51000]}
\CommentTok{\#\#  [    47 105000]}
\CommentTok{\#\#  [    23  28000]}
\CommentTok{\#\#  [    49 141000]}
\CommentTok{\#\#  [    28  87000]}
\CommentTok{\#\#  [    29  80000]}
\CommentTok{\#\#  [    37  62000]}
\CommentTok{\#\#  [    32  86000]}
\CommentTok{\#\#  [    21  88000]}
\CommentTok{\#\#  [    37  79000]}
\CommentTok{\#\#  [    57  60000]}
\CommentTok{\#\#  [    37  53000]}
\CommentTok{\#\#  [    24  58000]}
\CommentTok{\#\#  [    18  52000]}
\CommentTok{\#\#  [    22  81000]}
\CommentTok{\#\#  [    34  43000]}
\CommentTok{\#\#  [    31  34000]}
\CommentTok{\#\#  [    49  36000]}
\CommentTok{\#\#  [    27  88000]}
\CommentTok{\#\#  [    41  52000]}
\CommentTok{\#\#  [    27  84000]}
\CommentTok{\#\#  [    35  20000]}
\CommentTok{\#\#  [    43 112000]}
\CommentTok{\#\#  [    27  58000]}
\CommentTok{\#\#  [    37  80000]}
\CommentTok{\#\#  [    52  90000]}
\CommentTok{\#\#  [    26  30000]}
\CommentTok{\#\#  [    49  86000]}
\CommentTok{\#\#  [    57 122000]}
\CommentTok{\#\#  [    34  25000]}
\CommentTok{\#\#  [    35  57000]}
\CommentTok{\#\#  [    34 115000]}
\CommentTok{\#\#  [    59  88000]}
\CommentTok{\#\#  [    45  32000]}
\CommentTok{\#\#  [    29  83000]}
\CommentTok{\#\#  [    26  80000]}
\CommentTok{\#\#  [    49  28000]}
\CommentTok{\#\#  [    23  20000]}
\CommentTok{\#\#  [    32  18000]}
\CommentTok{\#\#  [    60  42000]}
\CommentTok{\#\#  [    19  76000]}
\CommentTok{\#\#  [    36  99000]}
\CommentTok{\#\#  [    19  26000]}
\CommentTok{\#\#  [    60  83000]}
\CommentTok{\#\#  [    24  89000]}
\CommentTok{\#\#  [    27  58000]}
\CommentTok{\#\#  [    40  47000]}
\CommentTok{\#\#  [    42  70000]}
\CommentTok{\#\#  [    32 150000]}
\CommentTok{\#\#  [    35  77000]}
\CommentTok{\#\#  [    22  63000]}
\CommentTok{\#\#  [    45  22000]}
\CommentTok{\#\#  [    27  89000]}
\CommentTok{\#\#  [    18  82000]}
\CommentTok{\#\#  [    42  79000]}
\CommentTok{\#\#  [    40  60000]}
\CommentTok{\#\#  [    53  34000]}
\CommentTok{\#\#  [    47 107000]}
\CommentTok{\#\#  [    58 144000]}
\CommentTok{\#\#  [    59  83000]}
\CommentTok{\#\#  [    24  55000]}
\CommentTok{\#\#  [    26  35000]}
\CommentTok{\#\#  [    58  38000]}
\CommentTok{\#\#  [    42  80000]}
\CommentTok{\#\#  [    40  75000]}
\CommentTok{\#\#  [    59 130000]}
\CommentTok{\#\#  [    46  41000]}
\CommentTok{\#\#  [    41  60000]}
\CommentTok{\#\#  [    42  64000]}
\CommentTok{\#\#  [    37 146000]}
\CommentTok{\#\#  [    23  48000]}
\CommentTok{\#\#  [    25  33000]}
\CommentTok{\#\#  [    24  84000]}
\CommentTok{\#\#  [    27  96000]}
\CommentTok{\#\#  [    23  63000]}
\CommentTok{\#\#  [    48  33000]}
\CommentTok{\#\#  [    48  90000]}
\CommentTok{\#\#  [    42 104000]]}
\BuiltInTok{print}\NormalTok{(y\_test)}
\CommentTok{\#\# [0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 1 0 0 1 0 1 0 1 0 0 0 0 0 1 1 0 0 0 0}
\CommentTok{\#\#  0 0 1 0 0 0 0 1 0 0 1 0 1 1 0 0 0 1 1 0 0 1 0 0 1 0 1 0 1 0 0 0 0 1 0 0 1}
\CommentTok{\#\#  0 0 0 0 1 1 1 0 0 0 1 1 0 1 1 0 0 1 0 0 0 1 0 1 1 1]}
\end{Highlighting}
\end{Shaded}

R

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\# install.packages(\textquotesingle{}caTools\textquotesingle{})}
\FunctionTok{library}\NormalTok{(caTools)}
\FunctionTok{set.seed}\NormalTok{(}\DecValTok{123}\NormalTok{)}
\NormalTok{split }\OtherTok{=} \FunctionTok{sample.split}\NormalTok{(dataset}\SpecialCharTok{$}\NormalTok{Purchased, }\AttributeTok{SplitRatio =} \FloatTok{0.75}\NormalTok{)}
\NormalTok{training\_set }\OtherTok{=} \FunctionTok{subset}\NormalTok{(dataset, split }\SpecialCharTok{==} \ConstantTok{TRUE}\NormalTok{)}
\NormalTok{test\_set }\OtherTok{=} \FunctionTok{subset}\NormalTok{(dataset, split }\SpecialCharTok{==} \ConstantTok{FALSE}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\hypertarget{feature-scaling-7}{%
\subsection{Feature Scaling}\label{feature-scaling-7}}

Python

\begin{Shaded}
\begin{Highlighting}[]
\ImportTok{from}\NormalTok{ sklearn.preprocessing }\ImportTok{import}\NormalTok{ StandardScaler}
\NormalTok{sc }\OperatorTok{=}\NormalTok{ StandardScaler()}
\NormalTok{X\_train }\OperatorTok{=}\NormalTok{ sc.fit\_transform(X\_train)}
\NormalTok{X\_test }\OperatorTok{=}\NormalTok{ sc.transform(X\_test)}
\BuiltInTok{print}\NormalTok{(X\_train)}
\CommentTok{\#\# [[ 0.58 {-}0.89]}
\CommentTok{\#\#  [{-}0.61  1.46]}
\CommentTok{\#\#  [{-}0.01 {-}0.57]}
\CommentTok{\#\#  [{-}0.61  1.9 ]}
\CommentTok{\#\#  [ 1.37 {-}1.41]}
\CommentTok{\#\#  [ 1.47  1.  ]}
\CommentTok{\#\#  [ 0.09 {-}0.8 ]}
\CommentTok{\#\#  [{-}0.01 {-}0.25]}
\CommentTok{\#\#  [{-}0.21 {-}0.57]}
\CommentTok{\#\#  [{-}0.21 {-}0.19]}
\CommentTok{\#\#  [{-}0.31 {-}1.29]}
\CommentTok{\#\#  [{-}0.31 {-}0.57]}
\CommentTok{\#\#  [ 0.38  0.1 ]}
\CommentTok{\#\#  [ 0.88 {-}0.6 ]}
\CommentTok{\#\#  [ 2.07 {-}1.18]}
\CommentTok{\#\#  [ 1.08 {-}0.13]}
\CommentTok{\#\#  [ 0.68  1.78]}
\CommentTok{\#\#  [{-}0.71  0.56]}
\CommentTok{\#\#  [ 0.78  0.36]}
\CommentTok{\#\#  [ 0.88 {-}0.54]}
\CommentTok{\#\#  [{-}1.2  {-}1.58]}
\CommentTok{\#\#  [ 2.17  0.94]}
\CommentTok{\#\#  [{-}0.01  1.23]}
\CommentTok{\#\#  [ 0.19  1.08]}
\CommentTok{\#\#  [ 0.38 {-}0.48]}
\CommentTok{\#\#  [{-}0.31 {-}0.31]}
\CommentTok{\#\#  [ 0.98 {-}0.83]}
\CommentTok{\#\#  [ 0.98  1.87]}
\CommentTok{\#\#  [{-}0.01  1.26]}
\CommentTok{\#\#  [{-}0.9   2.27]}
\CommentTok{\#\#  [{-}1.2  {-}1.58]}
\CommentTok{\#\#  [ 2.17 {-}0.8 ]}
\CommentTok{\#\#  [{-}1.4  {-}1.47]}
\CommentTok{\#\#  [ 0.38  2.3 ]}
\CommentTok{\#\#  [ 0.78  0.77]}
\CommentTok{\#\#  [{-}1.   {-}0.31]}
\CommentTok{\#\#  [ 0.09  0.77]}
\CommentTok{\#\#  [{-}1.    0.56]}
\CommentTok{\#\#  [ 0.28  0.07]}
\CommentTok{\#\#  [ 0.68 {-}1.26]}
\CommentTok{\#\#  [{-}0.51 {-}0.02]}
\CommentTok{\#\#  [{-}1.8   0.36]}
\CommentTok{\#\#  [{-}0.71  0.13]}
\CommentTok{\#\#  [ 0.38  0.3 ]}
\CommentTok{\#\#  [{-}0.31  0.07]}
\CommentTok{\#\#  [{-}0.51  2.3 ]}
\CommentTok{\#\#  [ 0.19  0.04]}
\CommentTok{\#\#  [ 1.27  2.22]}
\CommentTok{\#\#  [ 0.78  0.27]}
\CommentTok{\#\#  [{-}0.31  0.16]}
\CommentTok{\#\#  [{-}0.01 {-}0.54]}
\CommentTok{\#\#  [{-}0.21  0.16]}
\CommentTok{\#\#  [{-}0.11  0.24]}
\CommentTok{\#\#  [{-}0.01 {-}0.25]}
\CommentTok{\#\#  [ 2.17  1.11]}
\CommentTok{\#\#  [{-}1.8   0.36]}
\CommentTok{\#\#  [ 1.87  0.13]}
\CommentTok{\#\#  [ 0.38 {-}0.13]}
\CommentTok{\#\#  [{-}1.2   0.3 ]}
\CommentTok{\#\#  [ 0.78  1.37]}
\CommentTok{\#\#  [{-}0.31 {-}0.25]}
\CommentTok{\#\#  [{-}1.7  {-}0.05]}
\CommentTok{\#\#  [{-}1.   {-}0.74]}
\CommentTok{\#\#  [ 0.28  0.5 ]}
\CommentTok{\#\#  [{-}0.11 {-}1.06]}
\CommentTok{\#\#  [{-}1.1   0.59]}
\CommentTok{\#\#  [ 0.09 {-}0.8 ]}
\CommentTok{\#\#  [{-}1.    1.55]}
\CommentTok{\#\#  [{-}0.71  1.4 ]}
\CommentTok{\#\#  [{-}1.3   0.5 ]}
\CommentTok{\#\#  [{-}0.31  0.04]}
\CommentTok{\#\#  [{-}0.11  0.01]}
\CommentTok{\#\#  [{-}0.31 {-}0.89]}
\CommentTok{\#\#  [ 0.88 {-}1.35]}
\CommentTok{\#\#  [{-}0.31  2.24]}
\CommentTok{\#\#  [ 0.98  1.98]}
\CommentTok{\#\#  [{-}1.2   0.48]}
\CommentTok{\#\#  [{-}1.3   0.27]}
\CommentTok{\#\#  [ 1.37  1.98]}
\CommentTok{\#\#  [ 1.27 {-}1.35]}
\CommentTok{\#\#  [{-}0.31 {-}0.28]}
\CommentTok{\#\#  [{-}0.51  1.26]}
\CommentTok{\#\#  [{-}0.8   1.08]}
\CommentTok{\#\#  [ 0.98 {-}1.06]}
\CommentTok{\#\#  [ 0.28  0.3 ]}
\CommentTok{\#\#  [ 0.98  0.77]}
\CommentTok{\#\#  [{-}0.71 {-}1.5 ]}
\CommentTok{\#\#  [{-}0.71  0.04]}
\CommentTok{\#\#  [ 0.48  1.72]}
\CommentTok{\#\#  [ 2.07  0.19]}
\CommentTok{\#\#  [{-}1.99 {-}0.74]}
\CommentTok{\#\#  [{-}0.21  1.4 ]}
\CommentTok{\#\#  [ 0.38  0.59]}
\CommentTok{\#\#  [ 0.88 {-}1.15]}
\CommentTok{\#\#  [{-}1.2  {-}0.77]}
\CommentTok{\#\#  [ 0.19  0.24]}
\CommentTok{\#\#  [ 0.78 {-}0.31]}
\CommentTok{\#\#  [ 2.07 {-}0.8 ]}
\CommentTok{\#\#  [ 0.78  0.13]}
\CommentTok{\#\#  [{-}0.31  0.62]}
\CommentTok{\#\#  [{-}1.   {-}0.31]}
\CommentTok{\#\#  [ 0.19 {-}0.36]}
\CommentTok{\#\#  [ 2.07  2.13]}
\CommentTok{\#\#  [ 1.87 {-}1.26]}
\CommentTok{\#\#  [ 1.37 {-}0.92]}
\CommentTok{\#\#  [ 0.88  1.26]}
\CommentTok{\#\#  [ 1.47  2.13]}
\CommentTok{\#\#  [{-}0.31 {-}1.23]}
\CommentTok{\#\#  [ 1.97  0.91]}
\CommentTok{\#\#  [ 0.68 {-}0.71]}
\CommentTok{\#\#  [{-}1.5   0.36]}
\CommentTok{\#\#  [ 0.78 {-}1.35]}
\CommentTok{\#\#  [ 0.38 {-}0.13]}
\CommentTok{\#\#  [{-}1.    0.42]}
\CommentTok{\#\#  [{-}0.01 {-}0.31]}
\CommentTok{\#\#  [{-}1.2   0.42]}
\CommentTok{\#\#  [{-}0.9  {-}1.21]}
\CommentTok{\#\#  [{-}0.11  0.04]}
\CommentTok{\#\#  [{-}1.6  {-}0.42]}
\CommentTok{\#\#  [ 0.98 {-}1.  ]}
\CommentTok{\#\#  [ 1.08 {-}1.21]}
\CommentTok{\#\#  [{-}0.01 {-}0.13]}
\CommentTok{\#\#  [{-}1.1  {-}1.52]}
\CommentTok{\#\#  [ 0.78 {-}1.21]}
\CommentTok{\#\#  [ 0.98  2.07]}
\CommentTok{\#\#  [{-}1.2  {-}1.52]}
\CommentTok{\#\#  [{-}0.31  0.79]}
\CommentTok{\#\#  [ 0.09 {-}0.31]}
\CommentTok{\#\#  [{-}1.4  {-}1.23]}
\CommentTok{\#\#  [{-}0.61 {-}1.5 ]}
\CommentTok{\#\#  [ 0.78  0.53]}
\CommentTok{\#\#  [{-}0.31 {-}0.34]}
\CommentTok{\#\#  [ 1.77 {-}0.28]}
\CommentTok{\#\#  [ 0.88 {-}1.03]}
\CommentTok{\#\#  [ 0.19  0.07]}
\CommentTok{\#\#  [{-}0.61  0.88]}
\CommentTok{\#\#  [{-}1.89 {-}1.41]}
\CommentTok{\#\#  [{-}1.3   0.59]}
\CommentTok{\#\#  [{-}0.31  0.53]}
\CommentTok{\#\#  [{-}1.   {-}1.09]}
\CommentTok{\#\#  [ 1.18 {-}1.44]}
\CommentTok{\#\#  [ 0.19 {-}0.31]}
\CommentTok{\#\#  [ 1.18 {-}0.74]}
\CommentTok{\#\#  [{-}0.31  0.07]}
\CommentTok{\#\#  [ 0.19  2.1 ]}
\CommentTok{\#\#  [ 0.78 {-}1.09]}
\CommentTok{\#\#  [ 0.09  0.04]}
\CommentTok{\#\#  [{-}1.8   0.13]}
\CommentTok{\#\#  [{-}0.9   0.16]}
\CommentTok{\#\#  [{-}0.71  0.19]}
\CommentTok{\#\#  [ 0.88 {-}1.29]}
\CommentTok{\#\#  [ 0.19 {-}0.25]}
\CommentTok{\#\#  [{-}0.41  1.23]}
\CommentTok{\#\#  [{-}0.01  0.3 ]}
\CommentTok{\#\#  [ 0.38  0.16]}
\CommentTok{\#\#  [ 0.88 {-}0.65]}
\CommentTok{\#\#  [ 0.09  0.16]}
\CommentTok{\#\#  [{-}1.89 {-}1.29]}
\CommentTok{\#\#  [{-}0.11  0.3 ]}
\CommentTok{\#\#  [{-}0.21 {-}0.28]}
\CommentTok{\#\#  [ 0.28 {-}0.51]}
\CommentTok{\#\#  [{-}0.21  1.61]}
\CommentTok{\#\#  [ 0.98 {-}1.18]}
\CommentTok{\#\#  [{-}0.21  1.64]}
\CommentTok{\#\#  [ 1.27  1.87]}
\CommentTok{\#\#  [{-}1.1  {-}0.36]}
\CommentTok{\#\#  [{-}0.01  0.04]}
\CommentTok{\#\#  [ 0.09 {-}0.25]}
\CommentTok{\#\#  [{-}1.6  {-}1.23]}
\CommentTok{\#\#  [{-}0.51 {-}0.28]}
\CommentTok{\#\#  [ 0.98  0.13]}
\CommentTok{\#\#  [ 1.97 {-}1.35]}
\CommentTok{\#\#  [ 1.47  0.07]}
\CommentTok{\#\#  [{-}0.61  1.37]}
\CommentTok{\#\#  [ 1.57  0.01]}
\CommentTok{\#\#  [{-}0.8   0.3 ]}
\CommentTok{\#\#  [ 1.97  0.74]}
\CommentTok{\#\#  [{-}1.2  {-}0.51]}
\CommentTok{\#\#  [ 0.68  0.27]}
\CommentTok{\#\#  [{-}1.4  {-}0.42]}
\CommentTok{\#\#  [ 0.19  0.16]}
\CommentTok{\#\#  [{-}0.51 {-}1.21]}
\CommentTok{\#\#  [ 0.58  2.01]}
\CommentTok{\#\#  [{-}1.6  {-}1.5 ]}
\CommentTok{\#\#  [{-}0.51 {-}0.54]}
\CommentTok{\#\#  [ 0.48  1.84]}
\CommentTok{\#\#  [{-}1.4  {-}1.09]}
\CommentTok{\#\#  [ 0.78 {-}1.38]}
\CommentTok{\#\#  [{-}0.31 {-}0.42]}
\CommentTok{\#\#  [ 1.57  1.  ]}
\CommentTok{\#\#  [ 0.98  1.43]}
\CommentTok{\#\#  [{-}0.31 {-}0.48]}
\CommentTok{\#\#  [{-}0.11  2.16]}
\CommentTok{\#\#  [{-}1.5  {-}0.1 ]}
\CommentTok{\#\#  [{-}0.11  1.95]}
\CommentTok{\#\#  [{-}0.71 {-}0.34]}
\CommentTok{\#\#  [{-}0.51 {-}0.83]}
\CommentTok{\#\#  [ 0.68 {-}1.38]}
\CommentTok{\#\#  [{-}0.8  {-}1.58]}
\CommentTok{\#\#  [{-}1.89 {-}1.47]}
\CommentTok{\#\#  [ 1.08  0.13]}
\CommentTok{\#\#  [ 0.09  1.52]}
\CommentTok{\#\#  [{-}0.31  0.1 ]}
\CommentTok{\#\#  [ 0.09  0.04]}
\CommentTok{\#\#  [{-}1.4  {-}1.35]}
\CommentTok{\#\#  [ 0.28  0.07]}
\CommentTok{\#\#  [{-}0.9   0.39]}
\CommentTok{\#\#  [ 1.57 {-}1.26]}
\CommentTok{\#\#  [{-}0.31 {-}0.74]}
\CommentTok{\#\#  [{-}0.11  0.16]}
\CommentTok{\#\#  [{-}0.9  {-}0.65]}
\CommentTok{\#\#  [{-}0.71 {-}0.05]}
\CommentTok{\#\#  [ 0.38 {-}0.45]}
\CommentTok{\#\#  [{-}0.8   1.9 ]}
\CommentTok{\#\#  [ 1.37  1.29]}
\CommentTok{\#\#  [ 1.18 {-}0.97]}
\CommentTok{\#\#  [ 1.77  1.84]}
\CommentTok{\#\#  [{-}0.9  {-}0.25]}
\CommentTok{\#\#  [{-}0.8   0.56]}
\CommentTok{\#\#  [{-}1.2  {-}1.55]}
\CommentTok{\#\#  [{-}0.51 {-}1.12]}
\CommentTok{\#\#  [ 0.28  0.07]}
\CommentTok{\#\#  [{-}0.21 {-}1.06]}
\CommentTok{\#\#  [ 1.67  1.61]}
\CommentTok{\#\#  [ 0.98  1.78]}
\CommentTok{\#\#  [ 0.28  0.04]}
\CommentTok{\#\#  [{-}0.8  {-}0.22]}
\CommentTok{\#\#  [{-}0.11  0.07]}
\CommentTok{\#\#  [ 0.28 {-}0.19]}
\CommentTok{\#\#  [ 1.97 {-}0.65]}
\CommentTok{\#\#  [{-}0.8   1.35]}
\CommentTok{\#\#  [{-}1.8  {-}0.6 ]}
\CommentTok{\#\#  [{-}0.11  0.13]}
\CommentTok{\#\#  [ 0.28 {-}0.31]}
\CommentTok{\#\#  [ 1.08  0.56]}
\CommentTok{\#\#  [{-}1.    0.27]}
\CommentTok{\#\#  [ 1.47  0.36]}
\CommentTok{\#\#  [ 0.19 {-}0.36]}
\CommentTok{\#\#  [ 2.17 {-}1.03]}
\CommentTok{\#\#  [{-}0.31  1.11]}
\CommentTok{\#\#  [{-}1.7   0.07]}
\CommentTok{\#\#  [{-}0.01  0.04]}
\CommentTok{\#\#  [ 0.09  1.06]}
\CommentTok{\#\#  [{-}0.11 {-}0.36]}
\CommentTok{\#\#  [{-}1.2   0.07]}
\CommentTok{\#\#  [{-}0.31 {-}1.35]}
\CommentTok{\#\#  [ 1.57  1.11]}
\CommentTok{\#\#  [{-}0.8  {-}1.52]}
\CommentTok{\#\#  [ 0.09  1.87]}
\CommentTok{\#\#  [{-}0.9  {-}0.77]}
\CommentTok{\#\#  [{-}0.51 {-}0.77]}
\CommentTok{\#\#  [{-}0.31 {-}0.92]}
\CommentTok{\#\#  [ 0.28 {-}0.71]}
\CommentTok{\#\#  [ 0.28  0.07]}
\CommentTok{\#\#  [ 0.09  1.87]}
\CommentTok{\#\#  [{-}1.1   1.95]}
\CommentTok{\#\#  [{-}1.7  {-}1.55]}
\CommentTok{\#\#  [{-}1.2  {-}1.09]}
\CommentTok{\#\#  [{-}0.71 {-}0.1 ]}
\CommentTok{\#\#  [ 0.09  0.1 ]}
\CommentTok{\#\#  [ 0.28  0.27]}
\CommentTok{\#\#  [ 0.88 {-}0.57]}
\CommentTok{\#\#  [ 0.28 {-}1.15]}
\CommentTok{\#\#  [{-}0.11  0.68]}
\CommentTok{\#\#  [ 2.17 {-}0.68]}
\CommentTok{\#\#  [{-}1.3  {-}1.38]}
\CommentTok{\#\#  [{-}1.   {-}0.94]}
\CommentTok{\#\#  [{-}0.01 {-}0.42]}
\CommentTok{\#\#  [{-}0.21 {-}0.45]}
\CommentTok{\#\#  [{-}1.8  {-}0.97]}
\CommentTok{\#\#  [ 1.77  1.  ]}
\CommentTok{\#\#  [ 0.19 {-}0.36]}
\CommentTok{\#\#  [ 0.38  1.11]}
\CommentTok{\#\#  [{-}1.8  {-}1.35]}
\CommentTok{\#\#  [ 0.19 {-}0.13]}
\CommentTok{\#\#  [ 0.88 {-}1.44]}
\CommentTok{\#\#  [{-}1.99  0.48]}
\CommentTok{\#\#  [{-}0.31  0.27]}
\CommentTok{\#\#  [ 1.87 {-}1.06]}
\CommentTok{\#\#  [{-}0.41  0.07]}
\CommentTok{\#\#  [ 1.08 {-}0.89]}
\CommentTok{\#\#  [{-}1.1  {-}1.12]}
\CommentTok{\#\#  [{-}1.89  0.01]}
\CommentTok{\#\#  [ 0.09  0.27]}
\CommentTok{\#\#  [{-}1.2   0.33]}
\CommentTok{\#\#  [{-}1.3   0.3 ]}
\CommentTok{\#\#  [{-}1.    0.45]}
\CommentTok{\#\#  [ 1.67 {-}0.89]}
\CommentTok{\#\#  [ 1.18  0.53]}
\CommentTok{\#\#  [ 1.08  0.53]}
\CommentTok{\#\#  [ 1.37  2.33]}
\CommentTok{\#\#  [{-}0.31 {-}0.13]}
\CommentTok{\#\#  [ 0.38 {-}0.45]}
\CommentTok{\#\#  [{-}0.41 {-}0.77]}
\CommentTok{\#\#  [{-}0.11 {-}0.51]}
\CommentTok{\#\#  [ 0.98 {-}1.15]}
\CommentTok{\#\#  [{-}0.9  {-}0.77]}
\CommentTok{\#\#  [{-}0.21 {-}0.51]}
\CommentTok{\#\#  [{-}1.1  {-}0.45]}
\CommentTok{\#\#  [{-}1.2   1.4 ]]}
\BuiltInTok{print}\NormalTok{(X\_test)}
\CommentTok{\#\# [[{-}0.8   0.5 ]}
\CommentTok{\#\#  [{-}0.01 {-}0.57]}
\CommentTok{\#\#  [{-}0.31  0.16]}
\CommentTok{\#\#  [{-}0.8   0.27]}
\CommentTok{\#\#  [{-}0.31 {-}0.57]}
\CommentTok{\#\#  [{-}1.1  {-}1.44]}
\CommentTok{\#\#  [{-}0.71 {-}1.58]}
\CommentTok{\#\#  [{-}0.21  2.16]}
\CommentTok{\#\#  [{-}1.99 {-}0.05]}
\CommentTok{\#\#  [ 0.88 {-}0.77]}
\CommentTok{\#\#  [{-}0.8  {-}0.6 ]}
\CommentTok{\#\#  [{-}1.   {-}0.42]}
\CommentTok{\#\#  [{-}0.11 {-}0.42]}
\CommentTok{\#\#  [ 0.09  0.22]}
\CommentTok{\#\#  [{-}1.8   0.48]}
\CommentTok{\#\#  [{-}0.61  1.37]}
\CommentTok{\#\#  [{-}0.11  0.22]}
\CommentTok{\#\#  [{-}1.89  0.45]}
\CommentTok{\#\#  [ 1.67  1.75]}
\CommentTok{\#\#  [{-}0.31 {-}1.38]}
\CommentTok{\#\#  [{-}0.31 {-}0.65]}
\CommentTok{\#\#  [ 0.88  2.16]}
\CommentTok{\#\#  [ 0.28 {-}0.54]}
\CommentTok{\#\#  [ 0.88  1.03]}
\CommentTok{\#\#  [{-}1.5  {-}1.21]}
\CommentTok{\#\#  [ 1.08  2.07]}
\CommentTok{\#\#  [{-}1.    0.5 ]}
\CommentTok{\#\#  [{-}0.9   0.3 ]}
\CommentTok{\#\#  [{-}0.11 {-}0.22]}
\CommentTok{\#\#  [{-}0.61  0.48]}
\CommentTok{\#\#  [{-}1.7   0.53]}
\CommentTok{\#\#  [{-}0.11  0.27]}
\CommentTok{\#\#  [ 1.87 {-}0.28]}
\CommentTok{\#\#  [{-}0.11 {-}0.48]}
\CommentTok{\#\#  [{-}1.4  {-}0.34]}
\CommentTok{\#\#  [{-}1.99 {-}0.51]}
\CommentTok{\#\#  [{-}1.6   0.33]}
\CommentTok{\#\#  [{-}0.41 {-}0.77]}
\CommentTok{\#\#  [{-}0.71 {-}1.03]}
\CommentTok{\#\#  [ 1.08 {-}0.97]}
\CommentTok{\#\#  [{-}1.1   0.53]}
\CommentTok{\#\#  [ 0.28 {-}0.51]}
\CommentTok{\#\#  [{-}1.1   0.42]}
\CommentTok{\#\#  [{-}0.31 {-}1.44]}
\CommentTok{\#\#  [ 0.48  1.23]}
\CommentTok{\#\#  [{-}1.1  {-}0.34]}
\CommentTok{\#\#  [{-}0.11  0.3 ]}
\CommentTok{\#\#  [ 1.37  0.59]}
\CommentTok{\#\#  [{-}1.2  {-}1.15]}
\CommentTok{\#\#  [ 1.08  0.48]}
\CommentTok{\#\#  [ 1.87  1.52]}
\CommentTok{\#\#  [{-}0.41 {-}1.29]}
\CommentTok{\#\#  [{-}0.31 {-}0.36]}
\CommentTok{\#\#  [{-}0.41  1.32]}
\CommentTok{\#\#  [ 2.07  0.53]}
\CommentTok{\#\#  [ 0.68 {-}1.09]}
\CommentTok{\#\#  [{-}0.9   0.39]}
\CommentTok{\#\#  [{-}1.2   0.3 ]}
\CommentTok{\#\#  [ 1.08 {-}1.21]}
\CommentTok{\#\#  [{-}1.5  {-}1.44]}
\CommentTok{\#\#  [{-}0.61 {-}1.5 ]}
\CommentTok{\#\#  [ 2.17 {-}0.8 ]}
\CommentTok{\#\#  [{-}1.89  0.19]}
\CommentTok{\#\#  [{-}0.21  0.85]}
\CommentTok{\#\#  [{-}1.89 {-}1.26]}
\CommentTok{\#\#  [ 2.17  0.39]}
\CommentTok{\#\#  [{-}1.4   0.56]}
\CommentTok{\#\#  [{-}1.1  {-}0.34]}
\CommentTok{\#\#  [ 0.19 {-}0.65]}
\CommentTok{\#\#  [ 0.38  0.01]}
\CommentTok{\#\#  [{-}0.61  2.33]}
\CommentTok{\#\#  [{-}0.31  0.22]}
\CommentTok{\#\#  [{-}1.6  {-}0.19]}
\CommentTok{\#\#  [ 0.68 {-}1.38]}
\CommentTok{\#\#  [{-}1.1   0.56]}
\CommentTok{\#\#  [{-}1.99  0.36]}
\CommentTok{\#\#  [ 0.38  0.27]}
\CommentTok{\#\#  [ 0.19 {-}0.28]}
\CommentTok{\#\#  [ 1.47 {-}1.03]}
\CommentTok{\#\#  [ 0.88  1.08]}
\CommentTok{\#\#  [ 1.97  2.16]}
\CommentTok{\#\#  [ 2.07  0.39]}
\CommentTok{\#\#  [{-}1.4  {-}0.42]}
\CommentTok{\#\#  [{-}1.2  {-}1.  ]}
\CommentTok{\#\#  [ 1.97 {-}0.92]}
\CommentTok{\#\#  [ 0.38  0.3 ]}
\CommentTok{\#\#  [ 0.19  0.16]}
\CommentTok{\#\#  [ 2.07  1.75]}
\CommentTok{\#\#  [ 0.78 {-}0.83]}
\CommentTok{\#\#  [ 0.28 {-}0.28]}
\CommentTok{\#\#  [ 0.38 {-}0.16]}
\CommentTok{\#\#  [{-}0.11  2.22]}
\CommentTok{\#\#  [{-}1.5  {-}0.63]}
\CommentTok{\#\#  [{-}1.3  {-}1.06]}
\CommentTok{\#\#  [{-}1.4   0.42]}
\CommentTok{\#\#  [{-}1.1   0.77]}
\CommentTok{\#\#  [{-}1.5  {-}0.19]}
\CommentTok{\#\#  [ 0.98 {-}1.06]}
\CommentTok{\#\#  [ 0.98  0.59]}
\CommentTok{\#\#  [ 0.38  1.  ]]}
\end{Highlighting}
\end{Shaded}

R

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{training\_set[}\SpecialCharTok{{-}}\DecValTok{3}\NormalTok{] }\OtherTok{=} \FunctionTok{scale}\NormalTok{(training\_set[}\SpecialCharTok{{-}}\DecValTok{3}\NormalTok{])}
\NormalTok{test\_set[}\SpecialCharTok{{-}}\DecValTok{3}\NormalTok{] }\OtherTok{=} \FunctionTok{scale}\NormalTok{(test\_set[}\SpecialCharTok{{-}}\DecValTok{3}\NormalTok{])}
\end{Highlighting}
\end{Shaded}

\hypertarget{training-the-decision-tree-classification-model-on-the-training-set}{%
\subsection{Training the Decision Tree Classification model on the Training set}\label{training-the-decision-tree-classification-model-on-the-training-set}}

Python

\begin{Shaded}
\begin{Highlighting}[]
\ImportTok{from}\NormalTok{ sklearn.tree }\ImportTok{import}\NormalTok{ DecisionTreeClassifier}
\NormalTok{classifier }\OperatorTok{=}\NormalTok{ DecisionTreeClassifier(criterion }\OperatorTok{=} \StringTok{\textquotesingle{}entropy\textquotesingle{}}\NormalTok{, random\_state }\OperatorTok{=} \DecValTok{0}\NormalTok{)}
\NormalTok{classifier.fit(X\_train, y\_train)}
\CommentTok{\#\# DecisionTreeClassifier(criterion=\textquotesingle{}entropy\textquotesingle{}, random\_state=0)}
\end{Highlighting}
\end{Shaded}

R

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\# install.packages(\textquotesingle{}rpart\textquotesingle{})}
\FunctionTok{library}\NormalTok{(rpart)}
\NormalTok{classifier }\OtherTok{=} \FunctionTok{rpart}\NormalTok{(}\AttributeTok{formula =}\NormalTok{ Purchased }\SpecialCharTok{\textasciitilde{}}\NormalTok{ .,}
                   \AttributeTok{data =}\NormalTok{ training\_set)}
\end{Highlighting}
\end{Shaded}

\hypertarget{predicting-a-new-result-8}{%
\subsection{Predicting a new result}\label{predicting-a-new-result-8}}

Python

\begin{Shaded}
\begin{Highlighting}[]
\BuiltInTok{print}\NormalTok{(classifier.predict(sc.transform([[}\DecValTok{30}\NormalTok{,}\DecValTok{87000}\NormalTok{]])))}
\CommentTok{\#\# [0]}
\end{Highlighting}
\end{Shaded}

\hypertarget{predicting-the-test-set-results-7}{%
\subsection{Predicting the Test set results}\label{predicting-the-test-set-results-7}}

Python

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{y\_pred }\OperatorTok{=}\NormalTok{ classifier.predict(X\_test)}
\BuiltInTok{print}\NormalTok{(np.concatenate((y\_pred.reshape(}\BuiltInTok{len}\NormalTok{(y\_pred),}\DecValTok{1}\NormalTok{), y\_test.reshape(}\BuiltInTok{len}\NormalTok{(y\_test),}\DecValTok{1}\NormalTok{)),}\DecValTok{1}\NormalTok{))}
\CommentTok{\#\# [[0 0]}
\CommentTok{\#\#  [0 0]}
\CommentTok{\#\#  [0 0]}
\CommentTok{\#\#  [0 0]}
\CommentTok{\#\#  [0 0]}
\CommentTok{\#\#  [0 0]}
\CommentTok{\#\#  [0 0]}
\CommentTok{\#\#  [1 1]}
\CommentTok{\#\#  [0 0]}
\CommentTok{\#\#  [0 0]}
\CommentTok{\#\#  [0 0]}
\CommentTok{\#\#  [0 0]}
\CommentTok{\#\#  [0 0]}
\CommentTok{\#\#  [1 0]}
\CommentTok{\#\#  [0 0]}
\CommentTok{\#\#  [1 0]}
\CommentTok{\#\#  [1 0]}
\CommentTok{\#\#  [0 0]}
\CommentTok{\#\#  [1 1]}
\CommentTok{\#\#  [0 0]}
\CommentTok{\#\#  [0 0]}
\CommentTok{\#\#  [1 1]}
\CommentTok{\#\#  [0 0]}
\CommentTok{\#\#  [1 1]}
\CommentTok{\#\#  [0 0]}
\CommentTok{\#\#  [0 1]}
\CommentTok{\#\#  [0 0]}
\CommentTok{\#\#  [0 0]}
\CommentTok{\#\#  [0 0]}
\CommentTok{\#\#  [0 0]}
\CommentTok{\#\#  [0 0]}
\CommentTok{\#\#  [0 1]}
\CommentTok{\#\#  [1 1]}
\CommentTok{\#\#  [0 0]}
\CommentTok{\#\#  [0 0]}
\CommentTok{\#\#  [0 0]}
\CommentTok{\#\#  [0 0]}
\CommentTok{\#\#  [0 0]}
\CommentTok{\#\#  [0 0]}
\CommentTok{\#\#  [1 1]}
\CommentTok{\#\#  [0 0]}
\CommentTok{\#\#  [0 0]}
\CommentTok{\#\#  [0 0]}
\CommentTok{\#\#  [0 0]}
\CommentTok{\#\#  [1 1]}
\CommentTok{\#\#  [0 0]}
\CommentTok{\#\#  [0 0]}
\CommentTok{\#\#  [1 1]}
\CommentTok{\#\#  [0 0]}
\CommentTok{\#\#  [1 1]}
\CommentTok{\#\#  [1 1]}
\CommentTok{\#\#  [0 0]}
\CommentTok{\#\#  [0 0]}
\CommentTok{\#\#  [1 0]}
\CommentTok{\#\#  [1 1]}
\CommentTok{\#\#  [1 1]}
\CommentTok{\#\#  [0 0]}
\CommentTok{\#\#  [0 0]}
\CommentTok{\#\#  [1 1]}
\CommentTok{\#\#  [0 0]}
\CommentTok{\#\#  [0 0]}
\CommentTok{\#\#  [1 1]}
\CommentTok{\#\#  [0 0]}
\CommentTok{\#\#  [1 1]}
\CommentTok{\#\#  [0 0]}
\CommentTok{\#\#  [1 1]}
\CommentTok{\#\#  [0 0]}
\CommentTok{\#\#  [0 0]}
\CommentTok{\#\#  [0 0]}
\CommentTok{\#\#  [1 0]}
\CommentTok{\#\#  [1 1]}
\CommentTok{\#\#  [0 0]}
\CommentTok{\#\#  [0 0]}
\CommentTok{\#\#  [1 1]}
\CommentTok{\#\#  [0 0]}
\CommentTok{\#\#  [0 0]}
\CommentTok{\#\#  [0 0]}
\CommentTok{\#\#  [0 0]}
\CommentTok{\#\#  [1 1]}
\CommentTok{\#\#  [1 1]}
\CommentTok{\#\#  [1 1]}
\CommentTok{\#\#  [1 0]}
\CommentTok{\#\#  [0 0]}
\CommentTok{\#\#  [0 0]}
\CommentTok{\#\#  [1 1]}
\CommentTok{\#\#  [0 1]}
\CommentTok{\#\#  [0 0]}
\CommentTok{\#\#  [1 1]}
\CommentTok{\#\#  [1 1]}
\CommentTok{\#\#  [0 0]}
\CommentTok{\#\#  [0 0]}
\CommentTok{\#\#  [1 1]}
\CommentTok{\#\#  [0 0]}
\CommentTok{\#\#  [0 0]}
\CommentTok{\#\#  [0 0]}
\CommentTok{\#\#  [1 1]}
\CommentTok{\#\#  [0 0]}
\CommentTok{\#\#  [1 1]}
\CommentTok{\#\#  [1 1]}
\CommentTok{\#\#  [1 1]]}
\end{Highlighting}
\end{Shaded}

R

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{y\_pred }\OtherTok{=} \FunctionTok{predict}\NormalTok{(classifier, }\AttributeTok{newdata =}\NormalTok{ test\_set[}\SpecialCharTok{{-}}\DecValTok{3}\NormalTok{], }\AttributeTok{type =} \StringTok{\textquotesingle{}class\textquotesingle{}}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\hypertarget{making-the-confusion-matrix-5}{%
\subsection{Making the Confusion Matrix}\label{making-the-confusion-matrix-5}}

Python

\begin{Shaded}
\begin{Highlighting}[]
\ImportTok{from}\NormalTok{ sklearn.metrics }\ImportTok{import}\NormalTok{ confusion\_matrix, accuracy\_score}
\NormalTok{cm }\OperatorTok{=}\NormalTok{ confusion\_matrix(y\_test, y\_pred)}
\BuiltInTok{print}\NormalTok{(cm)}
\CommentTok{\#\# [[62  6]}
\CommentTok{\#\#  [ 3 29]]}
\NormalTok{accuracy\_score(y\_test, y\_pred)}
\CommentTok{\#\# 0.91}
\end{Highlighting}
\end{Shaded}

R

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{cm }\OtherTok{=} \FunctionTok{table}\NormalTok{(test\_set[, }\DecValTok{3}\NormalTok{], y\_pred)}
\end{Highlighting}
\end{Shaded}

\hypertarget{visualising-the-training-set-results-6}{%
\subsection{Visualising the Training set results}\label{visualising-the-training-set-results-6}}

Python

\begin{Shaded}
\begin{Highlighting}[]
\ImportTok{from}\NormalTok{ matplotlib.colors }\ImportTok{import}\NormalTok{ ListedColormap}
\NormalTok{X\_set, y\_set }\OperatorTok{=}\NormalTok{ sc.inverse\_transform(X\_train), y\_train}
\NormalTok{X1, X2 }\OperatorTok{=}\NormalTok{ np.meshgrid(np.arange(start }\OperatorTok{=}\NormalTok{ X\_set[:, }\DecValTok{0}\NormalTok{].}\BuiltInTok{min}\NormalTok{() }\OperatorTok{{-}} \DecValTok{10}\NormalTok{, stop }\OperatorTok{=}\NormalTok{ X\_set[:, }\DecValTok{0}\NormalTok{].}\BuiltInTok{max}\NormalTok{() }\OperatorTok{+} \DecValTok{10}\NormalTok{, step }\OperatorTok{=} \FloatTok{0.25}\NormalTok{),}
\NormalTok{                     np.arange(start }\OperatorTok{=}\NormalTok{ X\_set[:, }\DecValTok{1}\NormalTok{].}\BuiltInTok{min}\NormalTok{() }\OperatorTok{{-}} \DecValTok{1000}\NormalTok{, stop }\OperatorTok{=}\NormalTok{ X\_set[:, }\DecValTok{1}\NormalTok{].}\BuiltInTok{max}\NormalTok{() }\OperatorTok{+} \DecValTok{1000}\NormalTok{, step }\OperatorTok{=} \FloatTok{0.25}\NormalTok{))}
\NormalTok{plt.contourf(X1, X2, classifier.predict(sc.transform(np.array([X1.ravel(), X2.ravel()]).T)).reshape(X1.shape),}
\NormalTok{             alpha }\OperatorTok{=} \FloatTok{0.75}\NormalTok{, cmap }\OperatorTok{=}\NormalTok{ ListedColormap((}\StringTok{\textquotesingle{}red\textquotesingle{}}\NormalTok{, }\StringTok{\textquotesingle{}green\textquotesingle{}}\NormalTok{)))}
\NormalTok{plt.xlim(X1.}\BuiltInTok{min}\NormalTok{(), X1.}\BuiltInTok{max}\NormalTok{())}
\NormalTok{plt.ylim(X2.}\BuiltInTok{min}\NormalTok{(), X2.}\BuiltInTok{max}\NormalTok{())}
\ControlFlowTok{for}\NormalTok{ i, j }\KeywordTok{in} \BuiltInTok{enumerate}\NormalTok{(np.unique(y\_set)):}
\NormalTok{    plt.scatter(X\_set[y\_set }\OperatorTok{==}\NormalTok{ j, }\DecValTok{0}\NormalTok{], X\_set[y\_set }\OperatorTok{==}\NormalTok{ j, }\DecValTok{1}\NormalTok{], c }\OperatorTok{=}\NormalTok{ ListedColormap((}\StringTok{\textquotesingle{}red\textquotesingle{}}\NormalTok{, }\StringTok{\textquotesingle{}green\textquotesingle{}}\NormalTok{))(i), label }\OperatorTok{=}\NormalTok{ j)}
\NormalTok{plt.title(}\StringTok{\textquotesingle{}Decision Tree Classification (Training set)\textquotesingle{}}\NormalTok{)}
\NormalTok{plt.xlabel(}\StringTok{\textquotesingle{}Age\textquotesingle{}}\NormalTok{)}
\NormalTok{plt.ylabel(}\StringTok{\textquotesingle{}Estimated Salary\textquotesingle{}}\NormalTok{)}
\NormalTok{plt.legend()}
\NormalTok{plt.show()}
\end{Highlighting}
\end{Shaded}

R

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{library}\NormalTok{(ElemStatLearn)}
\NormalTok{set }\OtherTok{=}\NormalTok{ training\_set}
\NormalTok{X1 }\OtherTok{=} \FunctionTok{seq}\NormalTok{(}\FunctionTok{min}\NormalTok{(set[, }\DecValTok{1}\NormalTok{]) }\SpecialCharTok{{-}} \DecValTok{1}\NormalTok{, }\FunctionTok{max}\NormalTok{(set[, }\DecValTok{1}\NormalTok{]) }\SpecialCharTok{+} \DecValTok{1}\NormalTok{, }\AttributeTok{by =} \FloatTok{0.01}\NormalTok{)}
\NormalTok{X2 }\OtherTok{=} \FunctionTok{seq}\NormalTok{(}\FunctionTok{min}\NormalTok{(set[, }\DecValTok{2}\NormalTok{]) }\SpecialCharTok{{-}} \DecValTok{1}\NormalTok{, }\FunctionTok{max}\NormalTok{(set[, }\DecValTok{2}\NormalTok{]) }\SpecialCharTok{+} \DecValTok{1}\NormalTok{, }\AttributeTok{by =} \FloatTok{0.01}\NormalTok{)}
\NormalTok{grid\_set }\OtherTok{=} \FunctionTok{expand.grid}\NormalTok{(X1, X2)}
\FunctionTok{colnames}\NormalTok{(grid\_set) }\OtherTok{=} \FunctionTok{c}\NormalTok{(}\StringTok{\textquotesingle{}Age\textquotesingle{}}\NormalTok{, }\StringTok{\textquotesingle{}EstimatedSalary\textquotesingle{}}\NormalTok{)}
\NormalTok{y\_grid }\OtherTok{=} \FunctionTok{predict}\NormalTok{(classifier, }\AttributeTok{newdata =}\NormalTok{ grid\_set, }\AttributeTok{type =} \StringTok{\textquotesingle{}class\textquotesingle{}}\NormalTok{)}
\FunctionTok{plot}\NormalTok{(set[, }\SpecialCharTok{{-}}\DecValTok{3}\NormalTok{],}
     \AttributeTok{main =} \StringTok{\textquotesingle{}Decision Tree Classification (Training set)\textquotesingle{}}\NormalTok{,}
     \AttributeTok{xlab =} \StringTok{\textquotesingle{}Age\textquotesingle{}}\NormalTok{, }\AttributeTok{ylab =} \StringTok{\textquotesingle{}Estimated Salary\textquotesingle{}}\NormalTok{,}
     \AttributeTok{xlim =} \FunctionTok{range}\NormalTok{(X1), }\AttributeTok{ylim =} \FunctionTok{range}\NormalTok{(X2))}
\FunctionTok{contour}\NormalTok{(X1, X2, }\FunctionTok{matrix}\NormalTok{(}\FunctionTok{as.numeric}\NormalTok{(y\_grid), }\FunctionTok{length}\NormalTok{(X1), }\FunctionTok{length}\NormalTok{(X2)), }\AttributeTok{add =} \ConstantTok{TRUE}\NormalTok{)}
\FunctionTok{points}\NormalTok{(grid\_set, }\AttributeTok{pch =} \StringTok{\textquotesingle{}.\textquotesingle{}}\NormalTok{, }\AttributeTok{col =} \FunctionTok{ifelse}\NormalTok{(y\_grid }\SpecialCharTok{==} \DecValTok{1}\NormalTok{, }\StringTok{\textquotesingle{}springgreen3\textquotesingle{}}\NormalTok{, }\StringTok{\textquotesingle{}tomato\textquotesingle{}}\NormalTok{))}
\FunctionTok{points}\NormalTok{(set, }\AttributeTok{pch =} \DecValTok{21}\NormalTok{, }\AttributeTok{bg =} \FunctionTok{ifelse}\NormalTok{(set[, }\DecValTok{3}\NormalTok{] }\SpecialCharTok{==} \DecValTok{1}\NormalTok{, }\StringTok{\textquotesingle{}green4\textquotesingle{}}\NormalTok{, }\StringTok{\textquotesingle{}red3\textquotesingle{}}\NormalTok{))}
\end{Highlighting}
\end{Shaded}

\includegraphics{_main_files/figure-latex/unnamed-chunk-195-1.pdf}

\hypertarget{visualising-the-test-set-results-6}{%
\subsection{Visualising the Test set results}\label{visualising-the-test-set-results-6}}

Python

\begin{Shaded}
\begin{Highlighting}[]
\ImportTok{from}\NormalTok{ matplotlib.colors }\ImportTok{import}\NormalTok{ ListedColormap}
\NormalTok{X\_set, y\_set }\OperatorTok{=}\NormalTok{ sc.inverse\_transform(X\_test), y\_test}
\NormalTok{X1, X2 }\OperatorTok{=}\NormalTok{ np.meshgrid(np.arange(start }\OperatorTok{=}\NormalTok{ X\_set[:, }\DecValTok{0}\NormalTok{].}\BuiltInTok{min}\NormalTok{() }\OperatorTok{{-}} \DecValTok{10}\NormalTok{, stop }\OperatorTok{=}\NormalTok{ X\_set[:, }\DecValTok{0}\NormalTok{].}\BuiltInTok{max}\NormalTok{() }\OperatorTok{+} \DecValTok{10}\NormalTok{, step }\OperatorTok{=} \FloatTok{0.25}\NormalTok{),}
\NormalTok{                     np.arange(start }\OperatorTok{=}\NormalTok{ X\_set[:, }\DecValTok{1}\NormalTok{].}\BuiltInTok{min}\NormalTok{() }\OperatorTok{{-}} \DecValTok{1000}\NormalTok{, stop }\OperatorTok{=}\NormalTok{ X\_set[:, }\DecValTok{1}\NormalTok{].}\BuiltInTok{max}\NormalTok{() }\OperatorTok{+} \DecValTok{1000}\NormalTok{, step }\OperatorTok{=} \FloatTok{0.25}\NormalTok{))}
\NormalTok{plt.contourf(X1, X2, classifier.predict(sc.transform(np.array([X1.ravel(), X2.ravel()]).T)).reshape(X1.shape),}
\NormalTok{             alpha }\OperatorTok{=} \FloatTok{0.75}\NormalTok{, cmap }\OperatorTok{=}\NormalTok{ ListedColormap((}\StringTok{\textquotesingle{}red\textquotesingle{}}\NormalTok{, }\StringTok{\textquotesingle{}green\textquotesingle{}}\NormalTok{)))}
\NormalTok{plt.xlim(X1.}\BuiltInTok{min}\NormalTok{(), X1.}\BuiltInTok{max}\NormalTok{())}
\NormalTok{plt.ylim(X2.}\BuiltInTok{min}\NormalTok{(), X2.}\BuiltInTok{max}\NormalTok{())}
\ControlFlowTok{for}\NormalTok{ i, j }\KeywordTok{in} \BuiltInTok{enumerate}\NormalTok{(np.unique(y\_set)):}
\NormalTok{    plt.scatter(X\_set[y\_set }\OperatorTok{==}\NormalTok{ j, }\DecValTok{0}\NormalTok{], X\_set[y\_set }\OperatorTok{==}\NormalTok{ j, }\DecValTok{1}\NormalTok{], c }\OperatorTok{=}\NormalTok{ ListedColormap((}\StringTok{\textquotesingle{}red\textquotesingle{}}\NormalTok{, }\StringTok{\textquotesingle{}green\textquotesingle{}}\NormalTok{))(i), label }\OperatorTok{=}\NormalTok{ j)}
\NormalTok{plt.title(}\StringTok{\textquotesingle{}Decision Tree Classification (Test set)\textquotesingle{}}\NormalTok{)}
\NormalTok{plt.xlabel(}\StringTok{\textquotesingle{}Age\textquotesingle{}}\NormalTok{)}
\NormalTok{plt.ylabel(}\StringTok{\textquotesingle{}Estimated Salary\textquotesingle{}}\NormalTok{)}
\NormalTok{plt.legend()}
\NormalTok{plt.show()}
\end{Highlighting}
\end{Shaded}

R

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{library}\NormalTok{(ElemStatLearn)}
\NormalTok{set }\OtherTok{=}\NormalTok{ test\_set}
\NormalTok{X1 }\OtherTok{=} \FunctionTok{seq}\NormalTok{(}\FunctionTok{min}\NormalTok{(set[, }\DecValTok{1}\NormalTok{]) }\SpecialCharTok{{-}} \DecValTok{1}\NormalTok{, }\FunctionTok{max}\NormalTok{(set[, }\DecValTok{1}\NormalTok{]) }\SpecialCharTok{+} \DecValTok{1}\NormalTok{, }\AttributeTok{by =} \FloatTok{0.01}\NormalTok{)}
\NormalTok{X2 }\OtherTok{=} \FunctionTok{seq}\NormalTok{(}\FunctionTok{min}\NormalTok{(set[, }\DecValTok{2}\NormalTok{]) }\SpecialCharTok{{-}} \DecValTok{1}\NormalTok{, }\FunctionTok{max}\NormalTok{(set[, }\DecValTok{2}\NormalTok{]) }\SpecialCharTok{+} \DecValTok{1}\NormalTok{, }\AttributeTok{by =} \FloatTok{0.01}\NormalTok{)}
\NormalTok{grid\_set }\OtherTok{=} \FunctionTok{expand.grid}\NormalTok{(X1, X2)}
\FunctionTok{colnames}\NormalTok{(grid\_set) }\OtherTok{=} \FunctionTok{c}\NormalTok{(}\StringTok{\textquotesingle{}Age\textquotesingle{}}\NormalTok{, }\StringTok{\textquotesingle{}EstimatedSalary\textquotesingle{}}\NormalTok{)}
\NormalTok{y\_grid }\OtherTok{=} \FunctionTok{predict}\NormalTok{(classifier, }\AttributeTok{newdata =}\NormalTok{ grid\_set, }\AttributeTok{type =} \StringTok{\textquotesingle{}class\textquotesingle{}}\NormalTok{)}
\FunctionTok{plot}\NormalTok{(set[, }\SpecialCharTok{{-}}\DecValTok{3}\NormalTok{], }\AttributeTok{main =} \StringTok{\textquotesingle{}Decision Tree Classification (Test set)\textquotesingle{}}\NormalTok{,}
     \AttributeTok{xlab =} \StringTok{\textquotesingle{}Age\textquotesingle{}}\NormalTok{, }\AttributeTok{ylab =} \StringTok{\textquotesingle{}Estimated Salary\textquotesingle{}}\NormalTok{,}
     \AttributeTok{xlim =} \FunctionTok{range}\NormalTok{(X1), }\AttributeTok{ylim =} \FunctionTok{range}\NormalTok{(X2))}
\FunctionTok{contour}\NormalTok{(X1, X2, }\FunctionTok{matrix}\NormalTok{(}\FunctionTok{as.numeric}\NormalTok{(y\_grid), }\FunctionTok{length}\NormalTok{(X1), }\FunctionTok{length}\NormalTok{(X2)), }\AttributeTok{add =} \ConstantTok{TRUE}\NormalTok{)}
\FunctionTok{points}\NormalTok{(grid\_set, }\AttributeTok{pch =} \StringTok{\textquotesingle{}.\textquotesingle{}}\NormalTok{, }\AttributeTok{col =} \FunctionTok{ifelse}\NormalTok{(y\_grid }\SpecialCharTok{==} \DecValTok{1}\NormalTok{, }\StringTok{\textquotesingle{}springgreen3\textquotesingle{}}\NormalTok{, }\StringTok{\textquotesingle{}tomato\textquotesingle{}}\NormalTok{))}
\FunctionTok{points}\NormalTok{(set, }\AttributeTok{pch =} \DecValTok{21}\NormalTok{, }\AttributeTok{bg =} \FunctionTok{ifelse}\NormalTok{(set[, }\DecValTok{3}\NormalTok{] }\SpecialCharTok{==} \DecValTok{1}\NormalTok{, }\StringTok{\textquotesingle{}green4\textquotesingle{}}\NormalTok{, }\StringTok{\textquotesingle{}red3\textquotesingle{}}\NormalTok{))}
\end{Highlighting}
\end{Shaded}

\includegraphics{_main_files/figure-latex/unnamed-chunk-197-1.pdf}

\hypertarget{plotting-the-tree-1}{%
\subsection{Plotting the tree}\label{plotting-the-tree-1}}

R

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{plot}\NormalTok{(classifier)}
\FunctionTok{text}\NormalTok{(classifier)}
\end{Highlighting}
\end{Shaded}

\includegraphics{_main_files/figure-latex/unnamed-chunk-198-1.pdf}

\hypertarget{random-forest-classification}{%
\section{Random Forest Classification}\label{random-forest-classification}}

\hypertarget{importing-the-libraries-13}{%
\subsection{Importing the libraries}\label{importing-the-libraries-13}}

Python

\begin{Shaded}
\begin{Highlighting}[]
\ImportTok{import}\NormalTok{ numpy }\ImportTok{as}\NormalTok{ np}
\ImportTok{import}\NormalTok{ matplotlib.pyplot }\ImportTok{as}\NormalTok{ plt}
\ImportTok{import}\NormalTok{ pandas }\ImportTok{as}\NormalTok{ pd}
\end{Highlighting}
\end{Shaded}

\hypertarget{importing-the-dataset-13}{%
\subsection{Importing the dataset}\label{importing-the-dataset-13}}

Python

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{dataset }\OperatorTok{=}\NormalTok{ pd.read\_csv(}\StringTok{\textquotesingle{}Social\_Network\_Ads.csv\textquotesingle{}}\NormalTok{)}
\NormalTok{X }\OperatorTok{=}\NormalTok{ dataset.iloc[:, :}\OperatorTok{{-}}\DecValTok{1}\NormalTok{].values}
\NormalTok{y }\OperatorTok{=}\NormalTok{ dataset.iloc[:, }\OperatorTok{{-}}\DecValTok{1}\NormalTok{].values}
\end{Highlighting}
\end{Shaded}

R

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{dataset }\OtherTok{=} \FunctionTok{read.csv}\NormalTok{(}\StringTok{\textquotesingle{}Social\_Network\_Ads.csv\textquotesingle{}}\NormalTok{)}
\CommentTok{\# dataset = dataset[3:5]}
\end{Highlighting}
\end{Shaded}

\hypertarget{encoding-the-target-feature-as-factor-6}{%
\subsection{Encoding the target feature as factor}\label{encoding-the-target-feature-as-factor-6}}

R

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{dataset}\SpecialCharTok{$}\NormalTok{Purchased }\OtherTok{=} \FunctionTok{factor}\NormalTok{(dataset}\SpecialCharTok{$}\NormalTok{Purchased, }\AttributeTok{levels =} \FunctionTok{c}\NormalTok{(}\DecValTok{0}\NormalTok{, }\DecValTok{1}\NormalTok{))}
\end{Highlighting}
\end{Shaded}

\hypertarget{splitting-the-dataset-into-the-training-set-and-test-set-9}{%
\subsection{Splitting the dataset into the Training set and Test set}\label{splitting-the-dataset-into-the-training-set-and-test-set-9}}

Python

\begin{Shaded}
\begin{Highlighting}[]
\ImportTok{from}\NormalTok{ sklearn.model\_selection }\ImportTok{import}\NormalTok{ train\_test\_split}
\NormalTok{X\_train, X\_test, y\_train, y\_test }\OperatorTok{=}\NormalTok{ train\_test\_split(X, y, test\_size }\OperatorTok{=} \FloatTok{0.25}\NormalTok{, random\_state }\OperatorTok{=} \DecValTok{0}\NormalTok{)}
\BuiltInTok{print}\NormalTok{(X\_train)}
\CommentTok{\#\# [[    44  39000]}
\CommentTok{\#\#  [    32 120000]}
\CommentTok{\#\#  [    38  50000]}
\CommentTok{\#\#  [    32 135000]}
\CommentTok{\#\#  [    52  21000]}
\CommentTok{\#\#  [    53 104000]}
\CommentTok{\#\#  [    39  42000]}
\CommentTok{\#\#  [    38  61000]}
\CommentTok{\#\#  [    36  50000]}
\CommentTok{\#\#  [    36  63000]}
\CommentTok{\#\#  [    35  25000]}
\CommentTok{\#\#  [    35  50000]}
\CommentTok{\#\#  [    42  73000]}
\CommentTok{\#\#  [    47  49000]}
\CommentTok{\#\#  [    59  29000]}
\CommentTok{\#\#  [    49  65000]}
\CommentTok{\#\#  [    45 131000]}
\CommentTok{\#\#  [    31  89000]}
\CommentTok{\#\#  [    46  82000]}
\CommentTok{\#\#  [    47  51000]}
\CommentTok{\#\#  [    26  15000]}
\CommentTok{\#\#  [    60 102000]}
\CommentTok{\#\#  [    38 112000]}
\CommentTok{\#\#  [    40 107000]}
\CommentTok{\#\#  [    42  53000]}
\CommentTok{\#\#  [    35  59000]}
\CommentTok{\#\#  [    48  41000]}
\CommentTok{\#\#  [    48 134000]}
\CommentTok{\#\#  [    38 113000]}
\CommentTok{\#\#  [    29 148000]}
\CommentTok{\#\#  [    26  15000]}
\CommentTok{\#\#  [    60  42000]}
\CommentTok{\#\#  [    24  19000]}
\CommentTok{\#\#  [    42 149000]}
\CommentTok{\#\#  [    46  96000]}
\CommentTok{\#\#  [    28  59000]}
\CommentTok{\#\#  [    39  96000]}
\CommentTok{\#\#  [    28  89000]}
\CommentTok{\#\#  [    41  72000]}
\CommentTok{\#\#  [    45  26000]}
\CommentTok{\#\#  [    33  69000]}
\CommentTok{\#\#  [    20  82000]}
\CommentTok{\#\#  [    31  74000]}
\CommentTok{\#\#  [    42  80000]}
\CommentTok{\#\#  [    35  72000]}
\CommentTok{\#\#  [    33 149000]}
\CommentTok{\#\#  [    40  71000]}
\CommentTok{\#\#  [    51 146000]}
\CommentTok{\#\#  [    46  79000]}
\CommentTok{\#\#  [    35  75000]}
\CommentTok{\#\#  [    38  51000]}
\CommentTok{\#\#  [    36  75000]}
\CommentTok{\#\#  [    37  78000]}
\CommentTok{\#\#  [    38  61000]}
\CommentTok{\#\#  [    60 108000]}
\CommentTok{\#\#  [    20  82000]}
\CommentTok{\#\#  [    57  74000]}
\CommentTok{\#\#  [    42  65000]}
\CommentTok{\#\#  [    26  80000]}
\CommentTok{\#\#  [    46 117000]}
\CommentTok{\#\#  [    35  61000]}
\CommentTok{\#\#  [    21  68000]}
\CommentTok{\#\#  [    28  44000]}
\CommentTok{\#\#  [    41  87000]}
\CommentTok{\#\#  [    37  33000]}
\CommentTok{\#\#  [    27  90000]}
\CommentTok{\#\#  [    39  42000]}
\CommentTok{\#\#  [    28 123000]}
\CommentTok{\#\#  [    31 118000]}
\CommentTok{\#\#  [    25  87000]}
\CommentTok{\#\#  [    35  71000]}
\CommentTok{\#\#  [    37  70000]}
\CommentTok{\#\#  [    35  39000]}
\CommentTok{\#\#  [    47  23000]}
\CommentTok{\#\#  [    35 147000]}
\CommentTok{\#\#  [    48 138000]}
\CommentTok{\#\#  [    26  86000]}
\CommentTok{\#\#  [    25  79000]}
\CommentTok{\#\#  [    52 138000]}
\CommentTok{\#\#  [    51  23000]}
\CommentTok{\#\#  [    35  60000]}
\CommentTok{\#\#  [    33 113000]}
\CommentTok{\#\#  [    30 107000]}
\CommentTok{\#\#  [    48  33000]}
\CommentTok{\#\#  [    41  80000]}
\CommentTok{\#\#  [    48  96000]}
\CommentTok{\#\#  [    31  18000]}
\CommentTok{\#\#  [    31  71000]}
\CommentTok{\#\#  [    43 129000]}
\CommentTok{\#\#  [    59  76000]}
\CommentTok{\#\#  [    18  44000]}
\CommentTok{\#\#  [    36 118000]}
\CommentTok{\#\#  [    42  90000]}
\CommentTok{\#\#  [    47  30000]}
\CommentTok{\#\#  [    26  43000]}
\CommentTok{\#\#  [    40  78000]}
\CommentTok{\#\#  [    46  59000]}
\CommentTok{\#\#  [    59  42000]}
\CommentTok{\#\#  [    46  74000]}
\CommentTok{\#\#  [    35  91000]}
\CommentTok{\#\#  [    28  59000]}
\CommentTok{\#\#  [    40  57000]}
\CommentTok{\#\#  [    59 143000]}
\CommentTok{\#\#  [    57  26000]}
\CommentTok{\#\#  [    52  38000]}
\CommentTok{\#\#  [    47 113000]}
\CommentTok{\#\#  [    53 143000]}
\CommentTok{\#\#  [    35  27000]}
\CommentTok{\#\#  [    58 101000]}
\CommentTok{\#\#  [    45  45000]}
\CommentTok{\#\#  [    23  82000]}
\CommentTok{\#\#  [    46  23000]}
\CommentTok{\#\#  [    42  65000]}
\CommentTok{\#\#  [    28  84000]}
\CommentTok{\#\#  [    38  59000]}
\CommentTok{\#\#  [    26  84000]}
\CommentTok{\#\#  [    29  28000]}
\CommentTok{\#\#  [    37  71000]}
\CommentTok{\#\#  [    22  55000]}
\CommentTok{\#\#  [    48  35000]}
\CommentTok{\#\#  [    49  28000]}
\CommentTok{\#\#  [    38  65000]}
\CommentTok{\#\#  [    27  17000]}
\CommentTok{\#\#  [    46  28000]}
\CommentTok{\#\#  [    48 141000]}
\CommentTok{\#\#  [    26  17000]}
\CommentTok{\#\#  [    35  97000]}
\CommentTok{\#\#  [    39  59000]}
\CommentTok{\#\#  [    24  27000]}
\CommentTok{\#\#  [    32  18000]}
\CommentTok{\#\#  [    46  88000]}
\CommentTok{\#\#  [    35  58000]}
\CommentTok{\#\#  [    56  60000]}
\CommentTok{\#\#  [    47  34000]}
\CommentTok{\#\#  [    40  72000]}
\CommentTok{\#\#  [    32 100000]}
\CommentTok{\#\#  [    19  21000]}
\CommentTok{\#\#  [    25  90000]}
\CommentTok{\#\#  [    35  88000]}
\CommentTok{\#\#  [    28  32000]}
\CommentTok{\#\#  [    50  20000]}
\CommentTok{\#\#  [    40  59000]}
\CommentTok{\#\#  [    50  44000]}
\CommentTok{\#\#  [    35  72000]}
\CommentTok{\#\#  [    40 142000]}
\CommentTok{\#\#  [    46  32000]}
\CommentTok{\#\#  [    39  71000]}
\CommentTok{\#\#  [    20  74000]}
\CommentTok{\#\#  [    29  75000]}
\CommentTok{\#\#  [    31  76000]}
\CommentTok{\#\#  [    47  25000]}
\CommentTok{\#\#  [    40  61000]}
\CommentTok{\#\#  [    34 112000]}
\CommentTok{\#\#  [    38  80000]}
\CommentTok{\#\#  [    42  75000]}
\CommentTok{\#\#  [    47  47000]}
\CommentTok{\#\#  [    39  75000]}
\CommentTok{\#\#  [    19  25000]}
\CommentTok{\#\#  [    37  80000]}
\CommentTok{\#\#  [    36  60000]}
\CommentTok{\#\#  [    41  52000]}
\CommentTok{\#\#  [    36 125000]}
\CommentTok{\#\#  [    48  29000]}
\CommentTok{\#\#  [    36 126000]}
\CommentTok{\#\#  [    51 134000]}
\CommentTok{\#\#  [    27  57000]}
\CommentTok{\#\#  [    38  71000]}
\CommentTok{\#\#  [    39  61000]}
\CommentTok{\#\#  [    22  27000]}
\CommentTok{\#\#  [    33  60000]}
\CommentTok{\#\#  [    48  74000]}
\CommentTok{\#\#  [    58  23000]}
\CommentTok{\#\#  [    53  72000]}
\CommentTok{\#\#  [    32 117000]}
\CommentTok{\#\#  [    54  70000]}
\CommentTok{\#\#  [    30  80000]}
\CommentTok{\#\#  [    58  95000]}
\CommentTok{\#\#  [    26  52000]}
\CommentTok{\#\#  [    45  79000]}
\CommentTok{\#\#  [    24  55000]}
\CommentTok{\#\#  [    40  75000]}
\CommentTok{\#\#  [    33  28000]}
\CommentTok{\#\#  [    44 139000]}
\CommentTok{\#\#  [    22  18000]}
\CommentTok{\#\#  [    33  51000]}
\CommentTok{\#\#  [    43 133000]}
\CommentTok{\#\#  [    24  32000]}
\CommentTok{\#\#  [    46  22000]}
\CommentTok{\#\#  [    35  55000]}
\CommentTok{\#\#  [    54 104000]}
\CommentTok{\#\#  [    48 119000]}
\CommentTok{\#\#  [    35  53000]}
\CommentTok{\#\#  [    37 144000]}
\CommentTok{\#\#  [    23  66000]}
\CommentTok{\#\#  [    37 137000]}
\CommentTok{\#\#  [    31  58000]}
\CommentTok{\#\#  [    33  41000]}
\CommentTok{\#\#  [    45  22000]}
\CommentTok{\#\#  [    30  15000]}
\CommentTok{\#\#  [    19  19000]}
\CommentTok{\#\#  [    49  74000]}
\CommentTok{\#\#  [    39 122000]}
\CommentTok{\#\#  [    35  73000]}
\CommentTok{\#\#  [    39  71000]}
\CommentTok{\#\#  [    24  23000]}
\CommentTok{\#\#  [    41  72000]}
\CommentTok{\#\#  [    29  83000]}
\CommentTok{\#\#  [    54  26000]}
\CommentTok{\#\#  [    35  44000]}
\CommentTok{\#\#  [    37  75000]}
\CommentTok{\#\#  [    29  47000]}
\CommentTok{\#\#  [    31  68000]}
\CommentTok{\#\#  [    42  54000]}
\CommentTok{\#\#  [    30 135000]}
\CommentTok{\#\#  [    52 114000]}
\CommentTok{\#\#  [    50  36000]}
\CommentTok{\#\#  [    56 133000]}
\CommentTok{\#\#  [    29  61000]}
\CommentTok{\#\#  [    30  89000]}
\CommentTok{\#\#  [    26  16000]}
\CommentTok{\#\#  [    33  31000]}
\CommentTok{\#\#  [    41  72000]}
\CommentTok{\#\#  [    36  33000]}
\CommentTok{\#\#  [    55 125000]}
\CommentTok{\#\#  [    48 131000]}
\CommentTok{\#\#  [    41  71000]}
\CommentTok{\#\#  [    30  62000]}
\CommentTok{\#\#  [    37  72000]}
\CommentTok{\#\#  [    41  63000]}
\CommentTok{\#\#  [    58  47000]}
\CommentTok{\#\#  [    30 116000]}
\CommentTok{\#\#  [    20  49000]}
\CommentTok{\#\#  [    37  74000]}
\CommentTok{\#\#  [    41  59000]}
\CommentTok{\#\#  [    49  89000]}
\CommentTok{\#\#  [    28  79000]}
\CommentTok{\#\#  [    53  82000]}
\CommentTok{\#\#  [    40  57000]}
\CommentTok{\#\#  [    60  34000]}
\CommentTok{\#\#  [    35 108000]}
\CommentTok{\#\#  [    21  72000]}
\CommentTok{\#\#  [    38  71000]}
\CommentTok{\#\#  [    39 106000]}
\CommentTok{\#\#  [    37  57000]}
\CommentTok{\#\#  [    26  72000]}
\CommentTok{\#\#  [    35  23000]}
\CommentTok{\#\#  [    54 108000]}
\CommentTok{\#\#  [    30  17000]}
\CommentTok{\#\#  [    39 134000]}
\CommentTok{\#\#  [    29  43000]}
\CommentTok{\#\#  [    33  43000]}
\CommentTok{\#\#  [    35  38000]}
\CommentTok{\#\#  [    41  45000]}
\CommentTok{\#\#  [    41  72000]}
\CommentTok{\#\#  [    39 134000]}
\CommentTok{\#\#  [    27 137000]}
\CommentTok{\#\#  [    21  16000]}
\CommentTok{\#\#  [    26  32000]}
\CommentTok{\#\#  [    31  66000]}
\CommentTok{\#\#  [    39  73000]}
\CommentTok{\#\#  [    41  79000]}
\CommentTok{\#\#  [    47  50000]}
\CommentTok{\#\#  [    41  30000]}
\CommentTok{\#\#  [    37  93000]}
\CommentTok{\#\#  [    60  46000]}
\CommentTok{\#\#  [    25  22000]}
\CommentTok{\#\#  [    28  37000]}
\CommentTok{\#\#  [    38  55000]}
\CommentTok{\#\#  [    36  54000]}
\CommentTok{\#\#  [    20  36000]}
\CommentTok{\#\#  [    56 104000]}
\CommentTok{\#\#  [    40  57000]}
\CommentTok{\#\#  [    42 108000]}
\CommentTok{\#\#  [    20  23000]}
\CommentTok{\#\#  [    40  65000]}
\CommentTok{\#\#  [    47  20000]}
\CommentTok{\#\#  [    18  86000]}
\CommentTok{\#\#  [    35  79000]}
\CommentTok{\#\#  [    57  33000]}
\CommentTok{\#\#  [    34  72000]}
\CommentTok{\#\#  [    49  39000]}
\CommentTok{\#\#  [    27  31000]}
\CommentTok{\#\#  [    19  70000]}
\CommentTok{\#\#  [    39  79000]}
\CommentTok{\#\#  [    26  81000]}
\CommentTok{\#\#  [    25  80000]}
\CommentTok{\#\#  [    28  85000]}
\CommentTok{\#\#  [    55  39000]}
\CommentTok{\#\#  [    50  88000]}
\CommentTok{\#\#  [    49  88000]}
\CommentTok{\#\#  [    52 150000]}
\CommentTok{\#\#  [    35  65000]}
\CommentTok{\#\#  [    42  54000]}
\CommentTok{\#\#  [    34  43000]}
\CommentTok{\#\#  [    37  52000]}
\CommentTok{\#\#  [    48  30000]}
\CommentTok{\#\#  [    29  43000]}
\CommentTok{\#\#  [    36  52000]}
\CommentTok{\#\#  [    27  54000]}
\CommentTok{\#\#  [    26 118000]]}
\BuiltInTok{print}\NormalTok{(y\_train)}
\CommentTok{\#\# [0 1 0 1 1 1 0 0 0 0 0 0 1 1 1 0 1 0 0 1 0 1 0 1 0 0 1 1 1 1 0 1 0 1 0 0 1}
\CommentTok{\#\#  0 0 1 0 0 0 0 0 1 1 1 1 0 0 0 1 0 1 0 1 0 0 1 0 0 0 1 0 0 0 1 1 0 0 1 0 1}
\CommentTok{\#\#  1 1 0 0 1 1 0 0 1 1 0 1 0 0 1 1 0 1 1 1 0 0 0 0 0 1 0 0 1 1 1 1 1 0 1 1 0}
\CommentTok{\#\#  1 0 0 0 0 0 0 0 1 1 0 0 1 0 0 1 0 0 0 1 0 1 1 0 1 0 0 0 0 1 0 0 0 1 1 0 0}
\CommentTok{\#\#  0 0 1 0 1 0 0 0 1 0 0 0 0 1 1 1 0 0 0 0 0 0 1 1 1 1 1 0 1 0 0 0 0 0 1 0 0}
\CommentTok{\#\#  0 0 0 0 1 1 0 1 0 1 0 0 1 0 0 0 1 0 0 0 0 0 1 0 0 0 0 0 1 0 1 1 0 0 0 0 0}
\CommentTok{\#\#  0 1 1 0 0 0 0 1 0 0 0 0 1 0 1 0 1 0 0 0 1 0 0 0 1 0 1 0 0 0 0 0 1 1 0 0 0}
\CommentTok{\#\#  0 0 1 0 1 1 0 0 0 0 0 1 0 1 0 0 1 0 0 1 0 1 0 0 0 0 0 0 1 1 1 1 0 0 0 0 1}
\CommentTok{\#\#  0 0 0 0]}
\BuiltInTok{print}\NormalTok{(X\_test)}
\CommentTok{\#\# [[    30  87000]}
\CommentTok{\#\#  [    38  50000]}
\CommentTok{\#\#  [    35  75000]}
\CommentTok{\#\#  [    30  79000]}
\CommentTok{\#\#  [    35  50000]}
\CommentTok{\#\#  [    27  20000]}
\CommentTok{\#\#  [    31  15000]}
\CommentTok{\#\#  [    36 144000]}
\CommentTok{\#\#  [    18  68000]}
\CommentTok{\#\#  [    47  43000]}
\CommentTok{\#\#  [    30  49000]}
\CommentTok{\#\#  [    28  55000]}
\CommentTok{\#\#  [    37  55000]}
\CommentTok{\#\#  [    39  77000]}
\CommentTok{\#\#  [    20  86000]}
\CommentTok{\#\#  [    32 117000]}
\CommentTok{\#\#  [    37  77000]}
\CommentTok{\#\#  [    19  85000]}
\CommentTok{\#\#  [    55 130000]}
\CommentTok{\#\#  [    35  22000]}
\CommentTok{\#\#  [    35  47000]}
\CommentTok{\#\#  [    47 144000]}
\CommentTok{\#\#  [    41  51000]}
\CommentTok{\#\#  [    47 105000]}
\CommentTok{\#\#  [    23  28000]}
\CommentTok{\#\#  [    49 141000]}
\CommentTok{\#\#  [    28  87000]}
\CommentTok{\#\#  [    29  80000]}
\CommentTok{\#\#  [    37  62000]}
\CommentTok{\#\#  [    32  86000]}
\CommentTok{\#\#  [    21  88000]}
\CommentTok{\#\#  [    37  79000]}
\CommentTok{\#\#  [    57  60000]}
\CommentTok{\#\#  [    37  53000]}
\CommentTok{\#\#  [    24  58000]}
\CommentTok{\#\#  [    18  52000]}
\CommentTok{\#\#  [    22  81000]}
\CommentTok{\#\#  [    34  43000]}
\CommentTok{\#\#  [    31  34000]}
\CommentTok{\#\#  [    49  36000]}
\CommentTok{\#\#  [    27  88000]}
\CommentTok{\#\#  [    41  52000]}
\CommentTok{\#\#  [    27  84000]}
\CommentTok{\#\#  [    35  20000]}
\CommentTok{\#\#  [    43 112000]}
\CommentTok{\#\#  [    27  58000]}
\CommentTok{\#\#  [    37  80000]}
\CommentTok{\#\#  [    52  90000]}
\CommentTok{\#\#  [    26  30000]}
\CommentTok{\#\#  [    49  86000]}
\CommentTok{\#\#  [    57 122000]}
\CommentTok{\#\#  [    34  25000]}
\CommentTok{\#\#  [    35  57000]}
\CommentTok{\#\#  [    34 115000]}
\CommentTok{\#\#  [    59  88000]}
\CommentTok{\#\#  [    45  32000]}
\CommentTok{\#\#  [    29  83000]}
\CommentTok{\#\#  [    26  80000]}
\CommentTok{\#\#  [    49  28000]}
\CommentTok{\#\#  [    23  20000]}
\CommentTok{\#\#  [    32  18000]}
\CommentTok{\#\#  [    60  42000]}
\CommentTok{\#\#  [    19  76000]}
\CommentTok{\#\#  [    36  99000]}
\CommentTok{\#\#  [    19  26000]}
\CommentTok{\#\#  [    60  83000]}
\CommentTok{\#\#  [    24  89000]}
\CommentTok{\#\#  [    27  58000]}
\CommentTok{\#\#  [    40  47000]}
\CommentTok{\#\#  [    42  70000]}
\CommentTok{\#\#  [    32 150000]}
\CommentTok{\#\#  [    35  77000]}
\CommentTok{\#\#  [    22  63000]}
\CommentTok{\#\#  [    45  22000]}
\CommentTok{\#\#  [    27  89000]}
\CommentTok{\#\#  [    18  82000]}
\CommentTok{\#\#  [    42  79000]}
\CommentTok{\#\#  [    40  60000]}
\CommentTok{\#\#  [    53  34000]}
\CommentTok{\#\#  [    47 107000]}
\CommentTok{\#\#  [    58 144000]}
\CommentTok{\#\#  [    59  83000]}
\CommentTok{\#\#  [    24  55000]}
\CommentTok{\#\#  [    26  35000]}
\CommentTok{\#\#  [    58  38000]}
\CommentTok{\#\#  [    42  80000]}
\CommentTok{\#\#  [    40  75000]}
\CommentTok{\#\#  [    59 130000]}
\CommentTok{\#\#  [    46  41000]}
\CommentTok{\#\#  [    41  60000]}
\CommentTok{\#\#  [    42  64000]}
\CommentTok{\#\#  [    37 146000]}
\CommentTok{\#\#  [    23  48000]}
\CommentTok{\#\#  [    25  33000]}
\CommentTok{\#\#  [    24  84000]}
\CommentTok{\#\#  [    27  96000]}
\CommentTok{\#\#  [    23  63000]}
\CommentTok{\#\#  [    48  33000]}
\CommentTok{\#\#  [    48  90000]}
\CommentTok{\#\#  [    42 104000]]}
\BuiltInTok{print}\NormalTok{(y\_test)}
\CommentTok{\#\# [0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 1 0 0 1 0 1 0 1 0 0 0 0 0 1 1 0 0 0 0}
\CommentTok{\#\#  0 0 1 0 0 0 0 1 0 0 1 0 1 1 0 0 0 1 1 0 0 1 0 0 1 0 1 0 1 0 0 0 0 1 0 0 1}
\CommentTok{\#\#  0 0 0 0 1 1 1 0 0 0 1 1 0 1 1 0 0 1 0 0 0 1 0 1 1 1]}
\end{Highlighting}
\end{Shaded}

R

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\# install.packages(\textquotesingle{}caTools\textquotesingle{})}
\FunctionTok{library}\NormalTok{(caTools)}
\FunctionTok{set.seed}\NormalTok{(}\DecValTok{123}\NormalTok{)}
\NormalTok{split }\OtherTok{=} \FunctionTok{sample.split}\NormalTok{(dataset}\SpecialCharTok{$}\NormalTok{Purchased, }\AttributeTok{SplitRatio =} \FloatTok{0.75}\NormalTok{)}
\NormalTok{training\_set }\OtherTok{=} \FunctionTok{subset}\NormalTok{(dataset, split }\SpecialCharTok{==} \ConstantTok{TRUE}\NormalTok{)}
\NormalTok{test\_set }\OtherTok{=} \FunctionTok{subset}\NormalTok{(dataset, split }\SpecialCharTok{==} \ConstantTok{FALSE}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\hypertarget{feature-scaling-8}{%
\subsection{Feature Scaling}\label{feature-scaling-8}}

Python

\begin{Shaded}
\begin{Highlighting}[]
\ImportTok{from}\NormalTok{ sklearn.preprocessing }\ImportTok{import}\NormalTok{ StandardScaler}
\NormalTok{sc }\OperatorTok{=}\NormalTok{ StandardScaler()}
\NormalTok{X\_train }\OperatorTok{=}\NormalTok{ sc.fit\_transform(X\_train)}
\NormalTok{X\_test }\OperatorTok{=}\NormalTok{ sc.transform(X\_test)}
\BuiltInTok{print}\NormalTok{(X\_train)}
\CommentTok{\#\# [[ 0.58 {-}0.89]}
\CommentTok{\#\#  [{-}0.61  1.46]}
\CommentTok{\#\#  [{-}0.01 {-}0.57]}
\CommentTok{\#\#  [{-}0.61  1.9 ]}
\CommentTok{\#\#  [ 1.37 {-}1.41]}
\CommentTok{\#\#  [ 1.47  1.  ]}
\CommentTok{\#\#  [ 0.09 {-}0.8 ]}
\CommentTok{\#\#  [{-}0.01 {-}0.25]}
\CommentTok{\#\#  [{-}0.21 {-}0.57]}
\CommentTok{\#\#  [{-}0.21 {-}0.19]}
\CommentTok{\#\#  [{-}0.31 {-}1.29]}
\CommentTok{\#\#  [{-}0.31 {-}0.57]}
\CommentTok{\#\#  [ 0.38  0.1 ]}
\CommentTok{\#\#  [ 0.88 {-}0.6 ]}
\CommentTok{\#\#  [ 2.07 {-}1.18]}
\CommentTok{\#\#  [ 1.08 {-}0.13]}
\CommentTok{\#\#  [ 0.68  1.78]}
\CommentTok{\#\#  [{-}0.71  0.56]}
\CommentTok{\#\#  [ 0.78  0.36]}
\CommentTok{\#\#  [ 0.88 {-}0.54]}
\CommentTok{\#\#  [{-}1.2  {-}1.58]}
\CommentTok{\#\#  [ 2.17  0.94]}
\CommentTok{\#\#  [{-}0.01  1.23]}
\CommentTok{\#\#  [ 0.19  1.08]}
\CommentTok{\#\#  [ 0.38 {-}0.48]}
\CommentTok{\#\#  [{-}0.31 {-}0.31]}
\CommentTok{\#\#  [ 0.98 {-}0.83]}
\CommentTok{\#\#  [ 0.98  1.87]}
\CommentTok{\#\#  [{-}0.01  1.26]}
\CommentTok{\#\#  [{-}0.9   2.27]}
\CommentTok{\#\#  [{-}1.2  {-}1.58]}
\CommentTok{\#\#  [ 2.17 {-}0.8 ]}
\CommentTok{\#\#  [{-}1.4  {-}1.47]}
\CommentTok{\#\#  [ 0.38  2.3 ]}
\CommentTok{\#\#  [ 0.78  0.77]}
\CommentTok{\#\#  [{-}1.   {-}0.31]}
\CommentTok{\#\#  [ 0.09  0.77]}
\CommentTok{\#\#  [{-}1.    0.56]}
\CommentTok{\#\#  [ 0.28  0.07]}
\CommentTok{\#\#  [ 0.68 {-}1.26]}
\CommentTok{\#\#  [{-}0.51 {-}0.02]}
\CommentTok{\#\#  [{-}1.8   0.36]}
\CommentTok{\#\#  [{-}0.71  0.13]}
\CommentTok{\#\#  [ 0.38  0.3 ]}
\CommentTok{\#\#  [{-}0.31  0.07]}
\CommentTok{\#\#  [{-}0.51  2.3 ]}
\CommentTok{\#\#  [ 0.19  0.04]}
\CommentTok{\#\#  [ 1.27  2.22]}
\CommentTok{\#\#  [ 0.78  0.27]}
\CommentTok{\#\#  [{-}0.31  0.16]}
\CommentTok{\#\#  [{-}0.01 {-}0.54]}
\CommentTok{\#\#  [{-}0.21  0.16]}
\CommentTok{\#\#  [{-}0.11  0.24]}
\CommentTok{\#\#  [{-}0.01 {-}0.25]}
\CommentTok{\#\#  [ 2.17  1.11]}
\CommentTok{\#\#  [{-}1.8   0.36]}
\CommentTok{\#\#  [ 1.87  0.13]}
\CommentTok{\#\#  [ 0.38 {-}0.13]}
\CommentTok{\#\#  [{-}1.2   0.3 ]}
\CommentTok{\#\#  [ 0.78  1.37]}
\CommentTok{\#\#  [{-}0.31 {-}0.25]}
\CommentTok{\#\#  [{-}1.7  {-}0.05]}
\CommentTok{\#\#  [{-}1.   {-}0.74]}
\CommentTok{\#\#  [ 0.28  0.5 ]}
\CommentTok{\#\#  [{-}0.11 {-}1.06]}
\CommentTok{\#\#  [{-}1.1   0.59]}
\CommentTok{\#\#  [ 0.09 {-}0.8 ]}
\CommentTok{\#\#  [{-}1.    1.55]}
\CommentTok{\#\#  [{-}0.71  1.4 ]}
\CommentTok{\#\#  [{-}1.3   0.5 ]}
\CommentTok{\#\#  [{-}0.31  0.04]}
\CommentTok{\#\#  [{-}0.11  0.01]}
\CommentTok{\#\#  [{-}0.31 {-}0.89]}
\CommentTok{\#\#  [ 0.88 {-}1.35]}
\CommentTok{\#\#  [{-}0.31  2.24]}
\CommentTok{\#\#  [ 0.98  1.98]}
\CommentTok{\#\#  [{-}1.2   0.48]}
\CommentTok{\#\#  [{-}1.3   0.27]}
\CommentTok{\#\#  [ 1.37  1.98]}
\CommentTok{\#\#  [ 1.27 {-}1.35]}
\CommentTok{\#\#  [{-}0.31 {-}0.28]}
\CommentTok{\#\#  [{-}0.51  1.26]}
\CommentTok{\#\#  [{-}0.8   1.08]}
\CommentTok{\#\#  [ 0.98 {-}1.06]}
\CommentTok{\#\#  [ 0.28  0.3 ]}
\CommentTok{\#\#  [ 0.98  0.77]}
\CommentTok{\#\#  [{-}0.71 {-}1.5 ]}
\CommentTok{\#\#  [{-}0.71  0.04]}
\CommentTok{\#\#  [ 0.48  1.72]}
\CommentTok{\#\#  [ 2.07  0.19]}
\CommentTok{\#\#  [{-}1.99 {-}0.74]}
\CommentTok{\#\#  [{-}0.21  1.4 ]}
\CommentTok{\#\#  [ 0.38  0.59]}
\CommentTok{\#\#  [ 0.88 {-}1.15]}
\CommentTok{\#\#  [{-}1.2  {-}0.77]}
\CommentTok{\#\#  [ 0.19  0.24]}
\CommentTok{\#\#  [ 0.78 {-}0.31]}
\CommentTok{\#\#  [ 2.07 {-}0.8 ]}
\CommentTok{\#\#  [ 0.78  0.13]}
\CommentTok{\#\#  [{-}0.31  0.62]}
\CommentTok{\#\#  [{-}1.   {-}0.31]}
\CommentTok{\#\#  [ 0.19 {-}0.36]}
\CommentTok{\#\#  [ 2.07  2.13]}
\CommentTok{\#\#  [ 1.87 {-}1.26]}
\CommentTok{\#\#  [ 1.37 {-}0.92]}
\CommentTok{\#\#  [ 0.88  1.26]}
\CommentTok{\#\#  [ 1.47  2.13]}
\CommentTok{\#\#  [{-}0.31 {-}1.23]}
\CommentTok{\#\#  [ 1.97  0.91]}
\CommentTok{\#\#  [ 0.68 {-}0.71]}
\CommentTok{\#\#  [{-}1.5   0.36]}
\CommentTok{\#\#  [ 0.78 {-}1.35]}
\CommentTok{\#\#  [ 0.38 {-}0.13]}
\CommentTok{\#\#  [{-}1.    0.42]}
\CommentTok{\#\#  [{-}0.01 {-}0.31]}
\CommentTok{\#\#  [{-}1.2   0.42]}
\CommentTok{\#\#  [{-}0.9  {-}1.21]}
\CommentTok{\#\#  [{-}0.11  0.04]}
\CommentTok{\#\#  [{-}1.6  {-}0.42]}
\CommentTok{\#\#  [ 0.98 {-}1.  ]}
\CommentTok{\#\#  [ 1.08 {-}1.21]}
\CommentTok{\#\#  [{-}0.01 {-}0.13]}
\CommentTok{\#\#  [{-}1.1  {-}1.52]}
\CommentTok{\#\#  [ 0.78 {-}1.21]}
\CommentTok{\#\#  [ 0.98  2.07]}
\CommentTok{\#\#  [{-}1.2  {-}1.52]}
\CommentTok{\#\#  [{-}0.31  0.79]}
\CommentTok{\#\#  [ 0.09 {-}0.31]}
\CommentTok{\#\#  [{-}1.4  {-}1.23]}
\CommentTok{\#\#  [{-}0.61 {-}1.5 ]}
\CommentTok{\#\#  [ 0.78  0.53]}
\CommentTok{\#\#  [{-}0.31 {-}0.34]}
\CommentTok{\#\#  [ 1.77 {-}0.28]}
\CommentTok{\#\#  [ 0.88 {-}1.03]}
\CommentTok{\#\#  [ 0.19  0.07]}
\CommentTok{\#\#  [{-}0.61  0.88]}
\CommentTok{\#\#  [{-}1.89 {-}1.41]}
\CommentTok{\#\#  [{-}1.3   0.59]}
\CommentTok{\#\#  [{-}0.31  0.53]}
\CommentTok{\#\#  [{-}1.   {-}1.09]}
\CommentTok{\#\#  [ 1.18 {-}1.44]}
\CommentTok{\#\#  [ 0.19 {-}0.31]}
\CommentTok{\#\#  [ 1.18 {-}0.74]}
\CommentTok{\#\#  [{-}0.31  0.07]}
\CommentTok{\#\#  [ 0.19  2.1 ]}
\CommentTok{\#\#  [ 0.78 {-}1.09]}
\CommentTok{\#\#  [ 0.09  0.04]}
\CommentTok{\#\#  [{-}1.8   0.13]}
\CommentTok{\#\#  [{-}0.9   0.16]}
\CommentTok{\#\#  [{-}0.71  0.19]}
\CommentTok{\#\#  [ 0.88 {-}1.29]}
\CommentTok{\#\#  [ 0.19 {-}0.25]}
\CommentTok{\#\#  [{-}0.41  1.23]}
\CommentTok{\#\#  [{-}0.01  0.3 ]}
\CommentTok{\#\#  [ 0.38  0.16]}
\CommentTok{\#\#  [ 0.88 {-}0.65]}
\CommentTok{\#\#  [ 0.09  0.16]}
\CommentTok{\#\#  [{-}1.89 {-}1.29]}
\CommentTok{\#\#  [{-}0.11  0.3 ]}
\CommentTok{\#\#  [{-}0.21 {-}0.28]}
\CommentTok{\#\#  [ 0.28 {-}0.51]}
\CommentTok{\#\#  [{-}0.21  1.61]}
\CommentTok{\#\#  [ 0.98 {-}1.18]}
\CommentTok{\#\#  [{-}0.21  1.64]}
\CommentTok{\#\#  [ 1.27  1.87]}
\CommentTok{\#\#  [{-}1.1  {-}0.36]}
\CommentTok{\#\#  [{-}0.01  0.04]}
\CommentTok{\#\#  [ 0.09 {-}0.25]}
\CommentTok{\#\#  [{-}1.6  {-}1.23]}
\CommentTok{\#\#  [{-}0.51 {-}0.28]}
\CommentTok{\#\#  [ 0.98  0.13]}
\CommentTok{\#\#  [ 1.97 {-}1.35]}
\CommentTok{\#\#  [ 1.47  0.07]}
\CommentTok{\#\#  [{-}0.61  1.37]}
\CommentTok{\#\#  [ 1.57  0.01]}
\CommentTok{\#\#  [{-}0.8   0.3 ]}
\CommentTok{\#\#  [ 1.97  0.74]}
\CommentTok{\#\#  [{-}1.2  {-}0.51]}
\CommentTok{\#\#  [ 0.68  0.27]}
\CommentTok{\#\#  [{-}1.4  {-}0.42]}
\CommentTok{\#\#  [ 0.19  0.16]}
\CommentTok{\#\#  [{-}0.51 {-}1.21]}
\CommentTok{\#\#  [ 0.58  2.01]}
\CommentTok{\#\#  [{-}1.6  {-}1.5 ]}
\CommentTok{\#\#  [{-}0.51 {-}0.54]}
\CommentTok{\#\#  [ 0.48  1.84]}
\CommentTok{\#\#  [{-}1.4  {-}1.09]}
\CommentTok{\#\#  [ 0.78 {-}1.38]}
\CommentTok{\#\#  [{-}0.31 {-}0.42]}
\CommentTok{\#\#  [ 1.57  1.  ]}
\CommentTok{\#\#  [ 0.98  1.43]}
\CommentTok{\#\#  [{-}0.31 {-}0.48]}
\CommentTok{\#\#  [{-}0.11  2.16]}
\CommentTok{\#\#  [{-}1.5  {-}0.1 ]}
\CommentTok{\#\#  [{-}0.11  1.95]}
\CommentTok{\#\#  [{-}0.71 {-}0.34]}
\CommentTok{\#\#  [{-}0.51 {-}0.83]}
\CommentTok{\#\#  [ 0.68 {-}1.38]}
\CommentTok{\#\#  [{-}0.8  {-}1.58]}
\CommentTok{\#\#  [{-}1.89 {-}1.47]}
\CommentTok{\#\#  [ 1.08  0.13]}
\CommentTok{\#\#  [ 0.09  1.52]}
\CommentTok{\#\#  [{-}0.31  0.1 ]}
\CommentTok{\#\#  [ 0.09  0.04]}
\CommentTok{\#\#  [{-}1.4  {-}1.35]}
\CommentTok{\#\#  [ 0.28  0.07]}
\CommentTok{\#\#  [{-}0.9   0.39]}
\CommentTok{\#\#  [ 1.57 {-}1.26]}
\CommentTok{\#\#  [{-}0.31 {-}0.74]}
\CommentTok{\#\#  [{-}0.11  0.16]}
\CommentTok{\#\#  [{-}0.9  {-}0.65]}
\CommentTok{\#\#  [{-}0.71 {-}0.05]}
\CommentTok{\#\#  [ 0.38 {-}0.45]}
\CommentTok{\#\#  [{-}0.8   1.9 ]}
\CommentTok{\#\#  [ 1.37  1.29]}
\CommentTok{\#\#  [ 1.18 {-}0.97]}
\CommentTok{\#\#  [ 1.77  1.84]}
\CommentTok{\#\#  [{-}0.9  {-}0.25]}
\CommentTok{\#\#  [{-}0.8   0.56]}
\CommentTok{\#\#  [{-}1.2  {-}1.55]}
\CommentTok{\#\#  [{-}0.51 {-}1.12]}
\CommentTok{\#\#  [ 0.28  0.07]}
\CommentTok{\#\#  [{-}0.21 {-}1.06]}
\CommentTok{\#\#  [ 1.67  1.61]}
\CommentTok{\#\#  [ 0.98  1.78]}
\CommentTok{\#\#  [ 0.28  0.04]}
\CommentTok{\#\#  [{-}0.8  {-}0.22]}
\CommentTok{\#\#  [{-}0.11  0.07]}
\CommentTok{\#\#  [ 0.28 {-}0.19]}
\CommentTok{\#\#  [ 1.97 {-}0.65]}
\CommentTok{\#\#  [{-}0.8   1.35]}
\CommentTok{\#\#  [{-}1.8  {-}0.6 ]}
\CommentTok{\#\#  [{-}0.11  0.13]}
\CommentTok{\#\#  [ 0.28 {-}0.31]}
\CommentTok{\#\#  [ 1.08  0.56]}
\CommentTok{\#\#  [{-}1.    0.27]}
\CommentTok{\#\#  [ 1.47  0.36]}
\CommentTok{\#\#  [ 0.19 {-}0.36]}
\CommentTok{\#\#  [ 2.17 {-}1.03]}
\CommentTok{\#\#  [{-}0.31  1.11]}
\CommentTok{\#\#  [{-}1.7   0.07]}
\CommentTok{\#\#  [{-}0.01  0.04]}
\CommentTok{\#\#  [ 0.09  1.06]}
\CommentTok{\#\#  [{-}0.11 {-}0.36]}
\CommentTok{\#\#  [{-}1.2   0.07]}
\CommentTok{\#\#  [{-}0.31 {-}1.35]}
\CommentTok{\#\#  [ 1.57  1.11]}
\CommentTok{\#\#  [{-}0.8  {-}1.52]}
\CommentTok{\#\#  [ 0.09  1.87]}
\CommentTok{\#\#  [{-}0.9  {-}0.77]}
\CommentTok{\#\#  [{-}0.51 {-}0.77]}
\CommentTok{\#\#  [{-}0.31 {-}0.92]}
\CommentTok{\#\#  [ 0.28 {-}0.71]}
\CommentTok{\#\#  [ 0.28  0.07]}
\CommentTok{\#\#  [ 0.09  1.87]}
\CommentTok{\#\#  [{-}1.1   1.95]}
\CommentTok{\#\#  [{-}1.7  {-}1.55]}
\CommentTok{\#\#  [{-}1.2  {-}1.09]}
\CommentTok{\#\#  [{-}0.71 {-}0.1 ]}
\CommentTok{\#\#  [ 0.09  0.1 ]}
\CommentTok{\#\#  [ 0.28  0.27]}
\CommentTok{\#\#  [ 0.88 {-}0.57]}
\CommentTok{\#\#  [ 0.28 {-}1.15]}
\CommentTok{\#\#  [{-}0.11  0.68]}
\CommentTok{\#\#  [ 2.17 {-}0.68]}
\CommentTok{\#\#  [{-}1.3  {-}1.38]}
\CommentTok{\#\#  [{-}1.   {-}0.94]}
\CommentTok{\#\#  [{-}0.01 {-}0.42]}
\CommentTok{\#\#  [{-}0.21 {-}0.45]}
\CommentTok{\#\#  [{-}1.8  {-}0.97]}
\CommentTok{\#\#  [ 1.77  1.  ]}
\CommentTok{\#\#  [ 0.19 {-}0.36]}
\CommentTok{\#\#  [ 0.38  1.11]}
\CommentTok{\#\#  [{-}1.8  {-}1.35]}
\CommentTok{\#\#  [ 0.19 {-}0.13]}
\CommentTok{\#\#  [ 0.88 {-}1.44]}
\CommentTok{\#\#  [{-}1.99  0.48]}
\CommentTok{\#\#  [{-}0.31  0.27]}
\CommentTok{\#\#  [ 1.87 {-}1.06]}
\CommentTok{\#\#  [{-}0.41  0.07]}
\CommentTok{\#\#  [ 1.08 {-}0.89]}
\CommentTok{\#\#  [{-}1.1  {-}1.12]}
\CommentTok{\#\#  [{-}1.89  0.01]}
\CommentTok{\#\#  [ 0.09  0.27]}
\CommentTok{\#\#  [{-}1.2   0.33]}
\CommentTok{\#\#  [{-}1.3   0.3 ]}
\CommentTok{\#\#  [{-}1.    0.45]}
\CommentTok{\#\#  [ 1.67 {-}0.89]}
\CommentTok{\#\#  [ 1.18  0.53]}
\CommentTok{\#\#  [ 1.08  0.53]}
\CommentTok{\#\#  [ 1.37  2.33]}
\CommentTok{\#\#  [{-}0.31 {-}0.13]}
\CommentTok{\#\#  [ 0.38 {-}0.45]}
\CommentTok{\#\#  [{-}0.41 {-}0.77]}
\CommentTok{\#\#  [{-}0.11 {-}0.51]}
\CommentTok{\#\#  [ 0.98 {-}1.15]}
\CommentTok{\#\#  [{-}0.9  {-}0.77]}
\CommentTok{\#\#  [{-}0.21 {-}0.51]}
\CommentTok{\#\#  [{-}1.1  {-}0.45]}
\CommentTok{\#\#  [{-}1.2   1.4 ]]}
\BuiltInTok{print}\NormalTok{(X\_test)}
\CommentTok{\#\# [[{-}0.8   0.5 ]}
\CommentTok{\#\#  [{-}0.01 {-}0.57]}
\CommentTok{\#\#  [{-}0.31  0.16]}
\CommentTok{\#\#  [{-}0.8   0.27]}
\CommentTok{\#\#  [{-}0.31 {-}0.57]}
\CommentTok{\#\#  [{-}1.1  {-}1.44]}
\CommentTok{\#\#  [{-}0.71 {-}1.58]}
\CommentTok{\#\#  [{-}0.21  2.16]}
\CommentTok{\#\#  [{-}1.99 {-}0.05]}
\CommentTok{\#\#  [ 0.88 {-}0.77]}
\CommentTok{\#\#  [{-}0.8  {-}0.6 ]}
\CommentTok{\#\#  [{-}1.   {-}0.42]}
\CommentTok{\#\#  [{-}0.11 {-}0.42]}
\CommentTok{\#\#  [ 0.09  0.22]}
\CommentTok{\#\#  [{-}1.8   0.48]}
\CommentTok{\#\#  [{-}0.61  1.37]}
\CommentTok{\#\#  [{-}0.11  0.22]}
\CommentTok{\#\#  [{-}1.89  0.45]}
\CommentTok{\#\#  [ 1.67  1.75]}
\CommentTok{\#\#  [{-}0.31 {-}1.38]}
\CommentTok{\#\#  [{-}0.31 {-}0.65]}
\CommentTok{\#\#  [ 0.88  2.16]}
\CommentTok{\#\#  [ 0.28 {-}0.54]}
\CommentTok{\#\#  [ 0.88  1.03]}
\CommentTok{\#\#  [{-}1.5  {-}1.21]}
\CommentTok{\#\#  [ 1.08  2.07]}
\CommentTok{\#\#  [{-}1.    0.5 ]}
\CommentTok{\#\#  [{-}0.9   0.3 ]}
\CommentTok{\#\#  [{-}0.11 {-}0.22]}
\CommentTok{\#\#  [{-}0.61  0.48]}
\CommentTok{\#\#  [{-}1.7   0.53]}
\CommentTok{\#\#  [{-}0.11  0.27]}
\CommentTok{\#\#  [ 1.87 {-}0.28]}
\CommentTok{\#\#  [{-}0.11 {-}0.48]}
\CommentTok{\#\#  [{-}1.4  {-}0.34]}
\CommentTok{\#\#  [{-}1.99 {-}0.51]}
\CommentTok{\#\#  [{-}1.6   0.33]}
\CommentTok{\#\#  [{-}0.41 {-}0.77]}
\CommentTok{\#\#  [{-}0.71 {-}1.03]}
\CommentTok{\#\#  [ 1.08 {-}0.97]}
\CommentTok{\#\#  [{-}1.1   0.53]}
\CommentTok{\#\#  [ 0.28 {-}0.51]}
\CommentTok{\#\#  [{-}1.1   0.42]}
\CommentTok{\#\#  [{-}0.31 {-}1.44]}
\CommentTok{\#\#  [ 0.48  1.23]}
\CommentTok{\#\#  [{-}1.1  {-}0.34]}
\CommentTok{\#\#  [{-}0.11  0.3 ]}
\CommentTok{\#\#  [ 1.37  0.59]}
\CommentTok{\#\#  [{-}1.2  {-}1.15]}
\CommentTok{\#\#  [ 1.08  0.48]}
\CommentTok{\#\#  [ 1.87  1.52]}
\CommentTok{\#\#  [{-}0.41 {-}1.29]}
\CommentTok{\#\#  [{-}0.31 {-}0.36]}
\CommentTok{\#\#  [{-}0.41  1.32]}
\CommentTok{\#\#  [ 2.07  0.53]}
\CommentTok{\#\#  [ 0.68 {-}1.09]}
\CommentTok{\#\#  [{-}0.9   0.39]}
\CommentTok{\#\#  [{-}1.2   0.3 ]}
\CommentTok{\#\#  [ 1.08 {-}1.21]}
\CommentTok{\#\#  [{-}1.5  {-}1.44]}
\CommentTok{\#\#  [{-}0.61 {-}1.5 ]}
\CommentTok{\#\#  [ 2.17 {-}0.8 ]}
\CommentTok{\#\#  [{-}1.89  0.19]}
\CommentTok{\#\#  [{-}0.21  0.85]}
\CommentTok{\#\#  [{-}1.89 {-}1.26]}
\CommentTok{\#\#  [ 2.17  0.39]}
\CommentTok{\#\#  [{-}1.4   0.56]}
\CommentTok{\#\#  [{-}1.1  {-}0.34]}
\CommentTok{\#\#  [ 0.19 {-}0.65]}
\CommentTok{\#\#  [ 0.38  0.01]}
\CommentTok{\#\#  [{-}0.61  2.33]}
\CommentTok{\#\#  [{-}0.31  0.22]}
\CommentTok{\#\#  [{-}1.6  {-}0.19]}
\CommentTok{\#\#  [ 0.68 {-}1.38]}
\CommentTok{\#\#  [{-}1.1   0.56]}
\CommentTok{\#\#  [{-}1.99  0.36]}
\CommentTok{\#\#  [ 0.38  0.27]}
\CommentTok{\#\#  [ 0.19 {-}0.28]}
\CommentTok{\#\#  [ 1.47 {-}1.03]}
\CommentTok{\#\#  [ 0.88  1.08]}
\CommentTok{\#\#  [ 1.97  2.16]}
\CommentTok{\#\#  [ 2.07  0.39]}
\CommentTok{\#\#  [{-}1.4  {-}0.42]}
\CommentTok{\#\#  [{-}1.2  {-}1.  ]}
\CommentTok{\#\#  [ 1.97 {-}0.92]}
\CommentTok{\#\#  [ 0.38  0.3 ]}
\CommentTok{\#\#  [ 0.19  0.16]}
\CommentTok{\#\#  [ 2.07  1.75]}
\CommentTok{\#\#  [ 0.78 {-}0.83]}
\CommentTok{\#\#  [ 0.28 {-}0.28]}
\CommentTok{\#\#  [ 0.38 {-}0.16]}
\CommentTok{\#\#  [{-}0.11  2.22]}
\CommentTok{\#\#  [{-}1.5  {-}0.63]}
\CommentTok{\#\#  [{-}1.3  {-}1.06]}
\CommentTok{\#\#  [{-}1.4   0.42]}
\CommentTok{\#\#  [{-}1.1   0.77]}
\CommentTok{\#\#  [{-}1.5  {-}0.19]}
\CommentTok{\#\#  [ 0.98 {-}1.06]}
\CommentTok{\#\#  [ 0.98  0.59]}
\CommentTok{\#\#  [ 0.38  1.  ]]}
\end{Highlighting}
\end{Shaded}

R

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{training\_set[}\SpecialCharTok{{-}}\DecValTok{3}\NormalTok{] }\OtherTok{=} \FunctionTok{scale}\NormalTok{(training\_set[}\SpecialCharTok{{-}}\DecValTok{3}\NormalTok{])}
\NormalTok{test\_set[}\SpecialCharTok{{-}}\DecValTok{3}\NormalTok{] }\OtherTok{=} \FunctionTok{scale}\NormalTok{(test\_set[}\SpecialCharTok{{-}}\DecValTok{3}\NormalTok{])}
\end{Highlighting}
\end{Shaded}

\hypertarget{training-the-random-forest-classification-model-on-the-training-set}{%
\subsection{Training the Random Forest Classification model on the Training set}\label{training-the-random-forest-classification-model-on-the-training-set}}

Python

\begin{Shaded}
\begin{Highlighting}[]
\ImportTok{from}\NormalTok{ sklearn.ensemble }\ImportTok{import}\NormalTok{ RandomForestClassifier}
\NormalTok{classifier }\OperatorTok{=}\NormalTok{ RandomForestClassifier(n\_estimators }\OperatorTok{=} \DecValTok{10}\NormalTok{, criterion }\OperatorTok{=} \StringTok{\textquotesingle{}entropy\textquotesingle{}}\NormalTok{, random\_state }\OperatorTok{=} \DecValTok{0}\NormalTok{)}
\NormalTok{classifier.fit(X\_train, y\_train)}
\CommentTok{\#\# RandomForestClassifier(criterion=\textquotesingle{}entropy\textquotesingle{}, n\_estimators=10, random\_state=0)}
\end{Highlighting}
\end{Shaded}

R

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\# install.packages(\textquotesingle{}randomForest\textquotesingle{})}
\FunctionTok{library}\NormalTok{(randomForest)}
\FunctionTok{set.seed}\NormalTok{(}\DecValTok{123}\NormalTok{)}
\NormalTok{classifier }\OtherTok{=} \FunctionTok{randomForest}\NormalTok{(}\AttributeTok{x =}\NormalTok{ training\_set[}\SpecialCharTok{{-}}\DecValTok{3}\NormalTok{],}
                          \AttributeTok{y =}\NormalTok{ training\_set}\SpecialCharTok{$}\NormalTok{Purchased,}
                          \AttributeTok{ntree =} \DecValTok{500}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\hypertarget{predicting-a-new-result-9}{%
\subsection{Predicting a new result}\label{predicting-a-new-result-9}}

Python

\begin{Shaded}
\begin{Highlighting}[]
\BuiltInTok{print}\NormalTok{(classifier.predict(sc.transform([[}\DecValTok{30}\NormalTok{,}\DecValTok{87000}\NormalTok{]])))}
\CommentTok{\#\# [0]}
\end{Highlighting}
\end{Shaded}

\hypertarget{predicting-the-test-set-results-8}{%
\subsection{Predicting the Test set results}\label{predicting-the-test-set-results-8}}

Python

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{y\_pred }\OperatorTok{=}\NormalTok{ classifier.predict(X\_test)}
\BuiltInTok{print}\NormalTok{(np.concatenate((y\_pred.reshape(}\BuiltInTok{len}\NormalTok{(y\_pred),}\DecValTok{1}\NormalTok{), y\_test.reshape(}\BuiltInTok{len}\NormalTok{(y\_test),}\DecValTok{1}\NormalTok{)),}\DecValTok{1}\NormalTok{))}
\CommentTok{\#\# [[0 0]}
\CommentTok{\#\#  [0 0]}
\CommentTok{\#\#  [0 0]}
\CommentTok{\#\#  [0 0]}
\CommentTok{\#\#  [0 0]}
\CommentTok{\#\#  [0 0]}
\CommentTok{\#\#  [0 0]}
\CommentTok{\#\#  [1 1]}
\CommentTok{\#\#  [0 0]}
\CommentTok{\#\#  [1 0]}
\CommentTok{\#\#  [0 0]}
\CommentTok{\#\#  [0 0]}
\CommentTok{\#\#  [0 0]}
\CommentTok{\#\#  [0 0]}
\CommentTok{\#\#  [0 0]}
\CommentTok{\#\#  [1 0]}
\CommentTok{\#\#  [1 0]}
\CommentTok{\#\#  [0 0]}
\CommentTok{\#\#  [1 1]}
\CommentTok{\#\#  [0 0]}
\CommentTok{\#\#  [0 0]}
\CommentTok{\#\#  [1 1]}
\CommentTok{\#\#  [0 0]}
\CommentTok{\#\#  [1 1]}
\CommentTok{\#\#  [0 0]}
\CommentTok{\#\#  [0 1]}
\CommentTok{\#\#  [0 0]}
\CommentTok{\#\#  [0 0]}
\CommentTok{\#\#  [0 0]}
\CommentTok{\#\#  [0 0]}
\CommentTok{\#\#  [0 0]}
\CommentTok{\#\#  [0 1]}
\CommentTok{\#\#  [1 1]}
\CommentTok{\#\#  [0 0]}
\CommentTok{\#\#  [0 0]}
\CommentTok{\#\#  [0 0]}
\CommentTok{\#\#  [0 0]}
\CommentTok{\#\#  [0 0]}
\CommentTok{\#\#  [0 0]}
\CommentTok{\#\#  [1 1]}
\CommentTok{\#\#  [0 0]}
\CommentTok{\#\#  [0 0]}
\CommentTok{\#\#  [0 0]}
\CommentTok{\#\#  [0 0]}
\CommentTok{\#\#  [1 1]}
\CommentTok{\#\#  [0 0]}
\CommentTok{\#\#  [0 0]}
\CommentTok{\#\#  [1 1]}
\CommentTok{\#\#  [0 0]}
\CommentTok{\#\#  [1 1]}
\CommentTok{\#\#  [1 1]}
\CommentTok{\#\#  [0 0]}
\CommentTok{\#\#  [0 0]}
\CommentTok{\#\#  [1 0]}
\CommentTok{\#\#  [1 1]}
\CommentTok{\#\#  [1 1]}
\CommentTok{\#\#  [0 0]}
\CommentTok{\#\#  [0 0]}
\CommentTok{\#\#  [1 1]}
\CommentTok{\#\#  [0 0]}
\CommentTok{\#\#  [0 0]}
\CommentTok{\#\#  [1 1]}
\CommentTok{\#\#  [0 0]}
\CommentTok{\#\#  [1 1]}
\CommentTok{\#\#  [0 0]}
\CommentTok{\#\#  [1 1]}
\CommentTok{\#\#  [0 0]}
\CommentTok{\#\#  [0 0]}
\CommentTok{\#\#  [0 0]}
\CommentTok{\#\#  [0 0]}
\CommentTok{\#\#  [1 1]}
\CommentTok{\#\#  [0 0]}
\CommentTok{\#\#  [0 0]}
\CommentTok{\#\#  [1 1]}
\CommentTok{\#\#  [0 0]}
\CommentTok{\#\#  [0 0]}
\CommentTok{\#\#  [0 0]}
\CommentTok{\#\#  [0 0]}
\CommentTok{\#\#  [1 1]}
\CommentTok{\#\#  [1 1]}
\CommentTok{\#\#  [1 1]}
\CommentTok{\#\#  [1 0]}
\CommentTok{\#\#  [0 0]}
\CommentTok{\#\#  [0 0]}
\CommentTok{\#\#  [1 1]}
\CommentTok{\#\#  [0 1]}
\CommentTok{\#\#  [0 0]}
\CommentTok{\#\#  [1 1]}
\CommentTok{\#\#  [1 1]}
\CommentTok{\#\#  [0 0]}
\CommentTok{\#\#  [0 0]}
\CommentTok{\#\#  [1 1]}
\CommentTok{\#\#  [0 0]}
\CommentTok{\#\#  [0 0]}
\CommentTok{\#\#  [0 0]}
\CommentTok{\#\#  [0 1]}
\CommentTok{\#\#  [0 0]}
\CommentTok{\#\#  [1 1]}
\CommentTok{\#\#  [1 1]}
\CommentTok{\#\#  [1 1]]}
\end{Highlighting}
\end{Shaded}

R

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{y\_pred }\OtherTok{=} \FunctionTok{predict}\NormalTok{(classifier, }\AttributeTok{newdata =}\NormalTok{ test\_set[}\SpecialCharTok{{-}}\DecValTok{3}\NormalTok{])}
\end{Highlighting}
\end{Shaded}

\hypertarget{making-the-confusion-matrix-6}{%
\subsection{Making the Confusion Matrix}\label{making-the-confusion-matrix-6}}

Python

\begin{Shaded}
\begin{Highlighting}[]
\ImportTok{from}\NormalTok{ sklearn.metrics }\ImportTok{import}\NormalTok{ confusion\_matrix, accuracy\_score}
\NormalTok{cm }\OperatorTok{=}\NormalTok{ confusion\_matrix(y\_test, y\_pred)}
\BuiltInTok{print}\NormalTok{(cm)}
\CommentTok{\#\# [[63  5]}
\CommentTok{\#\#  [ 4 28]]}
\NormalTok{accuracy\_score(y\_test, y\_pred)}
\CommentTok{\#\# 0.91}
\end{Highlighting}
\end{Shaded}

R

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{cm }\OtherTok{=} \FunctionTok{table}\NormalTok{(test\_set[, }\DecValTok{3}\NormalTok{], y\_pred)}
\end{Highlighting}
\end{Shaded}

\hypertarget{visualising-the-training-set-results-7}{%
\subsection{Visualising the Training set results}\label{visualising-the-training-set-results-7}}

Python

\begin{Shaded}
\begin{Highlighting}[]
\ImportTok{from}\NormalTok{ matplotlib.colors }\ImportTok{import}\NormalTok{ ListedColormap}
\NormalTok{X\_set, y\_set }\OperatorTok{=}\NormalTok{ sc.inverse\_transform(X\_train), y\_train}
\NormalTok{X1, X2 }\OperatorTok{=}\NormalTok{ np.meshgrid(np.arange(start }\OperatorTok{=}\NormalTok{ X\_set[:, }\DecValTok{0}\NormalTok{].}\BuiltInTok{min}\NormalTok{() }\OperatorTok{{-}} \DecValTok{10}\NormalTok{, stop }\OperatorTok{=}\NormalTok{ X\_set[:, }\DecValTok{0}\NormalTok{].}\BuiltInTok{max}\NormalTok{() }\OperatorTok{+} \DecValTok{10}\NormalTok{, step }\OperatorTok{=} \FloatTok{0.25}\NormalTok{),}
\NormalTok{                     np.arange(start }\OperatorTok{=}\NormalTok{ X\_set[:, }\DecValTok{1}\NormalTok{].}\BuiltInTok{min}\NormalTok{() }\OperatorTok{{-}} \DecValTok{1000}\NormalTok{, stop }\OperatorTok{=}\NormalTok{ X\_set[:, }\DecValTok{1}\NormalTok{].}\BuiltInTok{max}\NormalTok{() }\OperatorTok{+} \DecValTok{1000}\NormalTok{, step }\OperatorTok{=} \FloatTok{0.25}\NormalTok{))}
\NormalTok{plt.contourf(X1, X2, classifier.predict(sc.transform(np.array([X1.ravel(), X2.ravel()]).T)).reshape(X1.shape),}
\NormalTok{             alpha }\OperatorTok{=} \FloatTok{0.75}\NormalTok{, cmap }\OperatorTok{=}\NormalTok{ ListedColormap((}\StringTok{\textquotesingle{}red\textquotesingle{}}\NormalTok{, }\StringTok{\textquotesingle{}green\textquotesingle{}}\NormalTok{)))}
\NormalTok{plt.xlim(X1.}\BuiltInTok{min}\NormalTok{(), X1.}\BuiltInTok{max}\NormalTok{())}
\NormalTok{plt.ylim(X2.}\BuiltInTok{min}\NormalTok{(), X2.}\BuiltInTok{max}\NormalTok{())}
\ControlFlowTok{for}\NormalTok{ i, j }\KeywordTok{in} \BuiltInTok{enumerate}\NormalTok{(np.unique(y\_set)):}
\NormalTok{    plt.scatter(X\_set[y\_set }\OperatorTok{==}\NormalTok{ j, }\DecValTok{0}\NormalTok{], X\_set[y\_set }\OperatorTok{==}\NormalTok{ j, }\DecValTok{1}\NormalTok{], c }\OperatorTok{=}\NormalTok{ ListedColormap((}\StringTok{\textquotesingle{}red\textquotesingle{}}\NormalTok{, }\StringTok{\textquotesingle{}green\textquotesingle{}}\NormalTok{))(i), label }\OperatorTok{=}\NormalTok{ j)}
\NormalTok{plt.title(}\StringTok{\textquotesingle{}Random Forest Classification (Training set)\textquotesingle{}}\NormalTok{)}
\NormalTok{plt.xlabel(}\StringTok{\textquotesingle{}Age\textquotesingle{}}\NormalTok{)}
\NormalTok{plt.ylabel(}\StringTok{\textquotesingle{}Estimated Salary\textquotesingle{}}\NormalTok{)}
\NormalTok{plt.legend()}
\NormalTok{plt.show()}
\end{Highlighting}
\end{Shaded}

R

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{library}\NormalTok{(ElemStatLearn)}
\NormalTok{set }\OtherTok{=}\NormalTok{ training\_set}
\NormalTok{X1 }\OtherTok{=} \FunctionTok{seq}\NormalTok{(}\FunctionTok{min}\NormalTok{(set[, }\DecValTok{1}\NormalTok{]) }\SpecialCharTok{{-}} \DecValTok{1}\NormalTok{, }\FunctionTok{max}\NormalTok{(set[, }\DecValTok{1}\NormalTok{]) }\SpecialCharTok{+} \DecValTok{1}\NormalTok{, }\AttributeTok{by =} \FloatTok{0.01}\NormalTok{)}
\NormalTok{X2 }\OtherTok{=} \FunctionTok{seq}\NormalTok{(}\FunctionTok{min}\NormalTok{(set[, }\DecValTok{2}\NormalTok{]) }\SpecialCharTok{{-}} \DecValTok{1}\NormalTok{, }\FunctionTok{max}\NormalTok{(set[, }\DecValTok{2}\NormalTok{]) }\SpecialCharTok{+} \DecValTok{1}\NormalTok{, }\AttributeTok{by =} \FloatTok{0.01}\NormalTok{)}
\NormalTok{grid\_set }\OtherTok{=} \FunctionTok{expand.grid}\NormalTok{(X1, X2)}
\FunctionTok{colnames}\NormalTok{(grid\_set) }\OtherTok{=} \FunctionTok{c}\NormalTok{(}\StringTok{\textquotesingle{}Age\textquotesingle{}}\NormalTok{, }\StringTok{\textquotesingle{}EstimatedSalary\textquotesingle{}}\NormalTok{)}
\NormalTok{y\_grid }\OtherTok{=} \FunctionTok{predict}\NormalTok{(classifier, grid\_set)}
\FunctionTok{plot}\NormalTok{(set[, }\SpecialCharTok{{-}}\DecValTok{3}\NormalTok{],}
     \AttributeTok{main =} \StringTok{\textquotesingle{}Random Forest Classification (Training set)\textquotesingle{}}\NormalTok{,}
     \AttributeTok{xlab =} \StringTok{\textquotesingle{}Age\textquotesingle{}}\NormalTok{, }\AttributeTok{ylab =} \StringTok{\textquotesingle{}Estimated Salary\textquotesingle{}}\NormalTok{,}
     \AttributeTok{xlim =} \FunctionTok{range}\NormalTok{(X1), }\AttributeTok{ylim =} \FunctionTok{range}\NormalTok{(X2))}
\FunctionTok{contour}\NormalTok{(X1, X2, }\FunctionTok{matrix}\NormalTok{(}\FunctionTok{as.numeric}\NormalTok{(y\_grid), }\FunctionTok{length}\NormalTok{(X1), }\FunctionTok{length}\NormalTok{(X2)), }\AttributeTok{add =} \ConstantTok{TRUE}\NormalTok{)}
\FunctionTok{points}\NormalTok{(grid\_set, }\AttributeTok{pch =} \StringTok{\textquotesingle{}.\textquotesingle{}}\NormalTok{, }\AttributeTok{col =} \FunctionTok{ifelse}\NormalTok{(y\_grid }\SpecialCharTok{==} \DecValTok{1}\NormalTok{, }\StringTok{\textquotesingle{}springgreen3\textquotesingle{}}\NormalTok{, }\StringTok{\textquotesingle{}tomato\textquotesingle{}}\NormalTok{))}
\FunctionTok{points}\NormalTok{(set, }\AttributeTok{pch =} \DecValTok{21}\NormalTok{, }\AttributeTok{bg =} \FunctionTok{ifelse}\NormalTok{(set[, }\DecValTok{3}\NormalTok{] }\SpecialCharTok{==} \DecValTok{1}\NormalTok{, }\StringTok{\textquotesingle{}green4\textquotesingle{}}\NormalTok{, }\StringTok{\textquotesingle{}red3\textquotesingle{}}\NormalTok{))}
\end{Highlighting}
\end{Shaded}

\includegraphics{_main_files/figure-latex/unnamed-chunk-215-1.pdf}

\hypertarget{visualising-the-test-set-results-7}{%
\subsection{Visualising the Test set results}\label{visualising-the-test-set-results-7}}

Python

\begin{Shaded}
\begin{Highlighting}[]
\ImportTok{from}\NormalTok{ matplotlib.colors }\ImportTok{import}\NormalTok{ ListedColormap}
\NormalTok{X\_set, y\_set }\OperatorTok{=}\NormalTok{ sc.inverse\_transform(X\_test), y\_test}
\NormalTok{X1, X2 }\OperatorTok{=}\NormalTok{ np.meshgrid(np.arange(start }\OperatorTok{=}\NormalTok{ X\_set[:, }\DecValTok{0}\NormalTok{].}\BuiltInTok{min}\NormalTok{() }\OperatorTok{{-}} \DecValTok{10}\NormalTok{, stop }\OperatorTok{=}\NormalTok{ X\_set[:, }\DecValTok{0}\NormalTok{].}\BuiltInTok{max}\NormalTok{() }\OperatorTok{+} \DecValTok{10}\NormalTok{, step }\OperatorTok{=} \FloatTok{0.25}\NormalTok{),}
\NormalTok{                     np.arange(start }\OperatorTok{=}\NormalTok{ X\_set[:, }\DecValTok{1}\NormalTok{].}\BuiltInTok{min}\NormalTok{() }\OperatorTok{{-}} \DecValTok{1000}\NormalTok{, stop }\OperatorTok{=}\NormalTok{ X\_set[:, }\DecValTok{1}\NormalTok{].}\BuiltInTok{max}\NormalTok{() }\OperatorTok{+} \DecValTok{1000}\NormalTok{, step }\OperatorTok{=} \FloatTok{0.25}\NormalTok{))}
\NormalTok{plt.contourf(X1, X2, classifier.predict(sc.transform(np.array([X1.ravel(), X2.ravel()]).T)).reshape(X1.shape),}
\NormalTok{             alpha }\OperatorTok{=} \FloatTok{0.75}\NormalTok{, cmap }\OperatorTok{=}\NormalTok{ ListedColormap((}\StringTok{\textquotesingle{}red\textquotesingle{}}\NormalTok{, }\StringTok{\textquotesingle{}green\textquotesingle{}}\NormalTok{)))}
\NormalTok{plt.xlim(X1.}\BuiltInTok{min}\NormalTok{(), X1.}\BuiltInTok{max}\NormalTok{())}
\NormalTok{plt.ylim(X2.}\BuiltInTok{min}\NormalTok{(), X2.}\BuiltInTok{max}\NormalTok{())}
\ControlFlowTok{for}\NormalTok{ i, j }\KeywordTok{in} \BuiltInTok{enumerate}\NormalTok{(np.unique(y\_set)):}
\NormalTok{    plt.scatter(X\_set[y\_set }\OperatorTok{==}\NormalTok{ j, }\DecValTok{0}\NormalTok{], X\_set[y\_set }\OperatorTok{==}\NormalTok{ j, }\DecValTok{1}\NormalTok{], c }\OperatorTok{=}\NormalTok{ ListedColormap((}\StringTok{\textquotesingle{}red\textquotesingle{}}\NormalTok{, }\StringTok{\textquotesingle{}green\textquotesingle{}}\NormalTok{))(i), label }\OperatorTok{=}\NormalTok{ j)}
\NormalTok{plt.title(}\StringTok{\textquotesingle{}Random Forest Classification (Test set)\textquotesingle{}}\NormalTok{)}
\NormalTok{plt.xlabel(}\StringTok{\textquotesingle{}Age\textquotesingle{}}\NormalTok{)}
\NormalTok{plt.ylabel(}\StringTok{\textquotesingle{}Estimated Salary\textquotesingle{}}\NormalTok{)}
\NormalTok{plt.legend()}
\NormalTok{plt.show()}
\end{Highlighting}
\end{Shaded}

R

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{library}\NormalTok{(ElemStatLearn)}
\NormalTok{set }\OtherTok{=}\NormalTok{ test\_set}
\NormalTok{X1 }\OtherTok{=} \FunctionTok{seq}\NormalTok{(}\FunctionTok{min}\NormalTok{(set[, }\DecValTok{1}\NormalTok{]) }\SpecialCharTok{{-}} \DecValTok{1}\NormalTok{, }\FunctionTok{max}\NormalTok{(set[, }\DecValTok{1}\NormalTok{]) }\SpecialCharTok{+} \DecValTok{1}\NormalTok{, }\AttributeTok{by =} \FloatTok{0.01}\NormalTok{)}
\NormalTok{X2 }\OtherTok{=} \FunctionTok{seq}\NormalTok{(}\FunctionTok{min}\NormalTok{(set[, }\DecValTok{2}\NormalTok{]) }\SpecialCharTok{{-}} \DecValTok{1}\NormalTok{, }\FunctionTok{max}\NormalTok{(set[, }\DecValTok{2}\NormalTok{]) }\SpecialCharTok{+} \DecValTok{1}\NormalTok{, }\AttributeTok{by =} \FloatTok{0.01}\NormalTok{)}
\NormalTok{grid\_set }\OtherTok{=} \FunctionTok{expand.grid}\NormalTok{(X1, X2)}
\FunctionTok{colnames}\NormalTok{(grid\_set) }\OtherTok{=} \FunctionTok{c}\NormalTok{(}\StringTok{\textquotesingle{}Age\textquotesingle{}}\NormalTok{, }\StringTok{\textquotesingle{}EstimatedSalary\textquotesingle{}}\NormalTok{)}
\NormalTok{y\_grid }\OtherTok{=} \FunctionTok{predict}\NormalTok{(classifier, grid\_set)}
\FunctionTok{plot}\NormalTok{(set[, }\SpecialCharTok{{-}}\DecValTok{3}\NormalTok{], }\AttributeTok{main =} \StringTok{\textquotesingle{}Random Forest Classification (Test set)\textquotesingle{}}\NormalTok{,}
     \AttributeTok{xlab =} \StringTok{\textquotesingle{}Age\textquotesingle{}}\NormalTok{, }\AttributeTok{ylab =} \StringTok{\textquotesingle{}Estimated Salary\textquotesingle{}}\NormalTok{,}
     \AttributeTok{xlim =} \FunctionTok{range}\NormalTok{(X1), }\AttributeTok{ylim =} \FunctionTok{range}\NormalTok{(X2))}
\FunctionTok{contour}\NormalTok{(X1, X2, }\FunctionTok{matrix}\NormalTok{(}\FunctionTok{as.numeric}\NormalTok{(y\_grid), }\FunctionTok{length}\NormalTok{(X1), }\FunctionTok{length}\NormalTok{(X2)), }\AttributeTok{add =} \ConstantTok{TRUE}\NormalTok{)}
\FunctionTok{points}\NormalTok{(grid\_set, }\AttributeTok{pch =} \StringTok{\textquotesingle{}.\textquotesingle{}}\NormalTok{, }\AttributeTok{col =} \FunctionTok{ifelse}\NormalTok{(y\_grid }\SpecialCharTok{==} \DecValTok{1}\NormalTok{, }\StringTok{\textquotesingle{}springgreen3\textquotesingle{}}\NormalTok{, }\StringTok{\textquotesingle{}tomato\textquotesingle{}}\NormalTok{))}
\FunctionTok{points}\NormalTok{(set, }\AttributeTok{pch =} \DecValTok{21}\NormalTok{, }\AttributeTok{bg =} \FunctionTok{ifelse}\NormalTok{(set[, }\DecValTok{3}\NormalTok{] }\SpecialCharTok{==} \DecValTok{1}\NormalTok{, }\StringTok{\textquotesingle{}green4\textquotesingle{}}\NormalTok{, }\StringTok{\textquotesingle{}red3\textquotesingle{}}\NormalTok{))}
\end{Highlighting}
\end{Shaded}

\includegraphics{_main_files/figure-latex/unnamed-chunk-217-1.pdf}

\hypertarget{choosing-the-number-of-trees}{%
\subsection{Choosing the number of trees}\label{choosing-the-number-of-trees}}

R

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{plot}\NormalTok{(classifier)}
\end{Highlighting}
\end{Shaded}

\includegraphics{_main_files/figure-latex/unnamed-chunk-218-1.pdf}

\hypertarget{classification-model-selection-in-python}{%
\section{Classification Model Selection in Python}\label{classification-model-selection-in-python}}

\hypertarget{heading-3}{%
\subsection{Heading 3}\label{heading-3}}

Python

R

\hypertarget{footnotes-and-citations}{%
\chapter{Footnotes and citations}\label{footnotes-and-citations}}

\hypertarget{footnotes}{%
\section{Footnotes}\label{footnotes}}

Footnotes are put inside the square brackets after a caret \texttt{\^{}{[}{]}}. Like this one \footnote{This is a footnote.}.

\hypertarget{citations}{%
\section{Citations}\label{citations}}

Reference items in your bibliography file(s) using \texttt{@key}.

For example, we are using the \textbf{bookdown} package \citep{R-bookdown} (check out the last code chunk in index.Rmd to see how this citation key was added) in this sample book, which was built on top of R Markdown and \textbf{knitr} \citep{xie2015} (this citation was added manually in an external file book.bib).
Note that the \texttt{.bib} files need to be listed in the index.Rmd with the YAML \texttt{bibliography} key.

The RStudio Visual Markdown Editor can also make it easier to insert citations: \url{https://rstudio.github.io/visual-markdown-editing/\#/citations}

\hypertarget{blocks}{%
\chapter{Blocks}\label{blocks}}

\hypertarget{equations}{%
\section{Equations}\label{equations}}

Here is an equation.

\begin{equation} 
  f\left(k\right) = \binom{n}{k} p^k\left(1-p\right)^{n-k}
  \label{eq:binom}
\end{equation}

You may refer to using \texttt{\textbackslash{}@ref(eq:binom)}, like see Equation \eqref{eq:binom}.

\hypertarget{theorems-and-proofs}{%
\section{Theorems and proofs}\label{theorems-and-proofs}}

Labeled theorems can be referenced in text using \texttt{\textbackslash{}@ref(thm:tri)}, for example, check out this smart theorem \ref{thm:tri}.

\begin{theorem}
\protect\hypertarget{thm:tri}{}\label{thm:tri}For a right triangle, if \(c\) denotes the \emph{length} of the hypotenuse
and \(a\) and \(b\) denote the lengths of the \textbf{other} two sides, we have
\[a^2 + b^2 = c^2\]
\end{theorem}

Read more here \url{https://bookdown.org/yihui/bookdown/markdown-extensions-by-bookdown.html}.

\hypertarget{callout-blocks}{%
\section{Callout blocks}\label{callout-blocks}}

The R Markdown Cookbook provides more help on how to use custom blocks to design your own callouts: \url{https://bookdown.org/yihui/rmarkdown-cookbook/custom-blocks.html}

\hypertarget{sharing-your-book}{%
\chapter{Sharing your book}\label{sharing-your-book}}

\hypertarget{publishing}{%
\section{Publishing}\label{publishing}}

HTML books can be published online, see: \url{https://bookdown.org/yihui/bookdown/publishing.html}

\hypertarget{pages}{%
\section{404 pages}\label{pages}}

By default, users will be directed to a 404 page if they try to access a webpage that cannot be found. If you'd like to customize your 404 page instead of using the default, you may add either a \texttt{\_404.Rmd} or \texttt{\_404.md} file to your project root and use code and/or Markdown syntax.

\hypertarget{metadata-for-sharing}{%
\section{Metadata for sharing}\label{metadata-for-sharing}}

Bookdown HTML books will provide HTML metadata for social sharing on platforms like Twitter, Facebook, and LinkedIn, using information you provide in the \texttt{index.Rmd} YAML. To setup, set the \texttt{url} for your book and the path to your \texttt{cover-image} file. Your book's \texttt{title} and \texttt{description} are also used.

This \texttt{gitbook} uses the same social sharing data across all chapters in your book- all links shared will look the same.

Specify your book's source repository on GitHub using the \texttt{edit} key under the configuration options in the \texttt{\_output.yml} file, which allows users to suggest an edit by linking to a chapter's source file.

Read more about the features of this output format here:

\url{https://pkgs.rstudio.com/bookdown/reference/gitbook.html}

Or use:

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{?bookdown}\SpecialCharTok{::}\NormalTok{gitbook}
\end{Highlighting}
\end{Shaded}


\end{document}
